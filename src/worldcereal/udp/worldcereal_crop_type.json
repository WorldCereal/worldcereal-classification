{
  "process_graph": {
    "loadcollection1": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "B02",
          "B03",
          "B04",
          "B05",
          "B06",
          "B07",
          "B08",
          "B8A",
          "B11",
          "B12"
        ],
        "featureflags": {
          "tilesize": 128
        },
        "id": "SENTINEL2_L2A",
        "properties": {
          "eo:cloud_cover": {
            "process_graph": {
              "lte1": {
                "process_id": "lte",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": 95.0
                },
                "result": true
              }
            }
          }
        },
        "spatial_extent": null,
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        }
      }
    },
    "loadcollection2": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "SCL"
        ],
        "id": "SENTINEL2_L2A",
        "properties": {
          "eo:cloud_cover": {
            "process_graph": {
              "lte2": {
                "process_id": "lte",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": 95.0
                },
                "result": true
              }
            }
          }
        },
        "spatial_extent": null,
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        }
      }
    },
    "resamplespatial1": {
      "process_id": "resample_spatial",
      "arguments": {
        "align": "upper-left",
        "data": {
          "from_node": "loadcollection2"
        },
        "method": "near",
        "projection": null,
        "resolution": 10
      }
    },
    "toscldilationmask1": {
      "process_id": "to_scl_dilation_mask",
      "arguments": {
        "data": {
          "from_node": "resamplespatial1"
        },
        "erosion_kernel_size": 3,
        "kernel1_size": 17,
        "kernel2_size": 77,
        "mask1_values": [
          2,
          4,
          5,
          6,
          7
        ],
        "mask2_values": [
          3,
          8,
          9,
          10,
          11
        ],
        "scl_band_name": "SCL"
      }
    },
    "renamelabels1": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "toscldilationmask1"
        },
        "dimension": "bands",
        "target": [
          "S2-L2A-SCL_DILATED_MASK"
        ]
      }
    },
    "mask1": {
      "process_id": "mask",
      "arguments": {
        "data": {
          "from_node": "loadcollection1"
        },
        "mask": {
          "from_node": "renamelabels1"
        }
      }
    },
    "renamelabels2": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "mask1"
        },
        "dimension": "bands",
        "source": [
          "B02",
          "B03",
          "B04",
          "B05",
          "B06",
          "B07",
          "B08",
          "B8A",
          "B11",
          "B12"
        ],
        "target": [
          "S2-L2A-B02",
          "S2-L2A-B03",
          "S2-L2A-B04",
          "S2-L2A-B05",
          "S2-L2A-B06",
          "S2-L2A-B07",
          "S2-L2A-B08",
          "S2-L2A-B8A",
          "S2-L2A-B11",
          "S2-L2A-B12"
        ]
      }
    },
    "apply1": {
      "process_id": "apply",
      "arguments": {
        "data": {
          "from_node": "renamelabels2"
        },
        "process": {
          "process_graph": {
            "linearscalerange1": {
              "process_id": "linear_scale_range",
              "arguments": {
                "inputMax": 65534,
                "inputMin": 0,
                "outputMax": 65534,
                "outputMin": 0,
                "x": {
                  "from_parameter": "x"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "aggregatetemporalperiod1": {
      "process_id": "aggregate_temporal_period",
      "arguments": {
        "data": {
          "from_node": "apply1"
        },
        "dimension": "t",
        "period": "month",
        "reducer": {
          "process_graph": {
            "median1": {
              "process_id": "median",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "apply2": {
      "process_id": "apply",
      "arguments": {
        "data": {
          "from_node": "aggregatetemporalperiod1"
        },
        "process": {
          "process_graph": {
            "linearscalerange2": {
              "process_id": "linear_scale_range",
              "arguments": {
                "inputMax": 65534,
                "inputMin": 0,
                "outputMax": 65534,
                "outputMin": 0,
                "x": {
                  "from_parameter": "x"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "loadcollection3": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "VH",
          "VV"
        ],
        "featureflags": {
          "tilesize": 128
        },
        "id": "SENTINEL1_GRD",
        "properties": {
          "sat:orbit_state": {
            "process_graph": {
              "eq1": {
                "process_id": "eq",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": {
                    "from_parameter": "orbit_state"
                  }
                },
                "result": true
              }
            }
          },
          "polarisation": {
            "process_graph": {
              "eq2": {
                "process_id": "eq",
                "arguments": {
                  "x": {
                    "from_parameter": "value"
                  },
                  "y": "VV&VH"
                },
                "result": true
              }
            }
          }
        },
        "spatial_extent": null,
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        }
      }
    },
    "sarbackscatter1": {
      "process_id": "sar_backscatter",
      "arguments": {
        "coefficient": "sigma0-ellipsoid",
        "contributing_area": false,
        "data": {
          "from_node": "loadcollection3"
        },
        "elevation_model": "COPERNICUS_30",
        "ellipsoid_incidence_angle": false,
        "local_incidence_angle": false,
        "mask": false,
        "noise_removal": true
      }
    },
    "resamplespatial2": {
      "process_id": "resample_spatial",
      "arguments": {
        "align": "upper-left",
        "data": {
          "from_node": "sarbackscatter1"
        },
        "method": "near",
        "projection": null,
        "resolution": 20.0
      }
    },
    "renamelabels3": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "resamplespatial2"
        },
        "dimension": "bands",
        "source": [
          "VH",
          "VV"
        ],
        "target": [
          "S1-SIGMA0-VH",
          "S1-SIGMA0-VV"
        ]
      }
    },
    "aggregatetemporalperiod2": {
      "process_id": "aggregate_temporal_period",
      "arguments": {
        "data": {
          "from_node": "renamelabels3"
        },
        "dimension": "t",
        "period": "month",
        "reducer": {
          "process_graph": {
            "mean1": {
              "process_id": "mean",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "applydimension1": {
      "process_id": "apply_dimension",
      "arguments": {
        "data": {
          "from_node": "aggregatetemporalperiod2"
        },
        "dimension": "bands",
        "process": {
          "process_graph": {
            "arrayelement1": {
              "process_id": "array_element",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                },
                "index": 0
              }
            },
            "log1": {
              "process_id": "log",
              "arguments": {
                "base": 10,
                "x": {
                  "from_node": "arrayelement1"
                }
              }
            },
            "multiply1": {
              "process_id": "multiply",
              "arguments": {
                "x": 10.0,
                "y": {
                  "from_node": "log1"
                }
              }
            },
            "add1": {
              "process_id": "add",
              "arguments": {
                "x": {
                  "from_node": "multiply1"
                },
                "y": 83.0
              }
            },
            "divide1": {
              "process_id": "divide",
              "arguments": {
                "x": {
                  "from_node": "add1"
                },
                "y": 20.0
              }
            },
            "power1": {
              "process_id": "power",
              "arguments": {
                "base": 10,
                "p": {
                  "from_node": "divide1"
                }
              }
            },
            "arrayelement2": {
              "process_id": "array_element",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                },
                "index": 1
              }
            },
            "log2": {
              "process_id": "log",
              "arguments": {
                "base": 10,
                "x": {
                  "from_node": "arrayelement2"
                }
              }
            },
            "multiply2": {
              "process_id": "multiply",
              "arguments": {
                "x": 10.0,
                "y": {
                  "from_node": "log2"
                }
              }
            },
            "add2": {
              "process_id": "add",
              "arguments": {
                "x": {
                  "from_node": "multiply2"
                },
                "y": 83.0
              }
            },
            "divide2": {
              "process_id": "divide",
              "arguments": {
                "x": {
                  "from_node": "add2"
                },
                "y": 20.0
              }
            },
            "power2": {
              "process_id": "power",
              "arguments": {
                "base": 10,
                "p": {
                  "from_node": "divide2"
                }
              }
            },
            "arraycreate1": {
              "process_id": "array_create",
              "arguments": {
                "data": [
                  {
                    "from_node": "power1"
                  },
                  {
                    "from_node": "power2"
                  }
                ]
              },
              "result": true
            }
          }
        }
      }
    },
    "apply3": {
      "process_id": "apply",
      "arguments": {
        "data": {
          "from_node": "applydimension1"
        },
        "process": {
          "process_graph": {
            "linearscalerange3": {
              "process_id": "linear_scale_range",
              "arguments": {
                "inputMax": 65534,
                "inputMin": 1,
                "outputMax": 65534,
                "outputMin": 1,
                "x": {
                  "from_parameter": "x"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "mergecubes1": {
      "process_id": "merge_cubes",
      "arguments": {
        "cube1": {
          "from_node": "apply2"
        },
        "cube2": {
          "from_node": "apply3"
        }
      }
    },
    "loadstac1": {
      "process_id": "load_stac",
      "arguments": {
        "bands": [
          "Slope"
        ],
        "url": "https://stac.openeo.vito.be/collections/COPERNICUS30_DEM_SLOPE"
      }
    },
    "renamelabels4": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "loadstac1"
        },
        "dimension": "bands",
        "target": [
          "slope"
        ]
      }
    },
    "reducedimension1": {
      "process_id": "reduce_dimension",
      "arguments": {
        "data": {
          "from_node": "renamelabels4"
        },
        "dimension": "t",
        "reducer": {
          "process_graph": {
            "min1": {
              "process_id": "min",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "loadcollection4": {
      "process_id": "load_collection",
      "arguments": {
        "bands": [
          "DEM"
        ],
        "id": "COPERNICUS_30",
        "spatial_extent": null,
        "temporal_extent": null
      }
    },
    "reducedimension2": {
      "process_id": "reduce_dimension",
      "arguments": {
        "data": {
          "from_node": "loadcollection4"
        },
        "dimension": "t",
        "reducer": {
          "process_graph": {
            "min2": {
              "process_id": "min",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "renamelabels5": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "reducedimension2"
        },
        "dimension": "bands",
        "source": [
          "DEM"
        ],
        "target": [
          "COP-DEM"
        ]
      }
    },
    "renamelabels6": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "renamelabels5"
        },
        "dimension": "bands",
        "target": [
          "elevation"
        ]
      }
    },
    "mergecubes2": {
      "process_id": "merge_cubes",
      "arguments": {
        "cube1": {
          "from_node": "reducedimension1"
        },
        "cube2": {
          "from_node": "renamelabels6"
        }
      }
    },
    "resamplecubespatial1": {
      "process_id": "resample_cube_spatial",
      "arguments": {
        "data": {
          "from_node": "mergecubes2"
        },
        "method": "bilinear",
        "target": {
          "from_node": "apply2"
        }
      }
    },
    "apply4": {
      "process_id": "apply",
      "arguments": {
        "data": {
          "from_node": "resamplecubespatial1"
        },
        "process": {
          "process_graph": {
            "linearscalerange4": {
              "process_id": "linear_scale_range",
              "arguments": {
                "inputMax": 65534,
                "inputMin": 0,
                "outputMax": 65534,
                "outputMin": 0,
                "x": {
                  "from_parameter": "x"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "mergecubes3": {
      "process_id": "merge_cubes",
      "arguments": {
        "cube1": {
          "from_node": "mergecubes1"
        },
        "cube2": {
          "from_node": "apply4"
        }
      }
    },
    "loadstac2": {
      "process_id": "load_stac",
      "arguments": {
        "bands": [
          "precipitation-flux",
          "temperature-mean"
        ],
        "temporal_extent": {
          "from_parameter": "temporal_extent"
        },
        "url": "https://stac.openeo.vito.be/collections/agera5_monthly"
      }
    },
    "renamelabels7": {
      "process_id": "rename_labels",
      "arguments": {
        "data": {
          "from_node": "loadstac2"
        },
        "dimension": "bands",
        "target": [
          "AGERA5-PRECIP",
          "AGERA5-TMEAN"
        ]
      }
    },
    "resamplecubespatial2": {
      "process_id": "resample_cube_spatial",
      "arguments": {
        "data": {
          "from_node": "renamelabels7"
        },
        "method": "bilinear",
        "target": {
          "from_node": "apply2"
        }
      }
    },
    "mergecubes4": {
      "process_id": "merge_cubes",
      "arguments": {
        "cube1": {
          "from_node": "mergecubes3"
        },
        "cube2": {
          "from_node": "resamplecubespatial2"
        }
      }
    },
    "filterbbox1": {
      "process_id": "filter_bbox",
      "arguments": {
        "data": {
          "from_node": "mergecubes4"
        },
        "extent": {
          "from_parameter": "spatial_extent"
        }
      }
    },
    "applyneighborhood1": {
      "process_id": "apply_neighborhood",
      "arguments": {
        "data": {
          "from_node": "filterbbox1"
        },
        "overlap": [
          {
            "dimension": "x",
            "unit": "px",
            "value": 0
          },
          {
            "dimension": "y",
            "unit": "px",
            "value": 0
          }
        ],
        "process": {
          "process_graph": {
            "runudf1": {
              "process_id": "run_udf",
              "arguments": {
                "context": {
                  "cropland_params": {
                    "postprocess_parameters": {
                      "enable": true,
                      "method": "smooth_probabilities",
                      "kernel_size": 5,
                      "save_intermediate": false,
                      "keep_class_probs": true
                    },
                    "feature_parameters": {
                      "rescale_s1": false,
                      "presto_model_url": "https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/presto-prometheo-landcover-MulticlassWithCroplandAuxBCELoss-labelsmoothing%3D0.05-month-LANDCOVER10-augment%3DTrue-balance%3DTrue-timeexplicit%3DFalse-masking%3Denabled-run%3D202510301004_encoder.pt",
                      "compile_presto": false,
                      "temporal_prediction": false,
                      "target_date": null
                    },
                    "classifier_parameters": {
                      "classifier_url": "https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/PrestoDownstreamCatBoost_temporary-crops_v201-prestorun%3D202510301004.onnx"
                    }
                  },
                  "croptype_params": {
                    "postprocess_parameters": {
                      "enable": true,
                      "method": {
                        "from_parameter": "postprocess_method"
                      },
                      "kernel_size": {
                        "from_parameter": "postprocess_kernel_size"
                      },
                      "save_intermediate": false,
                      "keep_class_probs": true
                    },
                    "feature_parameters": {
                      "rescale_s1": false,
                      "presto_model_url": "https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/presto-prometheo-croptype-with-nocrop-FocalLoss-labelsmoothing%3D0.05-month-CROPTYPE27-augment%3DTrue-balance%3DTrue-timeexplicit%3DFalse-masking%3Denabled-run%3D202510301004_encoder.pt",
                      "compile_presto": true,
                      "temporal_prediction": false,
                      "target_date": null
                    },
                    "classifier_parameters": {
                      "classifier_url": {
                        "from_parameter": "model_url"
                      }
                    },
                    "mask_cropland": true,
                    "save_mask": false
                  }
                },
                "data": {
                  "from_parameter": "data"
                },
                "runtime": "Python",
                "udf": "\"\"\"openEO UDF to compute Presto/Prometheo features with clean code structure.\"\"\"\n\nimport logging\nimport os\nimport random\nimport sys\nfrom pathlib import Path\nfrom typing import Any, Dict, Optional, Tuple\n\nimport numpy as np\nimport requests\nimport xarray as xr\nfrom openeo.udf import XarrayDataCube\nfrom openeo.udf.udf_data import UdfData\nfrom pyproj import Transformer\nfrom scipy.ndimage import convolve, zoom\nfrom shapely.geometry import Point\nfrom shapely.ops import transform\n\ntry:\n    from loguru import logger\n\n    logger.remove()\n    logger.add(sys.stderr, level=\"INFO\")\n\n    class InterceptHandler(logging.Handler):\n        def emit(self, record):\n            level = record.levelname\n            logger.opt(depth=6).log(level, record.getMessage())\n\n    # Replace existing handlers\n    for h in logging.root.handlers[:]:\n        logging.root.removeHandler(h)\n\n    logging.root.setLevel(logging.INFO)\n    logging.root.addHandler(InterceptHandler())\n\nexcept ImportError:\n    # loguru not available, use standard logging\n    logger = logging.getLogger(__name__)\n\n_MODULE_CACHE_KEY = f\"__model_cache_{__name__}\"\n\n# Constants\nPROMETHEO_WHL_URL = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/dependencies/prometheo-0.0.3-py3-none-any.whl\"\n\nGFMAP_BAND_MAPPING = {\n    \"S2-L2A-B02\": \"B2\",\n    \"S2-L2A-B03\": \"B3\",\n    \"S2-L2A-B04\": \"B4\",\n    \"S2-L2A-B05\": \"B5\",\n    \"S2-L2A-B06\": \"B6\",\n    \"S2-L2A-B07\": \"B7\",\n    \"S2-L2A-B08\": \"B8\",\n    \"S2-L2A-B8A\": \"B8A\",\n    \"S2-L2A-B11\": \"B11\",\n    \"S2-L2A-B12\": \"B12\",\n    \"S1-SIGMA0-VH\": \"VH\",\n    \"S1-SIGMA0-VV\": \"VV\",\n    \"AGERA5-TMEAN\": \"temperature_2m\",\n    \"AGERA5-PRECIP\": \"total_precipitation\",\n}\n\nLAT_HARMONIZED_NAME = \"GEO-LAT\"\nLON_HARMONIZED_NAME = \"GEO-LON\"\nEPSG_HARMONIZED_NAME = \"GEO-EPSG\"\n\nS1_BANDS = [\"S1-SIGMA0-VV\", \"S1-SIGMA0-VH\", \"S1-SIGMA0-HV\", \"S1-SIGMA0-HH\"]\nNODATA_VALUE = 65535\n\nPOSTPROCESSING_EXCLUDED_VALUES = [254, 255, 65535]\nPOSTPROCESSING_NODATA = 255\n\nNUM_THREADS = 2\n\nsys.path.append(\"feature_deps\")\nsys.path.append(\"onnx_deps\")\nimport onnxruntime as ort  # noqa: E402\n\n_PROMETHEO_INSTALLED = False\n\n# Global variables for Prometheo imports\nPresto = None\nload_presto_weights = None\nrun_model_inference = None\nPoolingMethods = None\n\n\n# =============================================================================\n# STANDALONE FUNCTIONS (Work in both apply_udf_data and apply_metadata contexts)\n# =============================================================================\ndef get_model_cache():\n    \"\"\"Get or create module-specific cache.\"\"\"\n    if not hasattr(sys, _MODULE_CACHE_KEY):\n        setattr(sys, _MODULE_CACHE_KEY, {})\n    return getattr(sys, _MODULE_CACHE_KEY)\n\n\ndef _ensure_prometheo_dependencies():\n    \"\"\"Non-cached dependency check.\"\"\"\n    global \\\n        _PROMETHEO_INSTALLED, \\\n        Presto, \\\n        load_presto_weights, \\\n        run_model_inference, \\\n        PoolingMethods\n\n    if _PROMETHEO_INSTALLED:\n        return\n\n    try:\n        # Try to import first\n        from prometheo.datasets.worldcereal import run_model_inference\n        from prometheo.models import Presto\n        from prometheo.models.pooling import PoolingMethods\n        from prometheo.models.presto.wrapper import load_presto_weights\n\n        # They're now available in the global scope\n        _PROMETHEO_INSTALLED = True\n        return\n    except ImportError:\n        pass\n\n    # Installation required\n    logger.info(\"Prometheo not available, installing...\")\n    _install_prometheo()\n\n    # Import immediately after installation - these will be available globally\n    from prometheo.datasets.worldcereal import run_model_inference\n    from prometheo.models import Presto\n    from prometheo.models.pooling import PoolingMethods\n    from prometheo.models.presto.wrapper import load_presto_weights\n\n    optimize_pytorch_cpu_performance(NUM_THREADS)\n    _PROMETHEO_INSTALLED = True\n\n\ndef _install_prometheo():\n    \"\"\"Non-cached installation function.\"\"\"\n    import shutil\n    import tempfile\n    import urllib.request\n    import zipfile\n\n    temp_dir = Path(tempfile.mkdtemp())\n    try:\n        # Download wheel\n        wheel_path, _ = urllib.request.urlretrieve(PROMETHEO_WHL_URL)\n\n        # Extract to temp directory\n        with zipfile.ZipFile(wheel_path, \"r\") as zip_ref:\n            zip_ref.extractall(temp_dir)\n\n        # Add to Python path\n        sys.path.append(str(temp_dir))\n        logger.info(f\"Prometheo installed to {temp_dir}.\")\n\n    except Exception as e:\n        if temp_dir.exists():\n            shutil.rmtree(temp_dir)\n        logger.error(f\"Failed to install prometheo: {e}\")\n        raise\n\n\ndef load_onnx_model_cached(model_url: str):\n    \"\"\"ONNX loading is fine since it's pure (no side effects).\"\"\"\n\n    cache = get_model_cache()\n    if model_url in cache:\n        logger.debug(f\"ONNX model cache hit for {model_url}.\")\n        return cache[model_url]\n\n    logger.info(f\"Loading ONNX model from {model_url}\")\n    response = requests.get(model_url, timeout=120)\n\n    session_options, providers = optimize_onnx_cpu_performance(NUM_THREADS)\n\n    model = ort.InferenceSession(response.content, session_options, providers=providers)\n\n    metadata = model.get_modelmeta().custom_metadata_map\n    class_params = eval(metadata[\"class_params\"], {\"__builtins__\": None}, {})\n\n    lut = dict(zip(class_params[\"class_names\"], class_params[\"class_to_label\"]))\n    sorted_lut = {k: v for k, v in sorted(lut.items(), key=lambda item: item[1])}\n\n    result = (model, sorted_lut)\n    cache[model_url] = result\n    return result\n\n\ndef load_presto_weights_cached(presto_model_url: str):\n    \"\"\"Manual caching for Presto weights with dependency check.\"\"\"\n    cache = get_model_cache()\n    if presto_model_url in cache:\n        logger.debug(f\"Presto model cache hit for {presto_model_url}\")\n        return cache[presto_model_url]\n\n    # Ensure dependencies are available (not cached)\n    _ensure_prometheo_dependencies()\n\n    logger.info(f\"Loading Presto weights from: {presto_model_url}\")\n\n    model = Presto()  # type: ignore\n    result = load_presto_weights(model, presto_model_url)  # type: ignore\n\n    cache[presto_model_url] = result\n    return result\n\n\ndef get_output_labels(lut_sorted: dict) -> list:\n    \"\"\"Generate output band names from LUT - works in both contexts.\"\"\"\n    class_names = lut_sorted.keys()\n    return [\"classification\", \"probability\"] + [\n        f\"probability_{name}\" for name in class_names\n    ]\n\n\ndef optimize_pytorch_cpu_performance(num_threads):\n    \"\"\"CPU-specific optimizations for Prometheo.\"\"\"\n    import torch\n\n    # Thread configuration\n\n    torch.set_num_threads(num_threads)\n    torch.set_num_interop_threads(\n        num_threads\n    )  # TODO test setting to 4 due to parallel slope cal ect\n    os.environ[\"OMP_NUM_THREADS\"] = str(num_threads)\n    os.environ[\"MKL_NUM_THREADS\"] = str(num_threads)\n    os.environ[\"OPENBLAS_NUM_THREADS\"] = str(num_threads)\n\n    logger.info(f\"PyTorch CPU:  using {num_threads} threads\")\n\n    # CPU-specific optimizations\n    if hasattr(torch.backends, \"mkldnn\"):\n        torch.backends.mkldnn.enabled = True\n\n    torch.set_grad_enabled(False)  # Disable gradients for inference\n\n    return num_threads\n\n\ndef optimize_onnx_cpu_performance(num_threads):\n    \"\"\"CPU-specific ONNX optimizations.\"\"\"\n    session_options = ort.SessionOptions()\n\n    session_options.intra_op_num_threads = num_threads\n    session_options.inter_op_num_threads = (\n        num_threads  # TODO test setting to 1 due to sequential nature\n    )\n\n    # CPU-specific optimizations\n    session_options.enable_cpu_mem_arena = True\n    session_options.enable_mem_pattern = True\n    session_options.execution_mode = ort.ExecutionMode.ORT_SEQUENTIAL\n    session_options.graph_optimization_level = ort.GraphOptimizationLevel.ORT_ENABLE_ALL\n\n    providers = [\"CPUExecutionProvider\"]\n\n    return session_options, providers\n\n\n# =============================================================================\n# POSTPROCESSING FUNCTIONS\n# =============================================================================\n\n\ndef majority_vote(\n    base_labels: xr.DataArray,\n    max_probabilities: xr.DataArray,\n    kernel_size: int,\n) -> xr.DataArray:\n    \"\"\"Majority vote is performed using a sliding local kernel.\n    For each pixel, the voting of a final class is done by counting\n    neighbours values.\n    Pixels that have one of the specified excluded values are\n    excluded in the voting process and are unchanged.\n\n    The prediction probabilities are reevaluated by taking, for each pixel,\n    the average of probabilities of the neighbors that belong to the winning class.\n    (For example, if a pixel was voted to class 2 and there are three\n    neighbors of that class, then the new probability is the sum of the\n    old probabilities of each pixels divided by 3)\n\n    Parameters\n    ----------\n    base_labels : xr.DataArray\n        The original predicted classification labels.\n    max_probabilities : xr.DataArray\n        The original probabilities of the winning class (ranging between 0 and 100).\n    kernel_size : int\n        The size of the kernel used for the neighbour around the pixel.\n\n    Returns\n    -------\n    xr.DataArray\n        The cleaned classification labels and associated probabilities.\n    \"\"\"\n    from scipy.signal import convolve2d\n\n    prediction = base_labels.values\n    probability = max_probabilities.values\n\n    # As the probabilities are in integers between 0 and 100,\n    # we use uint16 matrices to store the vote scores\n    assert kernel_size <= 25, (\n        f\"Kernel value cannot be larger than 25 (currently: {kernel_size}) because it might lead to scenarios where the 16-bit count matrix is overflown\"\n    )\n\n    # Build a class mapping, so classes are converted to indexes and vice-versa\n    unique_values = set(np.unique(prediction))\n    unique_values = sorted(unique_values - set(POSTPROCESSING_EXCLUDED_VALUES))  # type: ignore\n    index_value_lut = [(k, v) for k, v in enumerate(unique_values)]\n\n    counts = np.zeros(shape=(*prediction.shape, len(unique_values)), dtype=np.uint16)\n    probabilities = np.zeros(\n        shape=(*probability.shape, len(unique_values)), dtype=np.uint16\n    )\n\n    # Iterates for each classes\n    for cls_idx, cls_value in index_value_lut:\n        # Take the binary mask of the interest class, and multiply by the probabilities\n        class_mask = ((prediction == cls_value) * probability).astype(np.uint16)\n\n        # Set to 0 the class scores where the label is excluded\n        for excluded_value in POSTPROCESSING_EXCLUDED_VALUES:\n            class_mask[prediction == excluded_value] = 0\n\n        # Binary class mask, used to count HOW MANY neighbours pixels are used for this class\n        binary_class_mask = (class_mask > 0).astype(np.uint16)\n\n        # Creates the kernel\n        kernel = np.ones(shape=(kernel_size, kernel_size), dtype=np.uint16)\n\n        # Counts around the window the sum of probabilities for that given class\n        counts[:, :, cls_idx] = convolve2d(class_mask, kernel, mode=\"same\")\n\n        # Counts the number of neighbors pixels that voted for that given class\n        class_voters = convolve2d(binary_class_mask, kernel, mode=\"same\")\n        # Remove the 0 values because might create divide by 0 issues\n        class_voters[class_voters == 0] = 1\n\n        probabilities[:, :, cls_idx] = np.divide(counts[:, :, cls_idx], class_voters)\n\n    # Initializes output array\n    aggregated_predictions = np.zeros(\n        shape=(counts.shape[0], counts.shape[1]), dtype=np.uint16\n    )\n    # Initializes probabilities output array\n    aggregated_probabilities = np.zeros(\n        shape=(counts.shape[0], counts.shape[1]), dtype=np.uint16\n    )\n\n    if len(unique_values) > 0:\n        # Takes the indices that have the biggest scores\n        aggregated_predictions_indices = np.argmax(counts, axis=2)\n\n        # Get the new probabilities of the predictions\n        aggregated_probabilities = np.take_along_axis(\n            probabilities,\n            aggregated_predictions_indices.reshape(\n                *aggregated_predictions_indices.shape, 1\n            ),\n            axis=2,\n        ).squeeze()\n\n        # Check which pixels have a counts value equal to 0\n        no_score_mask = np.sum(counts, axis=2) == 0\n\n        # convert back to values from indices\n        for cls_idx, cls_value in index_value_lut:\n            aggregated_predictions[aggregated_predictions_indices == cls_idx] = (\n                cls_value\n            )\n            aggregated_predictions = aggregated_predictions.astype(np.uint16)\n\n        aggregated_predictions[no_score_mask] = POSTPROCESSING_NODATA\n        aggregated_probabilities[no_score_mask] = POSTPROCESSING_NODATA\n\n    # Setting excluded values back to their original values\n    for excluded_value in POSTPROCESSING_EXCLUDED_VALUES:\n        aggregated_predictions[prediction == excluded_value] = excluded_value\n        aggregated_probabilities[prediction == excluded_value] = excluded_value\n\n    return xr.DataArray(\n        np.stack((aggregated_predictions, aggregated_probabilities)),\n        dims=[\"bands\", \"y\", \"x\"],\n        coords={\n            \"bands\": [\"classification\", \"probability\"],\n            \"y\": base_labels.y,\n            \"x\": base_labels.x,\n        },\n    )\n\n\ndef smooth_probabilities(\n    base_labels: xr.DataArray, class_probabilities: xr.DataArray\n) -> xr.DataArray:\n    \"\"\"Performs gaussian smoothing on the class probabilities. Requires the\n    base labels to keep the pixels that are excluded away from smoothing.\n    \"\"\"\n    from scipy.signal import convolve2d\n\n    base_labels_vals = base_labels.values\n    probabilities_vals = class_probabilities.values\n\n    excluded_mask = np.in1d(\n        base_labels_vals.reshape(-1),\n        POSTPROCESSING_EXCLUDED_VALUES,\n    ).reshape(*base_labels_vals.shape)\n\n    conv_kernel = np.array([[1, 2, 1], [2, 3, 2], [1, 2, 1]], dtype=np.int16)\n\n    for class_idx in range(probabilities_vals.shape[0]):\n        probabilities_vals[class_idx] = (\n            convolve2d(\n                probabilities_vals[class_idx],\n                conv_kernel,\n                mode=\"same\",\n                boundary=\"symm\",\n            )\n            / conv_kernel.sum()\n        )\n        probabilities_vals[class_idx][excluded_mask] = 0\n\n    # Sum of probabilities should be 1, cast to uint16\n    probabilities_vals = np.round(\n        probabilities_vals / probabilities_vals.sum(axis=0) * 100.0\n    ).astype(\"uint16\")\n\n    return xr.DataArray(\n        probabilities_vals,\n        coords=class_probabilities.coords,\n        dims=class_probabilities.dims,\n    )\n\n\ndef reclassify(\n    base_labels: xr.DataArray,\n    base_max_probs: xr.DataArray,\n    probabilities: xr.DataArray,\n) -> xr.DataArray:\n    base_labels_vals = base_labels.values\n    base_max_probs_vals = base_max_probs.values\n\n    excluded_mask = np.in1d(\n        base_labels_vals.reshape(-1),\n        POSTPROCESSING_EXCLUDED_VALUES,\n    ).reshape(*base_labels_vals.shape)\n\n    new_labels_vals = np.argmax(probabilities.values, axis=0)\n    new_max_probs_vals = np.max(probabilities.values, axis=0)\n\n    new_labels_vals[excluded_mask] = base_labels_vals[excluded_mask]\n    new_max_probs_vals[excluded_mask] = base_max_probs_vals[excluded_mask]\n\n    return xr.DataArray(\n        np.stack((new_labels_vals, new_max_probs_vals)),\n        dims=[\"bands\", \"y\", \"x\"],\n        coords={\n            \"bands\": [\"classification\", \"probability\"],\n            \"y\": base_labels.y,\n            \"x\": base_labels.x,\n        },\n    )\n\n\n# =============================================================================\n# ERROR HANDLING - SIMPLE VERSION\n# =============================================================================\n\n\ndef create_nan_output_array(\n    inarr: xr.DataArray, num_outputs: int, error_info: str = \"\"\n) -> xr.DataArray:\n    \"\"\"Creates a NaN-filled output array with proper dimensions and coordinates.\n\n    Parameters\n    ----------\n    inarr : xr.DataArray\n        Input array to derive dimensions from\n    num_outputs : int\n        Number of output bands/classes\n    error_info : str\n        Error information to include in attributes for debugging\n\n    Returns\n    -------\n    xr.DataArray\n        NaN-filled array with proper structure\n    \"\"\"\n    logger.error(f\"Creating NaN output array due to error: {error_info}\")\n    logger.error(f\"Input array shape: {inarr.shape}, dims: {inarr.dims}\")\n    logger.error(\n        f\"Input array coords - bands: {inarr.bands.values}, t: {len(inarr.t)}, x: {len(inarr.x)}, y: {len(inarr.y)}\"\n    )\n\n    # Create NaN array with same spatial dimensions\n    nan_array = np.full(\n        (num_outputs, len(inarr.y), len(inarr.x)), np.nan, dtype=np.float32\n    )\n\n    # Create output array with proper coordinates\n    output_array = xr.DataArray(\n        nan_array,\n        dims=[\"bands\", \"y\", \"x\"],\n        coords={\n            \"bands\": list(range(num_outputs)),\n            \"y\": inarr.y,\n            \"x\": inarr.x,\n        },\n        attrs={\"error\": error_info},\n    )\n\n    return output_array\n\n\n# =============================================================================\n# CLASSES (Main logic for apply_udf_data)\n# =============================================================================\n\n\nclass SlopeCalculator:\n    \"\"\"Handles slope computation from elevation data.\"\"\"\n\n    @staticmethod\n    def compute(resolution: float, elevation_data: np.ndarray) -> np.ndarray:\n        \"\"\"Compute slope from elevation data.\"\"\"\n        dem_arr = SlopeCalculator._prepare_dem_array(elevation_data)\n        dem_downsampled = SlopeCalculator._downsample_to_20m(dem_arr, resolution)\n        slope = SlopeCalculator._compute_slope_gradient(dem_downsampled)\n        result = SlopeCalculator._upsample_to_original(slope, dem_arr.shape, resolution)\n        return result\n\n    @staticmethod\n    def _prepare_dem_array(dem: np.ndarray) -> np.ndarray:\n        \"\"\"Prepare DEM array by handling NaNs and invalid values.\"\"\"\n        dem_arr = dem.astype(np.float32)\n        dem_arr[dem_arr == NODATA_VALUE] = np.nan\n        return SlopeCalculator._fill_nans(dem_arr)\n\n    @staticmethod\n    def _fill_nans(dem_arr: np.ndarray, max_iter: int = 2) -> np.ndarray:\n        \"\"\"Fill NaN values using rolling fill approach.\"\"\"\n        if max_iter == 0 or not np.any(np.isnan(dem_arr)):\n            return dem_arr\n\n        mask = np.isnan(dem_arr)\n        roll_params = [(0, 1), (0, -1), (1, 0), (-1, 0)]\n        random.shuffle(roll_params)\n\n        for roll_param in roll_params:\n            rolled = np.roll(dem_arr, roll_param, axis=(0, 1))\n            dem_arr[mask] = rolled[mask]\n\n        return SlopeCalculator._fill_nans(dem_arr, max_iter - 1)\n\n    @staticmethod\n    def _downsample_to_20m(dem_arr: np.ndarray, resolution: float) -> np.ndarray:\n        \"\"\"Downsample DEM to 20m resolution for slope computation.\"\"\"\n        factor = int(20 / resolution)\n        if factor < 1 or factor % 2 != 0:\n            raise ValueError(f\"Unsupported resolution for slope: {resolution}\")\n\n        X, Y = dem_arr.shape\n        pad_X, pad_Y = (\n            (factor - (X % factor)) % factor,\n            (factor - (Y % factor)) % factor,\n        )\n        padded = np.pad(dem_arr, ((0, pad_X), (0, pad_Y)), mode=\"reflect\")\n\n        reshaped = padded.reshape(\n            (X + pad_X) // factor, factor, (Y + pad_Y) // factor, factor\n        )\n        return np.nanmean(reshaped, axis=(1, 3))\n\n    @staticmethod\n    def _compute_slope_gradient(dem: np.ndarray) -> np.ndarray:\n        \"\"\"Compute slope gradient using Sobel operators.\"\"\"\n        kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) / (8.0 * 20)\n        kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]) / (8.0 * 20)\n\n        dx = convolve(dem, kernel_x)\n        dy = convolve(dem, kernel_y)\n        gradient_magnitude = np.sqrt(dx**2 + dy**2)\n\n        return np.arctan(gradient_magnitude) * (180 / np.pi)\n\n    @staticmethod\n    def _upsample_to_original(\n        slope: np.ndarray, original_shape: Tuple[int, ...], resolution: float\n    ) -> np.ndarray:\n        \"\"\"Upsample slope back to original resolution.\"\"\"\n        factor = int(20 / resolution)\n        slope_upsampled = zoom(slope, zoom=factor, order=1)\n\n        # Handle odd dimensions\n        if original_shape[0] % 2 != 0:\n            slope_upsampled = slope_upsampled[:-1, :]\n        if original_shape[1] % 2 != 0:\n            slope_upsampled = slope_upsampled[:, :-1]\n\n        return slope_upsampled.astype(np.uint16)\n\n\nclass CoordinateTransformer:\n    \"\"\"Handles coordinate transformations and spatial operations.\"\"\"\n\n    @staticmethod\n    def get_resolution(inarr: xr.DataArray, epsg: int) -> float:\n        \"\"\"Calculate resolution in meters.\"\"\"\n        if epsg == 4326:\n            return CoordinateTransformer._get_wgs84_resolution(inarr)\n        return abs(inarr.x[1].values - inarr.x[0].values)\n\n    @staticmethod\n    def _get_wgs84_resolution(inarr: xr.DataArray) -> float:\n        \"\"\"Convert WGS84 coordinates to meters for resolution calculation.\"\"\"\n        transformer = Transformer.from_crs(4326, 3857, always_xy=True)\n        points = [Point(x, y) for x, y in zip(inarr.x.values, inarr.y.values)]\n        points = [transform(transformer.transform, point) for point in points]\n        return abs(points[1].x - points[0].x)\n\n    @staticmethod\n    def get_lat_lon_array(inarr: xr.DataArray, epsg: int) -> xr.DataArray:\n        \"\"\"Create latitude/longitude array from coordinates.\"\"\"\n        lon, lat = np.meshgrid(inarr.x.values, inarr.y.values)\n\n        if epsg != 4326:\n            transformer = Transformer.from_crs(epsg, 4326, always_xy=True)\n            lon, lat = transformer.transform(lon, lat)\n\n        latlon = np.stack([lat, lon])\n        return xr.DataArray(\n            latlon,\n            dims=[\"bands\", \"y\", \"x\"],\n            coords={\n                \"bands\": [LAT_HARMONIZED_NAME, LON_HARMONIZED_NAME],\n                \"y\": inarr.y,\n                \"x\": inarr.x,\n            },\n        )\n\n\nclass DataPreprocessor:\n    \"\"\"Handles data preprocessing operations.\"\"\"\n\n    @staticmethod\n    def rescale_s1_backscatter(arr: xr.DataArray) -> xr.DataArray:\n        \"\"\"Rescale Sentinel-1 backscatter from uint16 to dB values.\"\"\"\n        s1_bands_present = [b for b in S1_BANDS if b in arr.bands.values]\n        if not s1_bands_present:\n            return arr\n\n        s1_data = arr.sel(bands=s1_bands_present).astype(np.float32)\n        DataPreprocessor._validate_s1_data(s1_data.values)\n\n        # Convert to power values then to dB\n        power_values = 20.0 * np.log10(s1_data.values) - 83.0\n        power_values = np.power(10, power_values / 10.0)\n        power_values[~np.isfinite(power_values)] = np.nan\n\n        db_values = 10.0 * np.log10(power_values)\n        arr.loc[dict(bands=s1_bands_present)] = db_values\n\n        return arr\n\n    @staticmethod\n    def _validate_s1_data(data: np.ndarray) -> None:\n        \"\"\"Validate S1 data meets preprocessing requirements.\"\"\"\n        if data.min() < 1 or data.max() > NODATA_VALUE:\n            raise ValueError(\n                \"S1 data should be uint16 format with values 1-65535. \"\n                \"Set 'rescale_s1' to False to disable scaling.\"\n            )\n\n\nclass PrestoFeatureExtractor:\n    \"\"\"Handles Presto feature extraction pipeline.\"\"\"\n\n    def __init__(self, parameters: Dict[str, Any]):\n        self.parameters = parameters\n\n    def extract(self, inarr: xr.DataArray, epsg: int) -> xr.DataArray:\n        \"\"\"Extract Presto features from input array.\"\"\"\n        if epsg is None:\n            raise ValueError(\"EPSG code required for Presto feature extraction\")\n\n        # ONLY check top level - no nested lookup\n        presto_model_url = self.parameters.get(\"presto_model_url\")\n        if not presto_model_url:\n            logger.error(\n                f\"Missing presto_model_url. Available keys: {list(self.parameters.keys())}\"\n            )\n            raise ValueError('Missing required parameter \"presto_model_url\"')\n\n        if len(inarr.t) != 12:\n            error_msg = (\n                f\"Presto requires exactly 12 timesteps, but got {len(inarr.t)}. \"\n                f\"Available timesteps: {inarr.t.values}. \"\n                f\"Patch coordinates - x: {inarr.x.values.tolist()}, y: {inarr.y.values.tolist()}\"\n            )\n            logger.error(error_msg)\n\n            # Return NaN array instead of crashing\n            return create_nan_output_array(\n                inarr, self.parameters[\"num_outputs\"], error_msg\n            )\n\n        inarr = self._preprocess_input(inarr)\n\n        if \"slope\" not in inarr.bands:\n            inarr = self._add_slope_band(inarr, epsg)\n\n        return self._run_presto_inference(inarr, epsg)\n\n    def _preprocess_input(self, inarr: xr.DataArray) -> xr.DataArray:\n        \"\"\"Preprocess input array for Presto.\"\"\"\n        inarr = inarr.transpose(\"bands\", \"t\", \"x\", \"y\")\n\n        # Harmonize band names\n        new_bands = [GFMAP_BAND_MAPPING.get(b.item(), b.item()) for b in inarr.bands]\n        inarr = inarr.assign_coords(bands=new_bands)\n\n        return inarr.fillna(NODATA_VALUE)\n\n    def _add_slope_band(self, inarr: xr.DataArray, epsg: int) -> xr.DataArray:\n        \"\"\"Compute and add slope band to array.\"\"\"\n        logger.warning(\"Slope band not found, computing...\")\n        resolution = CoordinateTransformer.get_resolution(inarr.isel(t=0), epsg)\n        elevation_data = inarr.sel(bands=\"COP-DEM\").isel(t=0).values\n\n        slope_array = SlopeCalculator.compute(resolution, elevation_data)\n        slope_da = (\n            xr.DataArray(\n                slope_array[None, :, :],\n                dims=(\"bands\", \"y\", \"x\"),\n                coords={\"bands\": [\"slope\"], \"y\": inarr.y, \"x\": inarr.x},\n            )\n            .expand_dims({\"t\": inarr.t})\n            .astype(\"float32\")\n        )\n\n        return xr.concat([inarr.astype(\"float32\"), slope_da], dim=\"bands\")\n\n    def _run_presto_inference(self, inarr: xr.DataArray, epsg: int) -> xr.DataArray:\n        \"\"\"Run Presto model inference with safe dependency handling.\"\"\"\n        # Dependencies are now handled by load_presto_weights_cached\n        import gc\n\n        import torch\n\n        _ensure_prometheo_dependencies()\n\n        presto_model_url = self.parameters[\"presto_model_url\"]\n\n        model = load_presto_weights_cached(presto_model_url)\n\n        # Import here to ensure dependencies are available\n        pooling_method = (\n            PoolingMethods.TIME  # type: ignore\n            if self.parameters.get(\"temporal_prediction\")\n            else PoolingMethods.GLOBAL  # type: ignore\n        )\n\n        logger.info(\"Running presto inference ...\")\n        try:\n            with torch.inference_mode():\n                features = run_model_inference(\n                    inarr,\n                    model,\n                    epsg=epsg,\n                    batch_size=self.parameters.get(\"batch_size\", 256),  # TODO optimize?\n                    pooling_method=pooling_method,\n                )  # type: ignore\n            logger.info(\"Inference completed.\")\n\n            if self.parameters.get(\"temporal_prediction\"):\n                features = self._select_temporal_features(features)\n            return features.transpose(\"bands\", \"y\", \"x\")\n\n        finally:\n            gc.collect()\n\n    def _select_temporal_features(self, features: xr.DataArray) -> xr.DataArray:\n        \"\"\"Select specific timestep from temporal features.\"\"\"\n        target_date = self.parameters.get(\"target_date\")\n\n        if target_date is None:\n            mid_idx = len(features.t) // 2\n            return features.isel(t=mid_idx)\n\n        target_dt = np.datetime64(target_date)\n        min_time, max_time = features.t.min().values, features.t.max().values\n\n        if target_dt < min_time or target_dt > max_time:\n            raise ValueError(\n                f\"Target date {target_date} outside feature range: {min_time} to {max_time}\"\n            )\n\n        return features.sel(t=target_dt, method=\"nearest\")\n\n\nclass ONNXClassifier:\n    \"\"\"Handles ONNX model inference for classification.\"\"\"\n\n    def __init__(self, parameters: Dict[str, Any]):\n        self.parameters = parameters\n\n    def predict(self, features: xr.DataArray) -> xr.DataArray:\n        \"\"\"Run classification prediction.\"\"\"\n        classifier_url = self.parameters.get(\"classifier_url\")\n        if not classifier_url:\n            logger.error(\n                f\"Missing classifier_url. Available keys: {list(self.parameters.keys())}\"\n            )\n            raise ValueError('Missing required parameter \"classifier_url\"')\n\n        session, lut = load_onnx_model_cached(classifier_url)\n        features_flat = self._prepare_features(features)\n\n        logger.info(\"Running ONNX model inference ...\")\n        predictions = self._run_inference(session, lut, features_flat)\n        logger.info(\"ONNX inference completed.\")\n\n        return self._reshape_predictions(predictions, features, lut)\n\n    def _prepare_features(self, features: xr.DataArray) -> np.ndarray:\n        \"\"\"Prepare features for inference.\"\"\"\n        return (\n            features.transpose(\"bands\", \"x\", \"y\")\n            .stack(xy=[\"x\", \"y\"])\n            .transpose()\n            .values\n        )\n\n    def _run_inference(\n        self, session: Any, lut: Dict, features: np.ndarray\n    ) -> np.ndarray:\n        \"\"\"Run ONNX model inference.\"\"\"\n        outputs = session.run(None, {\"features\": features})\n\n        labels = np.zeros(len(outputs[0]), dtype=np.uint16)\n        probabilities = np.zeros(len(outputs[0]), dtype=np.uint8)\n\n        for i, (label, prob) in enumerate(zip(outputs[0], outputs[1])):\n            labels[i] = lut[label]\n            probabilities[i] = int(round(prob[label] * 100))\n\n        class_probs = np.array(\n            [[prob[label] for label in lut.keys()] for prob in outputs[1]]\n        )\n        class_probs = (class_probs * 100).round().astype(np.uint8)\n\n        return np.hstack([labels[:, None], probabilities[:, None], class_probs]).T\n\n    def _reshape_predictions(\n        self, predictions: np.ndarray, original_features: xr.DataArray, lut: Dict\n    ) -> xr.DataArray:\n        \"\"\"Reshape predictions to match original spatial dimensions.\"\"\"\n        output_labels = get_output_labels(lut)\n        x_coords, y_coords = original_features.x.values, original_features.y.values\n\n        reshaped = predictions.reshape(\n            (len(output_labels), len(x_coords), len(y_coords))\n        )\n\n        return xr.DataArray(\n            reshaped,\n            dims=[\"bands\", \"x\", \"y\"],\n            coords={\"bands\": output_labels, \"x\": x_coords, \"y\": y_coords},\n        ).transpose(\"bands\", \"y\", \"x\")\n\n\nclass Postprocessor:\n    \"\"\"Handles postprocessing of classification results.\"\"\"\n\n    def __init__(self, parameters: Dict[str, Any], classifier_url: str):\n        self.parameters = parameters\n        self.classifier_url = classifier_url\n\n    def apply(self, inarr: xr.DataArray) -> xr.DataArray:\n        inarr = inarr.transpose(\n            \"bands\", \"y\", \"x\"\n        )  # Ensure correct dimension order for openEO backend\n\n        _, lookup_table = load_onnx_model_cached(self.classifier_url)\n\n        if self.parameters.get(\"method\") == \"smooth_probabilities\":\n            # Cast to float for more accurate gaussian smoothing\n            class_probabilities = (\n                inarr.isel(bands=slice(2, None)).astype(\"float32\") / 100.0\n            )\n\n            # Peform probability smoothing\n            class_probabilities = smooth_probabilities(\n                inarr.sel(bands=\"classification\"), class_probabilities\n            )\n\n            # Reclassify\n            new_labels = reclassify(\n                inarr.sel(bands=\"classification\"),\n                inarr.sel(bands=\"probability\"),\n                class_probabilities,\n            )\n\n            # Re-apply labels\n            class_labels = list(lookup_table.values())\n\n            # Create a final labels array with same dimensions as new_labels\n            final_labels = xr.full_like(new_labels, fill_value=65535)\n            for idx, label in enumerate(class_labels):\n                final_labels.loc[{\"bands\": \"classification\"}] = xr.where(\n                    new_labels.sel(bands=\"classification\") == idx,\n                    label,\n                    final_labels.sel(bands=\"classification\"),\n                )\n            new_labels.sel(bands=\"classification\").values = final_labels.sel(\n                bands=\"classification\"\n            ).values\n\n            # Append the per-class probabalities if required\n            if self.parameters.get(\"keep_class_probs\", False):\n                new_labels = xr.concat([new_labels, class_probabilities], dim=\"bands\")\n\n        elif self.parameters.get(\"method\") == \"majority_vote\":\n            kernel_size = self.parameters.get(\"kernel_size\", 5)\n\n            new_labels = majority_vote(\n                inarr.sel(bands=\"classification\"),\n                inarr.sel(bands=\"probability\"),\n                kernel_size=kernel_size,\n            )\n\n            # Append the per-class probabalities if required\n            if self.parameters.get(\"keep_class_probs\", False):\n                class_probabilities = inarr.isel(bands=slice(2, None))\n                new_labels = xr.concat([new_labels, class_probabilities], dim=\"bands\")\n\n        else:\n            raise ValueError(\n                f\"Unknown post-processing method: {self.parameters.get('method')}\"\n            )\n\n        new_labels = new_labels.transpose(\n            \"bands\", \"y\", \"x\"\n        )  # Ensure correct dimension order for openEO backend\n\n        return new_labels\n\n\n# =============================================================================\n# MAIN UDF FUNCTIONS\n# =============================================================================\n\n\ndef run_single_workflow(\n    input_array: xr.DataArray,\n    epsg: int,\n    parameters: Dict[str, Any],\n    mask: Optional[xr.DataArray] = None,\n) -> xr.DataArray:\n    \"\"\"Run a single classification workflow with optional masking.\"\"\"\n\n    # Preprocess data\n    if parameters[\"feature_parameters\"].get(\"rescale_s1\", True):\n        logger.info(\"Rescale s1 ...\")\n        input_array = DataPreprocessor.rescale_s1_backscatter(input_array)\n\n    # Extract features\n    logger.info(\"Extract Presto embeddings ...\")\n    feature_extractor = PrestoFeatureExtractor(parameters[\"feature_parameters\"])\n    features = feature_extractor.extract(input_array, epsg)\n    logger.info(\"Presto embedding extraction done.\")\n\n    # Classify\n    logger.info(\"Onnx classification ...\")\n    classifier = ONNXClassifier(parameters[\"classifier_parameters\"])\n    classes = classifier.predict(features)\n    logger.info(\"Onnx classification done.\")\n\n    # Postprocess\n    postprocess_parameters: Dict[str, Any] = parameters.get(\n        \"postprocess_parameters\", {}\n    )\n\n    if postprocess_parameters.get(\"enable\"):\n        logger.info(\"Postprocessing classification results ...\")\n        if postprocess_parameters.get(\"save_intermediate\"):\n            classes_raw = classes.assign_coords(\n                bands=[f\"raw_{b}\" for b in list(classes.bands.values)]\n            )\n        postprocessor = Postprocessor(\n            postprocess_parameters,\n            classifier_url=parameters.get(\"classifier_parameters\", {}).get(\n                \"classifier_url\"\n            ),\n        )\n\n        classes = postprocessor.apply(classes)\n        if postprocess_parameters.get(\"save_intermediate\"):\n            classes = xr.concat([classes, classes_raw], dim=\"bands\")\n        logger.info(\"Postprocessing done.\")\n\n    # Set masked areas to specific value\n    if mask is not None:\n        logger.info(\"`mask` provided, applying to classification results ...\")\n        classes = classes.where(mask, 254)  # 254 = non-cropland\n\n    return classes\n\n\ndef combine_results(\n    croptype_result: xr.DataArray, cropland_result: xr.DataArray\n) -> xr.DataArray:\n    \"\"\"Combine crop type results with ALL cropland classification bands.\"\"\"\n\n    # Rename cropland bands to avoid conflicts\n    cropland_bands_renamed = [\n        f\"cropland_{band}\" for band in cropland_result.bands.values\n    ]\n    cropland_result = cropland_result.assign_coords(bands=cropland_bands_renamed)\n\n    # Rename croptype bands for clarity\n    croptype_bands_renamed = [\n        f\"croptype_{band}\" for band in croptype_result.bands.values\n    ]\n    croptype_result = croptype_result.assign_coords(bands=croptype_bands_renamed)\n\n    # Combine all bands from both results\n    combined_bands = list(croptype_bands_renamed) + list(cropland_bands_renamed)\n    combined_data = np.concatenate(\n        [croptype_result.values, cropland_result.values], axis=0\n    )\n\n    result = xr.DataArray(\n        combined_data,\n        dims=[\"bands\", \"y\", \"x\"],\n        coords={\n            \"bands\": combined_bands,\n            \"y\": croptype_result.y,\n            \"x\": croptype_result.x,\n        },\n    )\n\n    return result\n\n\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\n    \"\"\"Main UDF entry point - expects cropland_params and croptype_params in context.\"\"\"\n\n    input_cube = udf_data.datacube_list[0]\n    parameters = udf_data.user_context.copy()\n\n    epsg = udf_data.proj[\"EPSG\"] if udf_data.proj else None\n    if epsg is None:\n        raise ValueError(\"EPSG code not found in projection information\")\n\n    # Prepare input array\n    input_array = input_cube.get_array().transpose(\"bands\", \"t\", \"y\", \"x\")\n\n    # Extract both parameter sets directly from context\n    cropland_params = parameters.get(\"cropland_params\", {})\n    croptype_params = parameters.get(\"croptype_params\", {})\n\n    # Check if we have both parameter sets for dual workflow\n    if cropland_params and croptype_params:\n        logger.info(\n            \"Running combined workflow: cropland masking + croptype mapping ...\"\n        )\n\n        # Run cropland classification - pass the FLAT parameters\n        logger.info(\"Running cropland classification ...\")\n        cropland_result = run_single_workflow(input_array, epsg, cropland_params)\n        logger.info(\"Cropland classification done.\")\n\n        # Extract cropland mask for masking the crop type classification\n        cropland_mask = cropland_result.sel(bands=\"classification\") > 0\n\n        # Run crop type classification with mask\n        logger.info(\"Running crop type classification ...\")\n        croptype_result = run_single_workflow(\n            input_array, epsg, croptype_params, cropland_mask\n        )\n        logger.info(\"Croptype classification done.\")\n\n        # Combine ALL bands from both results\n        result = combine_results(croptype_result, cropland_result)\n        result_cube = XarrayDataCube(result)\n\n    else:\n        # Single workflow (fallback to original behavior)\n        logger.info(\"Running single workflow ...\")\n        result = run_single_workflow(input_array, epsg, parameters)\n        result_cube = XarrayDataCube(result)\n\n    udf_data.datacube_list = [result_cube]\n\n    return udf_data\n\n\ndef apply_metadata(metadata, context: Dict) -> Any:\n    \"\"\"Update collection metadata for combined output with ALL bands.\n\n    Band naming logic summary (kept for mapping module resilience):\n    - Single workflow (either cropland OR croptype parameters only):\n        Base bands: classification, probability, probability_<class>\n        If save_intermediate: raw_<band> duplicates are appended.\n    - Combined workflow (both croptype_params & cropland_params):\n        Prefixed bands: croptype_<band> and cropland_<band>\n        If save_intermediate: croptype_raw_<band> and cropland_raw_<band> duplicates appended.\n\n    No renaming occurs here beyond prefixing for the combined workflow; logic in\n    mapping.py must therefore accept both prefixed and unprefixed forms.\n    \"\"\"\n    try:\n        # For dual workflow, combine band names from both models\n        if \"croptype_params\" in context and \"cropland_params\" in context:\n            # Get croptype band names\n            croptype_classifier_url = context[\"croptype_params\"][\n                \"classifier_parameters\"\n            ].get(\"classifier_url\")\n            if croptype_classifier_url:\n                _, croptype_lut = load_onnx_model_cached(croptype_classifier_url)\n                croptype_bands = [\n                    f\"croptype_{band}\" for band in get_output_labels(croptype_lut)\n                ]\n                if (\n                    context[\"croptype_params\"]\n                    .get(\"postprocess_parameters\", {})\n                    .get(\"save_intermediate\", False)\n                ):\n                    croptype_bands += [\n                        band.replace(\"croptype_\", \"croptype_raw_\")\n                        for band in croptype_bands\n                    ]\n            else:\n                raise ValueError(\"No croptype LUT found\")\n\n            # Get cropland band names\n            cropland_classifier_url = context[\"cropland_params\"][\n                \"classifier_parameters\"\n            ].get(\"classifier_url\")\n            if cropland_classifier_url:\n                _, cropland_lut = load_onnx_model_cached(cropland_classifier_url)\n                cropland_bands = [\n                    f\"cropland_{band}\" for band in get_output_labels(cropland_lut)\n                ]\n                if (\n                    context[\"cropland_params\"]\n                    .get(\"postprocess_parameters\", {})\n                    .get(\"save_intermediate\", False)\n                ):\n                    cropland_bands += [\n                        band.replace(\"cropland_\", \"cropland_raw_\")\n                        for band in cropland_bands\n                    ]\n            else:\n                raise ValueError(\"No cropland LUT found\")\n\n            output_labels = croptype_bands + cropland_bands\n\n        else:\n            # Single workflow\n            classifier_url = context[\"classifier_parameters\"].get(\"classifier_url\")\n            if classifier_url:\n                _, lut_sorted = load_onnx_model_cached(classifier_url)\n                output_labels = get_output_labels(lut_sorted)\n                if context.get(\"postprocess_parameters\", {}).get(\n                    \"save_intermediate\", False\n                ):\n                    output_labels += [f\"raw_{band}\" for band in output_labels]\n            else:\n                raise ValueError(\"No classifier URL found in context\")\n\n        return metadata.rename_labels(dimension=\"bands\", target=output_labels)\n\n    except Exception as e:\n        logger.warning(f\"Could not load model in metadata context: {e}\")\n        return metadata\n"
              },
              "result": true
            }
          }
        },
        "size": [
          {
            "dimension": "x",
            "unit": "px",
            "value": 128
          },
          {
            "dimension": "y",
            "unit": "px",
            "value": 128
          }
        ]
      }
    },
    "reducedimension3": {
      "process_id": "reduce_dimension",
      "arguments": {
        "data": {
          "from_node": "applyneighborhood1"
        },
        "dimension": "t",
        "reducer": {
          "process_graph": {
            "mean2": {
              "process_id": "mean",
              "arguments": {
                "data": {
                  "from_parameter": "data"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "apply5": {
      "process_id": "apply",
      "arguments": {
        "data": {
          "from_node": "reducedimension3"
        },
        "process": {
          "process_graph": {
            "linearscalerange5": {
              "process_id": "linear_scale_range",
              "arguments": {
                "inputMax": 65534,
                "inputMin": 0,
                "outputMax": 65534,
                "outputMin": 0,
                "x": {
                  "from_parameter": "x"
                }
              },
              "result": true
            }
          }
        }
      }
    },
    "saveresult1": {
      "process_id": "save_result",
      "arguments": {
        "data": {
          "from_node": "apply5"
        },
        "format": "GTiff",
        "options": {
          "filename_prefix": "worldcereal_crop_type_postprocessed"
        }
      },
      "result": true
    }
  },
  "id": "worldcereal_crop_type",
  "summary": "Crop type mapping using Sentinel-1, Sentinel-2, METEO and Copernicus-30 data",
  "description": "The ESA WorldCereal Crop Type Detector combines Sentinel-1 (SAR) and Sentinel-2 (optical) time series with meteorological inputs and in-situ observations to produce local to global 10 m crop-type maps, processed at scale via openEO within the Copernicus Data Space Ecosystem. It generates pixel-level embeddings using the Nasa Harvest' Presto geospatial foundation model and classifies them with a lightweight CatBoost model, with options for users to train or adapt the downstream classifier for their own crops and regions. It exports results as cloud-optimized GeoTIFFs for easy integration into GIS workflows.",
  "parameters": [
    {
      "name": "spatial_extent",
      "description": "Limits the data to process to the specified bounding box or polygons.\n\nFor raster data, the process loads the pixel into the data cube if the point\nat the pixel center intersects with the bounding box or any of the polygons\n(as defined in the Simple Features standard by the OGC).\n\nFor vector data, the process loads the geometry into the data cube if the geometry\nis fully within the bounding box or any of the polygons (as defined in the\nSimple Features standard by the OGC). Empty geometries may only be in the\ndata cube if no spatial extent has been provided.\n\nEmpty geometries are ignored.\n\nSet this parameter to null to set no limit for the spatial extent.",
      "schema": [
        {
          "title": "Bounding Box",
          "type": "object",
          "subtype": "bounding-box",
          "required": [
            "west",
            "south",
            "east",
            "north"
          ],
          "properties": {
            "west": {
              "description": "West (lower left corner, coordinate axis 1).",
              "type": "number"
            },
            "south": {
              "description": "South (lower left corner, coordinate axis 2).",
              "type": "number"
            },
            "east": {
              "description": "East (upper right corner, coordinate axis 1).",
              "type": "number"
            },
            "north": {
              "description": "North (upper right corner, coordinate axis 2).",
              "type": "number"
            },
            "base": {
              "description": "Base (optional, lower left corner, coordinate axis 3).",
              "type": [
                "number",
                "null"
              ],
              "default": null
            },
            "height": {
              "description": "Height (optional, upper right corner, coordinate axis 3).",
              "type": [
                "number",
                "null"
              ],
              "default": null
            },
            "crs": {
              "description": "Coordinate reference system of the extent, specified as as [EPSG code](http://www.epsg-registry.org/) or [WKT2 CRS string](http://docs.opengeospatial.org/is/18-010r7/18-010r7.html). Defaults to `4326` (EPSG code 4326) unless the client explicitly requests a different coordinate reference system.",
              "anyOf": [
                {
                  "title": "EPSG Code",
                  "type": "integer",
                  "subtype": "epsg-code",
                  "minimum": 1000,
                  "examples": [
                    3857
                  ]
                },
                {
                  "title": "WKT2",
                  "type": "string",
                  "subtype": "wkt2-definition"
                }
              ],
              "default": 4326
            }
          }
        },
        {
          "title": "Vector data cube",
          "description": "Limits the data cube to the bounding box of the given geometries in the vector data cube. For raster data, all pixels inside the bounding box that do not intersect with any of the polygons will be set to no data (`null`). Empty geometries are ignored.",
          "type": "object",
          "subtype": "datacube",
          "dimensions": [
            {
              "type": "geometry"
            }
          ]
        },
        {
          "title": "No filter",
          "description": "Don't filter spatially. All data is included in the data cube.",
          "type": "null"
        }
      ]
    },
    {
      "name": "temporal_extent",
      "description": "Temporal extent specified as two-element array with start and end date/date-time.",
      "schema": {
        "type": "array",
        "subtype": "temporal-interval",
        "uniqueItems": true,
        "minItems": 2,
        "maxItems": 2,
        "items": {
          "anyOf": [
            {
              "type": "string",
              "subtype": "date-time",
              "format": "date-time"
            },
            {
              "type": "string",
              "subtype": "date",
              "format": "date"
            },
            {
              "type": "null"
            }
          ]
        }
      }
    },
    {
      "name": "model_url",
      "description": "The URL of the trained ONNX model",
      "schema": {
        "type": "string"
      }
    },
    {
      "name": "orbit_state",
      "description": "The orbit state of the Sentinel-1 data. Can be either 'ASCENDING' or 'DESCENDING'. Defaults to 'DESCENDING'.",
      "schema": {
        "type": "string",
        "enum": [
          "ASCENDING",
          "DESCENDING"
        ]
      },
      "default": "DESCENDING",
      "optional": true
    },
    {
      "name": "postprocess_method",
      "description": "The postprocessing method to be used. Can be either 'majority_vote' or 'smooth_probabilities'. Defaults to 'smooth_probabilities'.",
      "schema": {
        "type": "string",
        "enum": [
          "majority_vote",
          "smooth_probabilities"
        ]
      },
      "default": "smooth_probabilities",
      "optional": true
    },
    {
      "name": "postprocess_kernel_size",
      "description": "The kernel size to be used for the postprocessing method. Only used if the postprocess_method is 'majority_vote'. Must be an odd integer no greater than 25. Defaults to 5.",
      "schema": {
        "type": "integer",
        "maximum": 25,
        "allOf": [
          {
            "not": {
              "multipleOf": 2
            }
          }
        ]
      },
      "default": 5,
      "optional": true
    }
  ],
  "default_job_options": {
    "driver-memory": "4g",
    "executor-memory": "2g",
    "executor-memoryOverhead": "3g",
    "python-memory": "disable",
    "soft-errors": 0.1,
    "udf-dependency-archives": [
      "https://s3.waw3-1.cloudferro.com/swift/v1/project_dependencies/onnx_deps_python311.zip#onnx_deps",
      "https://s3.waw3-1.cloudferro.com/swift/v1/project_dependencies/torch_deps_python311.zip#feature_deps"
    ]
  }
}