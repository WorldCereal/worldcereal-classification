{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4368b61a",
   "metadata": {},
   "source": [
    "# WorldCereal Embeddings Demo\n",
    "\n",
    "This notebook demonstrates how to generate spatio-temporal WorldCereal embeddings through the openEO backend and visualize the resulting multiband GeoTIFF. The pretrained geospatial model under the hood is NASA Harvest's Presto model, finetuned on WorldCereal reference data.\n",
    "\n",
    "**Workflow overview**:\n",
    "1. Configure parameters for the embeddings generation.\n",
    "2. Interactively select an Area of Interest (AOI) and processing date range.\n",
    "3. Build and run the openEO process graph to create an asynchronous job.\n",
    "4. Download the resulting embeddings GeoTIFF.\n",
    "5. Inspect and visualize the embeddings (band statistics, PCA projection, pseudo-color rendering).\n",
    "\n",
    "Use this as a starting point to explore model outputs or integrate embeddings into downstream ML tasks.\n",
    "\n",
    "> Tip: Keep your AOI modest in size initially to reduce processing time. Expand once the workflow is validated.\n",
    "\n",
    "> Note: Maximum area for this processing is limited as larger areas may run into computational issues. If you want to run this at scale, openEO's job manager will be required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912109df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core imports for building the WorldCereal embeddings process graph\n",
    "from worldcereal.job import create_embeddings_process_graph\n",
    "from worldcereal.parameters import EmbeddingsParameters\n",
    "\n",
    "# Utility/visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Raster I/O for visualization after download\n",
    "import rasterio\n",
    "\n",
    "OUTPUT_PATH = Path(\"worldcereal_embeddings.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d6973f9",
   "metadata": {},
   "source": [
    "## 1. Configure Embedding Parameters\n",
    "\n",
    "Adjust any parameters below to control the embedding generation. You can override (for example) the model URL or other processing options if exposed by the API. After instantiation we print the effective configuration for transparency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f29fb4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate embedding parameters (override defaults by passing arguments)\n",
    "# Example: EmbeddingsParameters(presto_model_url=\"s3://bucket/custom_model.onnx\")\n",
    "embedding_params = EmbeddingsParameters()\n",
    "\n",
    "# Display the resolved parameters (assumes dataclass / attrs-like repr)\n",
    "print(\"Embedding Parameters:\\n\", embedding_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a4e8b",
   "metadata": {},
   "source": [
    "## 2. Select Area of Interest & Time Range\n",
    "\n",
    "Use the interactive map below to draw/select your AOI. Then use the date slider to choose the processing period. Keep ranges short at first to speed up processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7287920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "# Launch interactive map (draw/select AOI)\n",
    "map = ui_map(area_limit=400)  # To keep processing as a demo manageable\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257af771",
   "metadata": {},
   "source": [
    "A key feature of WorldCereal is its dynamic nature to compute embeddings (and infer downstream classes) on dynamically chosen temporal windows, aligned to the seasonality of interest. We compute the embeddings based on a one-year time range that can be chosen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "869d1507",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "# Create interactive date range selector widget\n",
    "slider = date_slider()\n",
    "slider"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2e8d16",
   "metadata": {},
   "source": [
    "### Capture Selected Extent & Period\n",
    "Run the cell below after finalizing the AOI and dates to capture them for the openEO job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376ebccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve AOI extent and date range\n",
    "extent = map.get_extent()\n",
    "processing_period = slider.get_selected_dates()\n",
    "\n",
    "print(\"Extent (bbox or geometry):\", extent)\n",
    "print(\"Processing period:\", processing_period)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f34893",
   "metadata": {},
   "source": [
    "## 3. Run openEO Embeddings Job\n",
    "This step builds the embeddings process graph, submits it as a job, waits for completion, and downloads the result as a multiband GeoTIFF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f28c1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.job import INFERENCE_JOB_OPTIONS\n",
    "\n",
    "scale_uint16 = True  # If False, the original Float32 values are returned\n",
    "\n",
    "# Create WorldCereal Embeddings openEO process graph\n",
    "print(\"Building process graph...\")\n",
    "inference_result = create_embeddings_process_graph(\n",
    "    spatial_extent=extent,\n",
    "    temporal_extent=processing_period,\n",
    "    embeddings_parameters=embedding_params,\n",
    "    scale_uint16=scale_uint16,\n",
    ")\n",
    "\n",
    "# Create the job\n",
    "print(\"Creating job...\")\n",
    "job = inference_result.create_job(\n",
    "    title=\"WorldCereal Embeddings Map\",\n",
    "    job_options=INFERENCE_JOB_OPTIONS,\n",
    ")\n",
    "\n",
    "# Start and wait\n",
    "print(\"Starting job (this may take a while depending on AOI & cluster load)...\")\n",
    "job.start_and_wait()\n",
    "print(\"Job finished. Retrieving results...\")\n",
    "\n",
    "# Download first GeoTIFF asset\n",
    "for asset in job.get_results().get_assets():\n",
    "    if asset.metadata.get(\"type\", \"\").startswith(\"image/tiff\"):\n",
    "        print(f\"Downloading asset to {OUTPUT_PATH} ...\")\n",
    "        asset.download(str(OUTPUT_PATH))\n",
    "        break\n",
    "else:\n",
    "    raise RuntimeError(\"No GeoTIFF asset found in job results.\")\n",
    "\n",
    "if not OUTPUT_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Expected output not found: {OUTPUT_PATH}\")\n",
    "print(\"Download complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404af968",
   "metadata": {},
   "source": [
    "## 4. Inspect & Visualize Embeddings\n",
    "We now load the downloaded multiband embeddings GeoTIFF and produce:\n",
    "1. Per-band value distribution (histogram)\n",
    "2. PCA projection (first 3 components) rendered as an RGB image\n",
    "3. Optional pseudo-color rendering from selected bands\n",
    "\n",
    "Note: If data were scaled to UInt16, we scale back first to the original Float32 values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8a4547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the embeddings raster and inspect basic metadata\n",
    "with rasterio.open(OUTPUT_PATH) as ds:\n",
    "    data = ds.read()  # shape: (bands, height, width)\n",
    "    profile = ds.profile\n",
    "\n",
    "# Go back to original scale if needed\n",
    "if scale_uint16:\n",
    "    # Empirically determined scaling factors for Presto-based WorldCereal embeddings\n",
    "    offset = -6\n",
    "    scale = 0.0002\n",
    "    data = data.astype(np.float32) * scale + offset\n",
    "\n",
    "print(\"Raster profile:\\n\", profile)\n",
    "print(\"Data shape (bands, height, width):\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7549a352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms for first few embeddings\n",
    "bands_to_plot = min(6, data.shape[0])\n",
    "fig, axes = plt.subplots(2, (bands_to_plot+1)//2, figsize=(12, 6))\n",
    "axes = axes.flatten()\n",
    "for i in range(bands_to_plot):\n",
    "    arr = data[i].ravel()\n",
    "    sample = arr if arr.size < 300_000 else np.random.choice(arr, 300_000, replace=False)\n",
    "    axes[i].hist(sample, bins=50, color='steelblue', alpha=0.8)\n",
    "    axes[i].set_title(f'Embedding dimension {i+1}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb213613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incremental / chunked PCA to avoid memory blow-ups\n",
    "import numpy as np\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "bands, h, w = data.shape\n",
    "flat = data.reshape(bands, -1).T  # (pixels, bands)\n",
    "\n",
    "# Configuration\n",
    "n_components = 3\n",
    "fit_sample_max = 400_000   # subset used to fit\n",
    "chunk_size = 50_000        # number of pixels processed per partial_fit / transform\n",
    "\n",
    "n_pixels = flat.shape[0]\n",
    "idx_all = np.arange(n_pixels)\n",
    "\n",
    "# Select subset for fitting (random) to speed up & reduce RAM\n",
    "if n_pixels > fit_sample_max:\n",
    "    fit_idx = np.random.choice(n_pixels, fit_sample_max, replace=False)\n",
    "else:\n",
    "    fit_idx = idx_all\n",
    "\n",
    "ipca = IncrementalPCA(n_components=n_components)\n",
    "\n",
    "# Pass 1: partial_fit on chunks of the fit subset\n",
    "for start in range(0, fit_idx.size, chunk_size):\n",
    "    end = start + chunk_size\n",
    "    batch_idx = fit_idx[start:end]\n",
    "    ipca.partial_fit(flat[batch_idx])\n",
    "\n",
    "print('Explained variance ratio (incremental):', ipca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cd8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass 2: transform entire image in chunks (streaming) and track per-component min/max\n",
    "components_full = np.empty((n_pixels, ipca.n_components), dtype=np.float32)\n",
    "comp_min = np.full(ipca.n_components, np.inf, dtype=np.float64)\n",
    "comp_max = np.full(ipca.n_components, -np.inf, dtype=np.float64)\n",
    "\n",
    "for start in range(0, n_pixels, chunk_size):\n",
    "    end = min(start + chunk_size, n_pixels)\n",
    "    transformed = ipca.transform(flat[start:end])\n",
    "    components_full[start:end] = transformed\n",
    "    # Update running min/max\n",
    "    comp_min = np.minimum(comp_min, transformed.min(axis=0))\n",
    "    comp_max = np.maximum(comp_max, transformed.max(axis=0))\n",
    "\n",
    "# Reshape to (h, w, 3)\n",
    "comp_img = components_full.reshape(h, w, ipca.n_components)\n",
    "\n",
    "# Normalize using collected min/max (avoid second full pass)\n",
    "rng = (comp_max - comp_min)\n",
    "rng[rng == 0] = 1\n",
    "comp_norm = (comp_img - comp_min) / rng\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(comp_norm[..., :3])\n",
    "plt.title('Incremental PCA Components 1-3 (as RGB)')\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "print('Final component ranges:', list(zip(comp_min, comp_max)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c1ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pseudo-RGB from three arbitrary embedding bands\n",
    "pseudo_indices = (0, 1, 2) if data.shape[0] >= 3 else None\n",
    "if pseudo_indices:\n",
    "    pseudo = data[list(pseudo_indices), :, :].astype(float)\n",
    "    # Normalize each selected band individually\n",
    "    for i in range(3):\n",
    "        b = pseudo[i]\n",
    "        pseudo[i] = (b - b.min()) / (b.max() - b.min() + 1e-9)\n",
    "    rgb = np.transpose(pseudo, (1, 2, 0))\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(rgb)\n",
    "    plt.title(f'Pseudo RGB Bands {pseudo_indices}')\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Not enough bands for pseudo-RGB composite.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427c1eca",
   "metadata": {},
   "source": [
    "## 5. Next Steps\n",
    "You can now:\n",
    "- Feed embeddings into clustering or dimensionality reduction for pattern discovery.\n",
    "- Sample embeddings at reference points for model training.\n",
    "- Compare embeddings across seasons or AOIs.\n",
    "- ..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
