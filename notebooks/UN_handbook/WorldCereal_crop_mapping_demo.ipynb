{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2783261",
   "metadata": {},
   "source": [
    "# UN Handbook on Remote Sensing for Agricultural Statistics\n",
    "## Chapter 6: WorldCereal â€“ A Global Effort for Crop Mapping\n",
    "<hr style=\"border:0; border-top:1px solid #ccc; margin:12px 0 20px;\">\n",
    "\n",
    "<div style=\"margin-left:120px; display:flex; align-items:center;\">\n",
    "  <img src=\"../resources/worldcereal_logo.jpg\" width=\"280\" alt=\"WorldCereal\" style=\"vertical-align:middle; margin-right:60px;\">\n",
    "  <img src=\"../resources/ESA_logo.jpg\" height=\"120\" alt=\"ESA\" style=\"vertical-align:middle;\">\n",
    "</div>\n",
    "<br>\n",
    "<br>\n",
    "<div style=\"display:flex; justify-content:left; margin-bottom:30px;\">\n",
    "  <div style=\"font-size:17px; line-height:1.3; text-align:left;\">\n",
    "    <strong>Authors:</strong><br>\n",
    "    Jeroen Degerickx, Christina Butsko, Kristof Van Tricht<br>\n",
    "    VITO Remote Sensing, Boeretang 200, 2400 Mol, BELGIUM<br>\n",
    "    <br>\n",
    "    <img src=\"../resources/Vito_RemoteSensing.png\" height=\"60\" alt=\"VITO Remote Sensing\" style=\"margin-left:50px;\">\n",
    "    <hr style=\"border:0; border-top:1px solid #ddd; margin:12px 0;\">\n",
    "    \n",
    "  </div>\n",
    "</div>\n",
    "\n",
    "\n",
    "# Crop mapping demo notebook\n",
    "\n",
    "In this notebook we demonstrate how robust crop classification models are built using the WorldCereal crop mapping system.<br>\n",
    "Want to try this for a custom area, season and crops of interest? Check out our full [crop type demo notebook](https://github.com/WorldCereal/worldcereal-classification/tree/main/notebooks/worldcereal_custom_croptype.ipynb).\n",
    "\n",
    "We will be training and comparing two multi-class crop type models:\n",
    "- the first one will be entirely based on data retrieved from the national parcel declaration system for France, for the years 2018, 2019, 2020 and 2022.<br>\n",
    "\n",
    "We will test how this model performs on the same country, but in a year for which we did not include training data in the model, i.e. 2021. Additionally, we will also apply the same model to another country, Latvia, also for 2021.\n",
    "\n",
    "- for the second model we will add a bit of local Latvian training data to the initial model to assess the impact of local training data on model performance.\n",
    "\n",
    "\n",
    "All data required for this notebook is available via a public URL and will be downloaded automatically the first time you run this notebook.<br>\n",
    "Interested to learn how this data was retrieved? Check out the associated [Data preparation notebook](https://github.com/WorldCereal/worldcereal-classification/tree/main/notebooks/UN_handbook/0_data_preparation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c945e23",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Gather and prepare the training data](###-1.-Gather-and-prepare-the-training-data)\n",
    "- [2. Computing training features using Presto](###-2.-Computing-training-features-using-Presto)\n",
    "- [3. Train and test classifiers](###-3.-Train-and-test-classifiers)\n",
    "- [4. Generate maps](###-4.-Generate-maps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbafb5b6",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "#### Option 1: Run on Terrascope\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment.\n",
    "Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">When you click the button, you will be prompted with \"Server Options\".<br>\n",
    "Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident?<br>\n",
    "Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2UN_handbook%2WorldCereal_crop_mapping_demo&branch=main\"><img src=\"https://img.shields.io/badge/Run%20on-Terrascope-brightgreen\" alt=\"Run on Terrascope\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> <br>\n",
    "Every time you click the above link, the latest version of the notebook will be fetched, potentially leading to conflicts with changes you have made yourself.<br>\n",
    "To avoid such code conflicts, we recommend you to make a copy of the notebook and make changes only in your copied version.\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Option 2: Install Locally\n",
    "\n",
    "If you prefer to install the package locally, you can create the WorldCereal environment using **Conda** or **pip**.\n",
    "\n",
    "First clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/WorldCereal/worldcereal-classification.git\n",
    "cd worldcereal-classification\n",
    "```\n",
    "Next, install the package locally:\n",
    "- for Conda: `conda env create -f environment.yml`\n",
    "- for Pip: `pip install .[train,notebooks]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3e5ab9",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "Make sure all utilities can be accessed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbbbd6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dirctory to sys.path\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772593ea",
   "metadata": {},
   "source": [
    "Set some variables we'll be needing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a192db7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Definition of crop types we will be using for this demo\n",
    "class_mappings_csv = Path('./resources/crop_type_class_mappings.csv')\n",
    "class_mappings = pd.read_csv(class_mappings_csv, sep=\";\", header=0)\n",
    "classes = class_mappings['finetune_class'].dropna().unique().tolist()\n",
    "print(classes)\n",
    "\n",
    "# Folder where data for this exercise is stored:\n",
    "datadir = Path('./data')\n",
    "datadir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9146719d",
   "metadata": {},
   "source": [
    "### 1. Prepare the training data\n",
    "\n",
    "Let's download our training data and explore the distribution of samples across years:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1974646",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets from France, used for training the first model:\n",
    "path_ds_france = datadir / \"extractions\" / \"extractions_train.parquet\"\n",
    "path_ds_france.parent.mkdir(exist_ok=True, parents=True)\n",
    "if not path_ds_france.exists():\n",
    "    print(f\"Downloading training data to {path_ds_france}...\")\n",
    "    remote_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/extractions_train.parquet\"\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(remote_url, path_ds_france)\n",
    "extractions_train = pd.read_parquet(path_ds_france)\n",
    "samples = extractions_train.drop_duplicates(subset=['sample_id'])\n",
    "print('Distribution of samples across years:')\n",
    "print(samples['ref_id'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bbcf9f2",
   "metadata": {},
   "source": [
    "Now we quickly have a look at the content of the data and plot the NDVI time series of 5 random samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f68925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import get_band_statistics, visualize_timeseries\n",
    "\n",
    "subset = extractions_train[extractions_train['ref_id'] == '2019_FRA_LPIS_POLY_110']\n",
    "\n",
    "# Check band statistics\n",
    "band_stats = get_band_statistics(subset)\n",
    "\n",
    "# Visualize timeseries for a few samples (5 by default)\n",
    "visualize_timeseries(subset, nsamples=5, crop_label_attr='finetune_class')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342a592",
   "metadata": {},
   "source": [
    "You probably noticed that the data is composed of time series of Sentinel-2 optical imagery, Sentinel-1 radar imagery, temperature, precipitation, elevation and slope.\n",
    "\n",
    "Also download the other data:\n",
    "- additional training data for Latvia\n",
    "- independent test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b322ff37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset from Latvia, used for training the second model:\n",
    "path_ds_latvia = datadir / \"extractions\" / \"extractions_train_lva.parquet\"\n",
    "path_ds_latvia.parent.mkdir(exist_ok=True, parents=True)\n",
    "if not path_ds_latvia.exists():\n",
    "    print(f\"Downloading training data to {path_ds_latvia}...\")\n",
    "    remote_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/extractions_train_lva.parquet\"\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(remote_url, path_ds_latvia)\n",
    "extractions_train_lva = pd.read_parquet(path_ds_latvia)\n",
    "samples = extractions_train_lva.drop_duplicates(subset=['sample_id'])\n",
    "print('Distribution of samples across years:')\n",
    "print(samples['ref_id'].value_counts())\n",
    "\n",
    "# Test datasets, used for assessing models' performance:\n",
    "path_ds_test = datadir / \"extractions\" / \"extractions_test.parquet\"\n",
    "path_ds_test.parent.mkdir(exist_ok=True, parents=True)\n",
    "if not path_ds_test.exists():\n",
    "    print(f\"Downloading test data to {path_ds_test}...\")\n",
    "    remote_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/extractions_test.parquet\"\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(remote_url, path_ds_test)\n",
    "extractions_test = pd.read_parquet(path_ds_test)\n",
    "samples = extractions_test.drop_duplicates(subset=['sample_id'])\n",
    "print('Distribution of samples across datasets:')\n",
    "print(samples['ref_id'].value_counts())\n",
    "print('Example data:')\n",
    "print(extractions_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7a2a73",
   "metadata": {},
   "source": [
    "Originally these training data are composed of multiple lines of data per sample, one line for each date for which satellite data has been extracted.\n",
    "\n",
    "In the next cell, we convert this to a more condensed format and ensure that any sample with an observation date outside the growing season is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32548ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo_gfmap import TemporalContext\n",
    "from notebook_utils.extractions import map_classes\n",
    "from notebook_utils.classifier import align_extractions_to_season\n",
    "\n",
    "# In Europe, the center of the main spring season is situated around the month of June.\n",
    "# WorldCereal models always require 12 months of input data.\n",
    "# To inform the system about the season of interest, \n",
    "# we make sure the season center (June) is nicely aligned with \n",
    "# the center of the 12 month time period we define:\n",
    "season = TemporalContext('2017-01-01', '2017-12-31')\n",
    "\n",
    "# Align the data with the selected season\n",
    "train_df = align_extractions_to_season(extractions_train, season)\n",
    "train_lva_df = align_extractions_to_season(extractions_train_lva, season)\n",
    "test_df = align_extractions_to_season(extractions_test, season)\n",
    "\n",
    "# Now map the WorldCereal harmonized class labels to our classes of interest:\n",
    "train_df = map_classes(train_df, class_mappings_csv)\n",
    "train_lva_df = map_classes(train_lva_df, class_mappings_csv)\n",
    "test_df = map_classes(test_df, class_mappings_csv)\n",
    "\n",
    "print('Distribution of training data across crop types:')\n",
    "print(train_df['finetune_class'].value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c2bb16",
   "metadata": {},
   "source": [
    "Before proceeding with model training, let's group some classes together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9d2e819",
   "metadata": {},
   "outputs": [],
   "source": [
    "combine_classes = {'winter_cereal': ['wheat', 'barley', 'rye'],\n",
    "                   'spring_cereal': ['spring_wheat', 'spring_barley', 'spring_rye'],\n",
    "                   'vegetables': ['vegetables_fruits', 'potatoes', 'beet'],\n",
    "                   'other_crops': ['fibre_crops', 'dry_pulses_legumes', 'grass_fodder_crops'],\n",
    "                   }\n",
    "\n",
    "train_df['downstream_class'] = train_df['finetune_class']\n",
    "train_lva_df['downstream_class'] = train_lva_df['finetune_class']\n",
    "test_df['downstream_class'] = test_df['finetune_class']\n",
    "\n",
    "for new_class, old_classes in combine_classes.items():\n",
    "    train_df.loc[train_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "    test_df.loc[test_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "    train_lva_df.loc[train_lva_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "    \n",
    "train_df['downstream_class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549970c3",
   "metadata": {},
   "source": [
    "### 2. Computing training features using Presto\n",
    "\n",
    "We do not feed entire satellite time series directly into a classification model. Instead, we unleash the power of a pre-trained geospatial foundation model (Presto) to summarize all information contained within the time series to a condensed and relevant set of 128 embeddings, specifically tuned for the task of crop mapping.<br>\n",
    "<br>\n",
    "For the training data, we apply additional data augmentation techniques:\n",
    "- temporal jittering: introduce random backward or forward displacements in the time series to make the resulting model more robust against slight shifts in variation in seasonality (increasing temporal robustness).\n",
    "- mask on training: applies sensor masking augmentations (e.g. simulating S1/S2 dropouts, introducing random additional clouds, removal of features) to make the model more robust against missing satellite and ancillary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcff12cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import compute_presto_embeddings\n",
    "\n",
    "train_embeddings_df = compute_presto_embeddings(train_df,\n",
    "    augment=True,  # apply temporal jittering\n",
    "    mask_on_training=True,  # apply sensor masking to training split\n",
    "    repeats=3  # number of times to augment each training sample\n",
    ")\n",
    "train_lva_embeddings_df = compute_presto_embeddings(train_lva_df,\n",
    "    augment=True,  # apply temporal jittering\n",
    "    mask_on_training=True,  # apply sensor masking to training split\n",
    "    repeats=3  # number of times to augment each training sample\n",
    ")\n",
    "test_embeddings_df = compute_presto_embeddings(test_df,\n",
    "    augment=False,  # apply temporal jittering\n",
    "    mask_on_training=False,  # apply sensor masking to training split\n",
    "    repeats=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846b1f2f",
   "metadata": {},
   "source": [
    "### 3. Train and test classifiers\n",
    "\n",
    "Let's train our first model, purely based on French training data (`train_embeddings_df`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f1b73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "model_1, report_1, cm_tmp = train_classifier(\n",
    "    train_embeddings_df, \n",
    "    balance_classes=True, \n",
    "    show_confusion_matrix='relative',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36959307",
   "metadata": {},
   "source": [
    "We check the performance on our independent test sets:\n",
    "1. France 2021\n",
    "2. Latvia 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4005656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check performance on independent test sets\n",
    "from notebook_utils.classifier import apply_classifier\n",
    "\n",
    "# We split the test set according to dataset\n",
    "test_df_FR = test_embeddings_df.loc[test_embeddings_df['ref_id'].str.contains('_FRA_')]\n",
    "test_df_LVA = test_embeddings_df.loc[test_embeddings_df['ref_id'].str.contains('_LVA_')]\n",
    "\n",
    "report_val_FR, cm_val_FR, pred = apply_classifier(\n",
    "    test_df_FR,\n",
    "    model_1,\n",
    "    show_confusion_matrix='relative',\n",
    "    print_report=True,\n",
    ")\n",
    "\n",
    "report_val_LVA, cm_val_LVA, pred = apply_classifier(\n",
    "    test_df_LVA,\n",
    "    model_1,\n",
    "    show_confusion_matrix='relative',\n",
    "    print_report=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f54f811",
   "metadata": {},
   "source": [
    "We notice very good performance on the French data (average f1 score of 0.82, which is nearly the same as the one obtained on the training data - 0.84). This effectively demonstrates temporal robustness of our model: as long as we train on multiple years, it is safe to apply the model to an unseen year in the same region.<br>\n",
    "\n",
    "At the same time, we notice significantly worse performance on the Latvian data (average f1 score of 0.66, with main confusion between vegetables and other crops).\n",
    "\n",
    "Transferring a model from one region to another is quite risky, as dominant crop types, cropping patterns, farming practices and environmental conditions can differ substantially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791c3208",
   "metadata": {},
   "source": [
    "Now let's train a second model using a combination of French and Latvian training data and immediately apply it to the Latvian test dataset.\n",
    "\n",
    "In the first line of the code, you can control how many samples from the Latvian data get randomly added to the French data...\n",
    "(recall we originally had 1000 samples, but we artifially increased this to 3000 due to augmentation, so you can pick any number between 1 and 3000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e223b016",
   "metadata": {},
   "outputs": [],
   "source": [
    "latvian_data = train_lva_embeddings_df.sample(1000)\n",
    "combined_embeddings_df = pd.concat([train_embeddings_df, latvian_data], ignore_index=True)\n",
    "\n",
    "model_2, report_2, cm_tmp = train_classifier(\n",
    "    combined_embeddings_df, \n",
    "    balance_classes=True, \n",
    "    show_confusion_matrix=None,\n",
    ")\n",
    "\n",
    "report_val_LVA, cm_val_LVA, pred = apply_classifier(\n",
    "    test_df_LVA,\n",
    "    model_2,\n",
    "    show_confusion_matrix='relative',\n",
    "    print_report=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11223eb5",
   "metadata": {},
   "source": [
    "Adding just 500 samples raised f1 score from 0.66 to 0.73.\n",
    "Adding 1000 resulted in f1 score of 0.75.\n",
    "Adding all available Latvian data increases performance further to 0.79!\n",
    "\n",
    "This clearly demonstrates that gradually adding more local training data significantly boosts the classification model's performance!\n",
    "\n",
    "Let's have a look at the composition of the training data again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c551dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_embeddings_df.ref_id.value_counts())\n",
    "pct = len(latvian_data) / len(combined_embeddings_df) * 100\n",
    "print(f'Total number of samples: {len(combined_embeddings_df)}')\n",
    "print(f'Percentage of Latvian samples: {pct:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17881ab2",
   "metadata": {},
   "source": [
    "### 4. Generate maps\n",
    "\n",
    "Now that we have a model, let's apply it to some test patches and see how the resulting maps look like.\n",
    "\n",
    "To apply our model, we need to deploy our model to your private bucket on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/). Make sure to register for a free account if you haven't done so.\n",
    "\n",
    "Upon execution of the next cell, click the link below the cell to authenticate with your credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7de41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "\n",
    "modelname = 'France_multiyear_Latvia'\n",
    "model_url = deploy_model(cdse_connection(), model_2, pattern=modelname)\n",
    "print(f\"Your model can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32aa3a97",
   "metadata": {},
   "source": [
    "We have prepared one test patch in France and one test patch in Latvia for you to apply the model to.<br>\n",
    "Upon execution of the next cell, these test patches will be automatically downloaded to the \"maps\" subdirectory.<br>\n",
    "\n",
    "Once downloaded, the `run_full_croptype_inference_workflow` will do the following:\n",
    "1. compute Presto embeddings finetuned for the task of land cover mapping for each pixel in the patch\n",
    "2. apply the default global WorldCereal cropland model to these embeddings, resulting in a distinction between temporary crops and other land cover\n",
    "3. compute Presto embeddings finetuned for the task of crop type mapping for each pixel in the patch\n",
    "4. apply your custom crop type model you just trained to generate a crop type map\n",
    "5. mask the crop type product using the cropland mask generated in step 2.\n",
    "\n",
    "Test patches are approx. 10 x 10 km in size. The full pipeline for one patch takes around 10-15 mins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ae79bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.local_inference import run_full_croptype_inference_workflow\n",
    "\n",
    "test_sites = [\n",
    "    # 'france', \n",
    "    'latvia']\n",
    "\n",
    "outdir = Path('./maps')\n",
    "outdir.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "inputs = {}\n",
    "for site in test_sites:\n",
    "    site_dir = outdir / site\n",
    "    site_dir.mkdir(exist_ok=True, parents=True)\n",
    "    input_path = site_dir / 'preprocessed_inputs.nc'\n",
    "    if not input_path.exists():\n",
    "        print(f\"Downloading preprocessed inputs to {input_path}...\")\n",
    "        remote_url = f\"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/{site}_preprocessed-inputs_2021-01-01_2021-12-31.nc\"\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(remote_url, input_path)\n",
    "    inputs[site] = input_path\n",
    "\n",
    "output_paths = run_full_croptype_inference_workflow(inputs, outdir, model_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93fb29fa",
   "metadata": {},
   "source": [
    "The resulting maps are automatically stored in the \"maps\" subdirectory.<br>\n",
    "You can inspect the resulting maps in QGIS, or use the following cell for a quick visualization.<br>\n",
    "\n",
    "The resulting crop type raster will contain multiple bands:\n",
    "- Band 1: \"classification\": The classification label of the pixel.\n",
    "- Band 2: \"confidence\": The class-specific probablity of the winning class.\n",
    "- Band 3 and beyond: \"probability_xxx\": Class-specific probablities. The \"xxx\" indicates the associated class.\n",
    "\n",
    "Upon running the next cell, two additional GeoTiff files will be generated, one showing the classification and the other showing the probability of the winning class. These maps receive standardized styling, enabling quick visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_product\n",
    "from worldcereal.utils.models import load_model_lut\n",
    "\n",
    "site = 'latvia'\n",
    "# site = 'france'\n",
    "croptype_path = output_paths[site]['croptype']\n",
    "\n",
    "lut = load_model_lut(model_url)\n",
    "# the look-up table is needed to interprete the raster values of the classification band...\n",
    "print(lut)\n",
    "\n",
    "# Visualize the product here using matplotlib...\n",
    "visualize_product(croptype_path, product='croptype', lut=lut)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f25ba307",
   "metadata": {},
   "source": [
    "To give you an idea about the actual crops in both regions, here is a screenshot of the two areas with crop types colored according to the following scheme:\n",
    "- winter cereals = darkish brown\n",
    "- spring cereals = orange\n",
    "- maize = yellow\n",
    "- soybean = red\n",
    "- rapeseed = cyan\n",
    "- potatoes/beet/vegetables = blue\n",
    "- sunflower = purple\n",
    "- other crops = pink\n",
    "- grassland & permanent crops = green\n",
    "\n",
    "FRANCE:\n",
    "\n",
    "<img src=\"./resources/france_validation.png\" alt=\"France crop type validation\" width=\"600\">\n",
    "\n",
    "LATVIA:\n",
    "\n",
    "<img src=\"./resources/latvia_validation.png\" alt=\"Latvia crop type validation\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4761deb",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this demo!\n",
    "\n",
    "Want to know more after this session?\n",
    "\n",
    "- Check the [WorldCereal documentation](https://worldcereal.github.io/worldcereal-documentation/)\n",
    "- Ask questions on our [user forum](https://forum.esa-worldcereal.org/)\n",
    "- Subscribe to our [newsletter](https://esa-worldcereal.org/en#news) to get the latest updates\n",
    "- Follow us on [LinkedIn](https://www.linkedin.com/company/esa-worldcereal)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
