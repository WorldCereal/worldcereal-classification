{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/System_v1_custom_croptype.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model using publicly available and harmonized in-situ reference data for your area and crop types of interest. Afterwards, the model can be applied to your season of interest to generate a crop type map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "  \n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Define your region of interest](#1.-Define-your-region-of-interest)\n",
    "- [2. Define your temporal extent](#2.-Define-your-temporal-extent)\n",
    "- [3. Extract public reference data](#3-extract-public-reference-data)\n",
    "- [4. Select your desired crop types](#4.-Select-your-desired-crop-types)\n",
    "- [5. Prepare training features](#5.-Prepare-training-features)\n",
    "- [6. Train custom classification model](#6.-Train-custom-classification-model)\n",
    "- [7. Deploy your custom model](#7.-Deploy-your-custom-model)\n",
    "- [8. Generate a map](#8.-Generate-a-map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Define your region of interest\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.\n",
    "The widget will automatically store the coordinates of the last rectangle you drew on the map.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Processing area limitation:</b><br> \n",
    "Processing areas beyond 2500 km¬≤ are currently not supported to avoid excessive credit usage and long processing times.<br>\n",
    "Upon exceeding this limit, an error will be shown, and you will need to draw a new rectangle.\n",
    "\n",
    "For testing purposes, we recommend you to select a small area (< 250 km¬≤) in order to limit processing time and credit usage.\n",
    "\n",
    "A run of 250 km¬≤ will typically consume 40 credits and last around 20 mins.<br>\n",
    "A run of 750 km¬≤ will typically consume 90 credits and last around 50 mins.<br>\n",
    "A run of 2500 km¬≤ will typically consume 250 credits and last around 1h 40 mins.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map(area_limit=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Define your temporal extent\n",
    "\n",
    "To determine your season of interest, you can consult the WorldCereal crop calendars (by executing the next cell), or check out the [USDA crop calendars](https://ipad.fas.usda.gov/ogamaps/cropcalendar.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import retrieve_worldcereal_seasons\n",
    "\n",
    "spatial_extent = map.get_extent()\n",
    "seasons = retrieve_worldcereal_seasons(spatial_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the slider to select your processing period. Note that the length of the period is always fixed to a year.\n",
    "Just make sure your season of interest is fully captured within the period you select."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "slider = date_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Extract public reference data\n",
    "\n",
    "Here we query existing public reference data that have already been processed by WorldCereal and are ready to use.\n",
    "To increase the number of hits, we expand the search area by 250 km in all directions.\n",
    "\n",
    "We print the number of training samples retrieved per year.\n",
    "\n",
    "To give you an idea on the regions where public crop type training data is available, consult the figure below:\n",
    "\n",
    "<p align=\"center\">\n",
    "<img src=\"./resources/croptype_data_Ph1.png\" alt=\"crop-data\" width=\"400\"/>\n",
    "</p>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case no samples were found?</b><br> \n",
    "\n",
    "1. **Increase the buffer size**: Try increasing the buffer size by passing the `buffer` parameter to the `query_public_extractions` function (to a reasonable extent).\n",
    "    *Current setting is: 250000 m¬≤.*\n",
    "2. **Pick another area**\n",
    "3. **Contribute data**: Collect some data and contribute to our global database! üåçüåæ [Learn how to contribute here.](https://worldcereal.github.io/worldcereal-documentation/rdm/upload.html)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.refdata import query_public_extractions\n",
    "\n",
    "# Retrieve the polygon you just drew\n",
    "polygon = map.get_polygon_latlon()\n",
    "\n",
    "# Retrieve the date range you just selected\n",
    "processing_period = slider.get_processing_period()\n",
    "\n",
    "# Query our public database of training data\n",
    "public_df = query_public_extractions(polygon, processing_period=processing_period, buffer=250000)\n",
    "public_df.year.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Select your desired crop types\n",
    "\n",
    "Run the next cell and select all crop types you wish to include in your model. All the crops that are not selected will be grouped under the \"other\" category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import pick_croptypes\n",
    "from IPython.display import display\n",
    "\n",
    "checkbox, checkbox_widgets, updated_class_map = pick_croptypes(public_df, samples_threshold=100)\n",
    "display(checkbox)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on your selection, a custom target label is now generated for each sample. Verify that only crops of your choice are appearing in the `downstream_class`, all others will fall under `other`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import get_custom_croptype_labels\n",
    "\n",
    "public_df = get_custom_croptype_labels(public_df, checkbox_widgets, updated_class_map)\n",
    "public_df[\"downstream_class\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Prepare training features\n",
    "\n",
    "Using a deep learning framework (Presto), we derive classification features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting *embeddings* and the *target* labels to train on will be returned as a training dataframe which we will use for downstream model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import prepare_training_dataframe\n",
    "\n",
    "training_dataframe = prepare_training_dataframe(public_df, task_type=\"croptype\")\n",
    "training_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Train custom classification model\n",
    "We train a catboost model for the selected crop types. By default, no class weighting is done. You could opt to enable this by setting `balance_classes=True`, however, depending on the class distribution this may lead to undesired results. There is no golden rule here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model, report, confusion_matrix = train_classifier(training_dataframe, balance_classes=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before training, the available training data has been automatically split into a calibration and validation part. By executing the next cell, you get an idea of how well the model performs on the independent validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the classification report\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Deploy your custom model\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used by OpenEO for inference. Note that these models are only kept in cloud storage for a limited amount of time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "from utils import get_input\n",
    "\n",
    "modelname = get_input(\"model\")\n",
    "model_url = deploy_model(cdse_connection(), custom_model, pattern=modelname)\n",
    "print(f\"Your model can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Generate a map\n",
    "\n",
    "Using our custom model, we generate a map for our region and season of interest.\n",
    "\n",
    "Set some other customization options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.job import PostprocessParameters\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Choose whether you want to store the cropland mask as separate output file\n",
    "save_mask = True\n",
    "\n",
    "# Choose whether or not you want to spatially clean the classification results\n",
    "postprocess_result = True\n",
    "# Choose the postprocessing method you want to use [\"smooth_probabilities\", \"majority_vote\"]\n",
    "# (\"smooth_probabilities will do limited spatial cleaning,\n",
    "# while \"majority_vote\" will do more aggressive spatial cleaning, depending on the value of kernel_size)\n",
    "postprocess_method = \"majority_vote\"\n",
    "# Additional parameter for the majority vote method \n",
    "# (the higher the value, the more aggressive the spatial cleaning,\n",
    "# should be an odd number, not larger than 25, default = 5)\n",
    "kernel_size = 5\n",
    "# Do you want to save the intermediate results (before applying the postprocessing)\n",
    "save_intermediate = True\n",
    "# Do you want to save all class probabilities in the final product? (default is False)\n",
    "keep_class_probs = True\n",
    "\n",
    "postprocess_parameters = PostprocessParameters(enable=postprocess_result,\n",
    "                                               method=postprocess_method,\n",
    "                                               kernel_size=kernel_size,\n",
    "                                               save_intermediate=save_intermediate,\n",
    "                                               keep_class_probs=keep_class_probs)\n",
    "\n",
    "# The output directory is named after the model\n",
    "output_dir = Path(os.getcwd()) / f'CROPTYPE_{modelname}'\n",
    "print(f\"Output directory: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all information we need to generate our map!<br>\n",
    "The next cell will submit a map inference job on CDSE through OpenEO.<br>\n",
    "The first time you run this, you will be asked to authenticate with your CDSE account by clicking the link provided below the cell.<br>\n",
    "Then sit back and wait untill your map is ready..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.job import WorldCerealProductType, generate_map, CropTypeParameters\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Change the URL to your custom classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "parameters.save_mask = save_mask\n",
    "\n",
    "# Get processing period and area\n",
    "processing_period = slider.get_processing_period()\n",
    "processing_extent = map.get_extent()\n",
    "\n",
    "# Launch the job\n",
    "job_results = generate_map(\n",
    "    processing_extent,\n",
    "    processing_period,\n",
    "    output_dir=output_dir,\n",
    "    product_type=WorldCerealProductType.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    postprocess_parameters=postprocess_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The results contain the openeo job id...\n",
    "print(f\"Job id: {job_results.job_id}\")\n",
    "print(f\"Location of metadata: {job_results.metadata}\")\n",
    "#... a list of products that were downloaded...\n",
    "print(f\"Products: {job_results.products.keys()}\")\n",
    "# ... for each product:\n",
    "print('-- For each product --')\n",
    "print(f\"Type: {job_results.products['croptype']['type']}\")\n",
    "print(f\"Temporal extent: {job_results.products['croptype']['temporal_extent']}\")\n",
    "print(f\"Look-up table: {job_results.products['croptype']['lut']}\")\n",
    "print(f\"URL: {job_results.products['croptype']['url']}\")\n",
    "print(f\"Local path: {job_results.products['croptype']['path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification results will be automatically downloaded to your *output_dir* in .tif format.\n",
    "\n",
    "For a model with two classes, you get a raster file containing up to four bands:\n",
    "1. The label of the winning class\n",
    "2. The probability of the winning class [0 - 100]\n",
    "3. and beyond (optional, depending on settings): Class probabilities of each class, ordered according to the look-up table. The look-up table for each product can be consulted in the 'results' object as produced by the 'generate_map' function.\n",
    "\n",
    "Using the function below, we split this information into separate .tif files, thereby adding metadata and a color map, to ease interpretation and visualization:\n",
    "- \"croptype_classification_start-date_end-date.tif\" --> contains the classification labels. A class look-up table is included in the .tif metadata.\n",
    "- \"croptype_probability_start-date_end-date.tif\" -->  contains the probability associated with the prediction [0 - 100]\n",
    "\n",
    "In case you chose to store the original per-class probabilities, these are NOT written to a separate file and need to be consulted in the original result downloaded from OpenEO.\n",
    "\n",
    "Note that in case you chose to apply post-processing AND save intermediate results, you will also get a \"croptype-raw_xxx.tif\" output, which holds the classification labels and probabilities BEFORE post-processing.\n",
    "\n",
    "Also note that if you chose to save the cropland mask as a separate output, you will also get a cropland (and potentially cropland-raw) product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import prepare_visualization\n",
    "\n",
    "filepaths = prepare_visualization(job_results)\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_classification\n",
    "\n",
    "visualize_classification(filepaths, \"croptype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting raster files can be visualized in QGIS.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>WARNING:</b> <br>\n",
    "In case you run this notebook through the Terrascope environment, ALWAYS make sure you download the resulting files to your local system!<br>\n",
    "The Terrascope environment will be cleaned automatically upon exit!\n",
    "</div>\n",
    "\n",
    "In case you are running this script on your local environment, you can alternatively use the following cells to visualize the outputs directly in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_products\n",
    "\n",
    "visualize_products(filepaths, port=8887)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import show_color_legend\n",
    "\n",
    "show_color_legend(filepaths, \"croptype\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
