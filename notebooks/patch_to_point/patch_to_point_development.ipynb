{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development and example of patch-to-point extraction workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openeo\n",
    "import pandas as pd \n",
    "import pystac\n",
    "import pystac_client\n",
    "\n",
    "from shapely.geometry import shape, MultiPolygon\n",
    "\n",
    "from worldcereal.extract.patch_to_point_worldcereal import create_job_patch_to_point_worldcereal, get_sample_points_from_rdm\n",
    "from worldcereal.rdm_api import RdmInteraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create job dataframe\n",
    "\n",
    "As discussed we will orchestrate the jobs by splittin per `ref_id` and `EPSG`. The below will be replaced by a `create_job_dataframe_patch_to_point_worldcereal` function (or a fancier name). For now we just create a dummy `pandas.DataFrame` containing all necessary columns (prone to change)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>backend</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>epsg</th>\n",
       "      <th>ref_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Terrascope</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2022-01-01</td>\n",
       "      <td>32633</td>\n",
       "      <td>2021_AUT_LPIS_POLY_110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      backend  start_date    end_date   epsg                  ref_id\n",
       "0  Terrascope  2021-01-01  2022-01-01  32633  2021_AUT_LPIS_POLY_110"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_df = pd.read_parquet('job_df.parquet')\n",
    "job_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we find all samples in RDM that match the following:\n",
    "\n",
    "- ref_id = ref_id\n",
    "- Lie within patch extraction patches (polygons that are partly within are cut off)\n",
    "- Temporal extent matches given temporal extent\n",
    "\n",
    "We can either include the `get_sample_points_from_rdm` in the `create_job` function, but this creates extra overhead before submitting the job. Otherwise, we can make it part of the `create_job_dataframe` workflow (fetch gdf and upload to artifactory as geoparquet, and include artifactory URL in job database)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This returns all geometries in the RDM, cut-off so that they are fully within the patches, and then taken the centroid. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create job patch to point\n",
    "\n",
    "Here we create the openEO process graph to be sent to the backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated using refresh token.\n"
     ]
    }
   ],
   "source": [
    "row = job_df.iloc[0]\n",
    "connection = openeo.connect('openeo.vito.be').authenticate_oidc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-03-11 13:42:07.883\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mworldcereal.rdm_api.rdm_interaction\u001b[0m:\u001b[36mget_samples\u001b[0m:\u001b[36m500\u001b[0m - \u001b[1mQuerying 1 collections...\u001b[0m\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Artifactory credentials not found. Please set ARTIFACTORY_USERNAME and ARTIFACTORY_PASSWORD.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m job \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_job_patch_to_point_worldcereal\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprovider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconnection_provider\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecutor_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2g\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpython_memory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m2g\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_executors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m20\u001b[39;49m\n\u001b[1;32m      9\u001b[0m \n\u001b[1;32m     10\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/worldcereal/worldcereal-classification/src/worldcereal/extract/patch_to_point_worldcereal.py:84\u001b[0m, in \u001b[0;36mcreate_job_patch_to_point_worldcereal\u001b[0;34m(row, connection, provider, connection_provider, executor_memory, python_memory, max_executors)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# Assume row has the following fields: backend, start_date, end_date, spatial_extent/geometry(?), epsg, ref_id\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m     \u001b[38;5;66;03m# TODO: in a separate issue and PR, we could consider refactoring worldcereal/openeo/preprocessing to separate the S1 and S2 preprocessing from the raw datacube extractions\u001b[39;00m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;66;03m# For now I suggest to just get it working\u001b[39;00m\n\u001b[1;32m     83\u001b[0m     gdf \u001b[38;5;241m=\u001b[39m get_sample_points_from_rdm(row)\n\u001b[0;32m---> 84\u001b[0m     url \u001b[38;5;241m=\u001b[39m \u001b[43mupload_geoparquet_artifactory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepsg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcollection\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mref_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     point_geometries \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39mload_url(url\u001b[38;5;241m=\u001b[39murl, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParquet\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     87\u001b[0m     stac_property_filter \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: eq(x, row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mref_id\u001b[39m\u001b[38;5;124m\"\u001b[39m]),\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mproj:epsg\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mlambda\u001b[39;00m x: eq(x, \u001b[38;5;28mint\u001b[39m(row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepsg\u001b[39m\u001b[38;5;124m\"\u001b[39m])),\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;66;03m# \"valid_time\": {\"gte\": row[\"start_date\"], \"lte\": row[\"end_date\"]},  # Let's discuss temporal filtering together\u001b[39;00m\n\u001b[1;32m     91\u001b[0m }\n",
      "File \u001b[0;32m~/worldcereal/worldcereal-classification/src/worldcereal/extract/utils.py:90\u001b[0m, in \u001b[0;36mupload_geoparquet_artifactory\u001b[0;34m(gdf, name, collection)\u001b[0m\n\u001b[1;32m     87\u001b[0m artifactory_password \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mgetenv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mARTIFACTORY_PASSWORD\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m artifactory_username \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m artifactory_password:\n\u001b[0;32m---> 90\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     91\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArtifactory credentials not found. Please set ARTIFACTORY_USERNAME and ARTIFACTORY_PASSWORD.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     92\u001b[0m     )\n\u001b[1;32m     94\u001b[0m headers \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mContent-Type\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapplication/octet-stream\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m     96\u001b[0m upload_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://artifactory.vgt.vito.be/artifactory/auxdata-public/gfmap-temp/openeogfmap_dataframe_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcollection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "\u001b[0;31mValueError\u001b[0m: Artifactory credentials not found. Please set ARTIFACTORY_USERNAME and ARTIFACTORY_PASSWORD."
     ]
    }
   ],
   "source": [
    "job = create_job_patch_to_point_worldcereal(\n",
    "    row=row,\n",
    "    connection=connection,\n",
    "    provider=None,\n",
    "    connection_provider=None,\n",
    "    executor_memory='2g',\n",
    "    python_memory='2g',\n",
    "    max_executors=20\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
