{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a23e1b2",
   "metadata": {},
   "source": [
    "## Extracting pre-processed inputs\n",
    "\n",
    "This notebook demonstrates how you can extract, for one or multiple small patches, pre-processed satellite time series required for running a cropland or crop type model locally on your machine.\n",
    "\n",
    "### Why?\n",
    "\n",
    "Having a set of small patches available comes in handy during the development of a custom crop type model. It allows you to quickly test different model set-ups, as each time you have trained a new model, you can immediately apply it to the same set of patches and check for improvements. By not having to deploy and run the model on CDSE, this drastically reduces the time required to get to your ideal crop model!\n",
    "\n",
    "### How does it work?\n",
    "\n",
    "All you need to specify is:\n",
    "- the geometry of one or multiple small patches (< 20 x 20 km)\n",
    "- start and end date of the time series\n",
    "\n",
    "The notebook will then launch, for each of the specified geometries, an OpenEO processing job on the Copernicus Data Space Ecosystem (CDSE) extracting all relevant Sentinel-1, Sentinel-2, meteo and digital elevation information that is used by the WorldCereal classification algorithms to predict cropland and crop types.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>PREREQUISITE:</b> <br>\n",
    "This means you need a <a href=\"https://dataspace.copernicus.eu/\" target=\"_blank\">CDSE account</a> in order to proceed!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55cf1921",
   "metadata": {},
   "source": [
    "### Step 1: specify your area(s) of interest\n",
    "\n",
    "**Option 1: draw a small patch on the map**\n",
    "\n",
    "Use the rectangle button in the interactive widget below to draw a small area of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb80fc43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map(area_limit=400)  # area limit in km2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb0867ee",
   "metadata": {},
   "source": [
    "Now save your area of interest for future reference. You will be asked to provide a short descriptive name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262a3a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.production import bbox_extent_to_gdf\n",
    "from pathlib import Path\n",
    "\n",
    "bbox_name = input('Enter the name for the output bbox file (without extension): ')\n",
    "patches_file = Path(f'./bbox/{bbox_name}.gpkg')\n",
    "processing_extent = map.get_extent(projection='latlon')\n",
    "bbox_extent_to_gdf(processing_extent, patches_file)\n",
    "id_source_attribute = None  # Not needed for drawn bbox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f0eb2d",
   "metadata": {},
   "source": [
    "**Option 2: Provide path to vector file (.shp/.gpkg/.geoparquet)** \n",
    "\n",
    "The file should contain one or multiple small polygons defining your areas of interest. Along with the geometry, the vector file should contain an id attribute, containing a unique identifier for each geometry. The name of this attribute should be passed to `id_source_attribute`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f80dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "patches_file = Path(...)\n",
    "id_source_attribute = ...  # e.g. 'id' or 'patch_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87aa53a",
   "metadata": {},
   "source": [
    "### Step 2: Select your processing period\n",
    "\n",
    "Keep in mind WorldCereal models always use a processing period of 12 months.<br>\n",
    "Use the slider below to define your processing period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705eaea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "processing_slider = date_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59e3b4e",
   "metadata": {},
   "source": [
    "### Step 3: Launch the processing job(s)\n",
    "\n",
    "You will be asked to provide a descriptive name for the output directory.<br>\n",
    "Results will be automatically saved in a folder `./preprocessed_inputs/<your_name>`.<br>\n",
    "\n",
    "If desired, you can also specify a preferred orbit state for the Sentinel-1 data. If not provided, the orbit state will be automatically determined based on the availability of data.\n",
    "\n",
    "Extracting inputs for a small area takes around 10 minutes. Hang in there!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81058534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.preprocessed_inputs import collect_worldcereal_inputs_patches\n",
    "\n",
    "processing_period = processing_slider.get_selected_dates()\n",
    "\n",
    "name_output = input('Enter name for the output directory: ')\n",
    "outdir = Path(f'./preprocessed_inputs/{name_output}')\n",
    "\n",
    "s1_orbit_state = None  # or 'ASCENDING' / 'DESCENDING'\n",
    "\n",
    "collect_worldcereal_inputs_patches(patches_file, outdir, \n",
    "                                  processing_period.start_date,\n",
    "                                  processing_period.end_date,\n",
    "                                  id_source=id_source_attribute,\n",
    "                                  s1_orbit_state=s1_orbit_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921c8eb7",
   "metadata": {},
   "source": [
    "### Step 4: Check results!\n",
    "\n",
    "Let's first have a look at the status of your processing job(s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d72ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "job_status_file = outdir / 'job_tracking.csv'\n",
    "job_status = pd.read_csv(job_status_file)\n",
    "print(job_status['status'].value_counts())\n",
    "job_status.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a60fa5",
   "metadata": {},
   "source": [
    "As a result of each processing job, you should have received one NetCDF file.<br>\n",
    "Let's inspect the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d907ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import xarray as xr\n",
    "\n",
    "outfiles = sorted(glob.glob(str(outdir / '*' / 'preprocessed-inputs_*.nc')))\n",
    "outfile = outfiles[0]\n",
    "ds = xr.open_dataset(outfile)\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5613bc",
   "metadata": {},
   "source": [
    "We can do a quick quality check on the extracted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42d6e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.preprocessed_inputs import get_band_statistics_netcdf, visualize_timeseries_netcdf\n",
    "\n",
    "stats = get_band_statistics_netcdf(ds)\n",
    "visualize_timeseries_netcdf(ds, band=\"NDVI\", npixels=6, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5c937a",
   "metadata": {},
   "source": [
    "All done!<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
