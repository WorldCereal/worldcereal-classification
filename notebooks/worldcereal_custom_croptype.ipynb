{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301a591",
   "metadata": {},
   "source": [
    "![](./resources/Custom_croptype_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a284b",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [Introduction](###-Introduction)\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Gather and prepare your training data](###-1.-Gather-and-prepare-your-training-data)\n",
    "- [2. Prepare training features](###-2.-Prepare-training-features)\n",
    "- [3. Train custom classification model](###-3.-Train-custom-classification-model)\n",
    "- [4. Deploy your custom model](###-4.-Deploy-your-custom-model)\n",
    "- [5. Generate your custom crop type map](###-5.-Generate-your-custom-crop-type-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c162856",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model for your area, season and crop types of interest.\n",
    "\n",
    "For training the model, you can use a combination of:\n",
    "- publicly available reference data harmonized by the WorldCereal consortium;\n",
    "- your own private reference data.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "In case you would like to use private reference data to train your model, make sure to first complete the workflow as outlined in our separate notebook <b>worldcereal_private_extractions.ipynb</b>.\n",
    "</div>\n",
    "\n",
    "After model training, we deploy your custom model to the cloud, from where it can be accessed by OpenEO, allowing you to apply your model on your area and season of interest and generate your custom crop type map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4436d",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "#### Option 1: Run on Terrascope\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment. Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">When you click the button, you will be prompted with \"Server Options\".<br>\n",
    "Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident?<br>\n",
    "Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2Fworldcereal_custom_croptype.ipynb&branch=main\"><img src=\"https://img.shields.io/badge/Generate%20custom%20crop%20type%20map-Terrascope-brightgreen\" alt=\"Generate custom crop type map\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "#### Option 2: Install Locally\n",
    "\n",
    "If you prefer to install the package locally, you can create the WorldCereal environment using **Conda** or **pip**.\n",
    "\n",
    "First clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/WorldCereal/worldcereal-classification.git\n",
    "cd worldcereal-classification\n",
    "```\n",
    "Next, install the package locally:\n",
    "- for Conda: `conda env create -f environment.yml`\n",
    "- for Pip: `pip install .[train,notebooks]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb9cc",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).<br>\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116e791",
   "metadata": {},
   "source": [
    "### 1. Gather and prepare your training data\n",
    "\n",
    "Note:\n",
    "In case you would like to explore the availability of publicly available reference data for your region of interest, you can:\n",
    "\n",
    "- use the WorldCereal Reference Data Module user interface, available [here](https://rdm.esa-worldcereal.org/). More explanation can be found [here](https://worldcereal.github.io/worldcereal-documentation/rdm/explore.html#explore-data-through-our-user-interface).\n",
    "- use our dedicated notebook [worldcereal_RDM_demo.ipynb](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_RDM_demo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64e8c9",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest (AOI)**\n",
    "\n",
    "Provide a bounding box specifying the region in which you would like to look for available reference data.<br>\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.<br>\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.<br>\n",
    "The widget will automatically store the coordinates of the last rectangle you drew on the map.<br>\n",
    "\n",
    "Alternatively, you can also upload a vector file (either zipped shapefile or GeoPackage) delineating<br>\n",
    "your area of interest. In case your vector file contains multiple polygons or points, the total bounds<br>\n",
    "will be automatically computed and serve as your AOI. Files containing only a single point are not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4b0f1",
   "metadata": {},
   "source": [
    "**Step 2: Get all available reference data**\n",
    "\n",
    "Now we query both public and private extractions and retrieve the relevant samples based on your defined area of interest.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note on the use of private data</b><br>\n",
    "In case you would like to include your private extractions, make sure to specify the private_extractions_path in the cell below, where your private extractions reside!\n",
    "</div>\n",
    "\n",
    "By default, a spatial buffer of 250 km is applied to your area of interest to ensure sufficient training data is found.<br>\n",
    "You can freely expand this search perimeter by changing the value of the `buffer` parameter.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important consideration on model scope!</b><br>\n",
    "\n",
    "We provide the option to filter the reference data explicitly to only retain temporary crops, by setting the `filter_cropland` parameter to `True`.<br>\n",
    "You should ONLY use this option in case:\n",
    "- you want to train a model able to distinguish different types of temporary crops\n",
    "- you don't want your model to make the distinction between temporary crops and other types of land cover\n",
    "- you want to use the default WorldCereal temporary crops model to locate temporary crops OR you already have a cropland mask for your area of interest\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1721e1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.extractions import query_extractions\n",
    "\n",
    "# Retrieve the polygon you drew on the map\n",
    "polygon = map.get_polygon_latlon()\n",
    "\n",
    "# Specify a buffer distance to expand your search perimeter\n",
    "buffer = 250000  # meters\n",
    "\n",
    "# Specify the path to the private extractions data; \n",
    "# if you followed the private extractions notebook, your extractions path should be the one commented below;\n",
    "# if you leave this None, only public data will be queried\n",
    "private_extractions_path = None\n",
    "# private_extractions_path = Path('./extractions/worldcereal_merged_extractions.parquet')\n",
    "\n",
    "# Specify whether you are only interested in temporary crops (True) or all land cover types (False)\n",
    "filter_cropland = False\n",
    "\n",
    "# Query our public database of training data\n",
    "extractions = query_extractions(polygon, buffer, private_parquet_path=private_extractions_path, filter_cropland=filter_cropland)\n",
    "extractions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d4258",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case no samples were found? Or in case you only have observations for a single crop type?</b><br> \n",
    "\n",
    "1. **Increase the buffer size**: Try increasing the buffer size by adjusting the `buffer` parameter.<br>  *Current setting is: 250 km.*\n",
    "2. **Pick another area**: Consult our [Reference Data Module](https://rdm.esa-worldcereal.org) to find areas with higher data density.\n",
    "3. **Contribute data**: Collect some data and contribute to our global database! <br>\n",
    "üåçüåæ [Learn how to contribute here.](https://worldcereal.github.io/worldcereal-documentation/rdm/upload.html)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e4487",
   "metadata": {},
   "source": [
    "**Step 3: Perform a quick quality check**\n",
    "\n",
    "In this optional step, we provide you with some tools to quickly assess the quality of the datasets.\n",
    "\n",
    "Upon executing this cell, you will be prompted to enter a dataset name (ref_id) for inspection.\n",
    "\n",
    "Especially the visualization of the time series might help you better define your season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d333",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import get_band_statistics, visualize_timeseries\n",
    "\n",
    "dataset_name = input('Enter the dataset name: ')\n",
    "subset_data = extractions.loc[extractions['ref_id'] == dataset_name]\n",
    "\n",
    "# Check band statistics\n",
    "band_stats = get_band_statistics(subset_data)\n",
    "\n",
    "# Visualize timeseries for a few samples (5 by default)\n",
    "visualize_timeseries(subset_data, nsamples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405a2dc",
   "metadata": {},
   "source": [
    "Based on the reported contents or quality check of the datasets, you might want to drop some of the selected data before proceeding.<br>\n",
    "\n",
    "Here is an example on how to drop a complete dataset from the extracted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10432e58",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "## Drop a specific dataset\n",
    "# dataset_name = '2021_AUT_LPIS_POLY_110'\n",
    "# extractions = extractions.loc[extractions['ref_id'] != dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e73d1",
   "metadata": {},
   "source": [
    "**Step 4: Filter your training data based on timing of observation**\n",
    "\n",
    "In WorldCereal, we allow you to train **season-specific** classifiers.<br>\n",
    "In this step, you are asked to specify your cropping season of interest.<br>\n",
    "Based on this information, we get rid of training data not relevant for your season of interest.<br>\n",
    "\n",
    "To gain a better understanding of crop seasonality in your area of interest, you can consult the WorldCereal crop calendars (by executing the next cell), or check out the [USDA crop calendars](https://ipad.fas.usda.gov/ogamaps/cropcalendar.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcf426",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import retrieve_worldcereal_seasons\n",
    "\n",
    "spatial_extent = map.get_extent()\n",
    "seasons = retrieve_worldcereal_seasons(spatial_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83cfa",
   "metadata": {},
   "source": [
    "Now use the slider to select your season of interest.<br>\n",
    "\n",
    "Note that WorldCereal models are always trained on time series of **12 months**.<br>\n",
    "Just make sure the center of your season of interest nicely coincides with the `Season center` as indicated below the slider.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb02a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import season_slider\n",
    "\n",
    "slider = season_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e373be4",
   "metadata": {},
   "source": [
    "\n",
    "In this step, our training data is first converted into a format which can be used by our training feature computation and model training routines.\n",
    "\n",
    "Then, we filter out any sample for which the observation date (attribute `valid_time`) does not match the selected season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e07f9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.refdata import process_extractions_df\n",
    "\n",
    "# Retrieve the date range you just selected\n",
    "season = slider.get_selected_dates()\n",
    "\n",
    "# Process the merged data\n",
    "training_df = process_extractions_df(extractions, season)\n",
    "\n",
    "# Report on the contents of the data\n",
    "print(f'Samples originating from {training_df[\"ref_id\"].nunique()} unique reference datasets.')\n",
    "print('Distribution of samples across years:')\n",
    "print(training_df.year.value_counts())\n",
    "ncroptypes = training_df['ewoc_code'].nunique()\n",
    "print(f'Number of crop types remaining: {ncroptypes}')\n",
    "if ncroptypes <= 1:\n",
    "    raise ValueError(\"Not enough crop types found in the remaining data to train a model, cannot continue.\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5a9e5",
   "metadata": {},
   "source": [
    "**Step 5: Select your crops of interest**\n",
    "\n",
    "The following widget will display all available land cover classes and crop types in your training dataframe.\n",
    "\n",
    "Tick the checkbox for each crop type you wish to explicitly include in your model.<br>\n",
    "In case you wish to group multiple crops together, just tick the parent node in the hierarchy.\n",
    "\n",
    "Non-selected crops will be merged together in an `other` class.\n",
    "\n",
    "After selecting all your crop types of interest, hit the \"Apply\" button.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Minimum number of samples:</b><br>\n",
    "In order to train a model, we recommend a minimum of 30 samples to be available for each unique crop type.<br>\n",
    "Any crop type in the dataframe with fewer than 30 samples will initially not be shown.<br>\n",
    "You can adjust this threshold through the count_threshold parameter.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70716157",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import CropTypePicker\n",
    "\n",
    "croptypepicker = CropTypePicker(sample_df=training_df, count_threshold=30, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe53569",
   "metadata": {},
   "source": [
    "In the next cell, we apply your selection to your training dataframe.<br>\n",
    "The new dataframe will contain a `downstream_class` attribute, denoting the final label.<br>\n",
    "Let's first check which classes ended up in the \"other\" class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd192cb8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import apply_croptypepicker_to_df\n",
    "from worldcereal.utils.legend import translate_ewoc_codes\n",
    "\n",
    "training_df = apply_croptypepicker_to_df(training_df, croptypepicker)\n",
    "other_count = training_df.loc[training_df['downstream_class'] == 'other']['ewoc_code'].value_counts()\n",
    "other_labels = translate_ewoc_codes(other_count.index.tolist())\n",
    "other_count.to_frame().merge(other_labels, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e8190",
   "metadata": {},
   "source": [
    "Based on this list, you might consider dropping some classes.<br>\n",
    "This can be done by providing the \"ewoc_codes\" in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d282d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# drop classes\n",
    "# to_drop = [1107000020, 1107000000, ]\n",
    "to_drop = []\n",
    "if len(to_drop) > 0:\n",
    "    training_df = training_df.loc[~training_df['ewoc_code'].isin(to_drop)]\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eff31d",
   "metadata": {},
   "source": [
    "Finally, you could opt to combine some classes using the code snippet below as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2d225",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# combine_classes = {\n",
    "#     'cereals': ['winter_barley', 'oats', 'millet', 'winter_rye', 'wheat']}\n",
    "combine_classes = {}\n",
    "for new_class, old_classes in combine_classes.items():\n",
    "    training_df.loc[training_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "\n",
    "# Report on the contents of the data\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38a25e",
   "metadata": {},
   "source": [
    "**Step 6: Save your final training dataframe for future reference**\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a unique name for your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a9c9b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "df_name = get_input(\"Name dataframe\")\n",
    "\n",
    "training_dir = Path('./training_data')\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outfile = training_dir / f'{df_name}.csv'\n",
    "\n",
    "if outfile.exists():\n",
    "    raise ValueError(f\"File {outfile} already exists. Please delete it or choose a different name.\")\n",
    "\n",
    "training_df.to_csv(outfile)\n",
    "\n",
    "print(f\"Dataframe saved to {outfile}\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1d5f0",
   "metadata": {},
   "source": [
    "### 2. Prepare training features\n",
    "\n",
    "Using a deep learning framework (Presto), we derive classification features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting *embeddings* (`presto_ft_0` -> `presto_ft_127`) and the target labels (`downstream_class`) to train on will be returned as a training dataframe which we will use for downstream model training.\n",
    "\n",
    "We provide several options for users seeking to increase model robustness. By default, these options are disabled, but especially when training a model across multiple years in areas with much reference data, these options are worth considering:<rb>\n",
    "- `augment` parameter: when set to `True` introduces slight temporal jittering of the processing window, making the model more robust against slight variations in seasonality across different years.\n",
    "- `mask_ratio` parameter: value between zero and one. When larger than zero, random inputs are masked prior to embedding computation. This can be used to make the model more resilient against missing data (e.g. due to Sentinel-1 data being unavailable).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dbd1a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import prepare_training_dataframe\n",
    "\n",
    "training_dataframe = prepare_training_dataframe(training_df, augment=False, mask_ratio=0)\n",
    "training_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65beebf",
   "metadata": {},
   "source": [
    "### 3. Train custom classification model\n",
    "\n",
    "We train a catboost model for the selected crop types.<br> \n",
    "\n",
    "By default, we apply **class balancing** to ensure minority classes are not discarded. However, depending on the class distribution this may lead to undesired results. There is no golden rule here. If your main goal is to make sure the most dominant classes in your training data are very precisely identified in your map, you can opt to NOT apply class balancing by setting: `balance_classes=False`. \n",
    "\n",
    "Before training, the available training data has been automatically split into a calibration and validation part. The validation report and confusion matrix already provide you with a first idea on your model's performance.<br>\n",
    "For visualizing the confusion matrix, you have several options through the `show_confusion_matrix` parameter:\n",
    "- `absolute`: print absolute sample counts in the confusion matrix\n",
    "- `relative`: plots the normalized confusion matrix\n",
    "- `none`: do not visualize a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8237d6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model, report, confusion_matrix = train_classifier(\n",
    "    training_dataframe, balance_classes=True, show_confusion_matrix='absolute',\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87456094",
   "metadata": {},
   "source": [
    "### 4. Deploy your custom model\n",
    "\n",
    "Once trained, your model is uploaded to a dedicated S3 bucket on CDSE, so it can be accessed by OpenEO for generating maps (see next step).<br>\n",
    "Your model is protected using your CDSE credentials and will not be accessible by anyone else.\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a clear and short name for your custom model.\n",
    "\n",
    "Note that your model is only kept in cloud storage for a limited amount of time. <br>\n",
    "Make sure to download your model (using the link provided) if you wish to store it for a longer period of time!<br>\n",
    "In case you would like to use your model for generating maps at a later point in time, you will need to host your model in a publicly available repository, e.g. Google Drive, and replace `model_url` with this public link during model inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0ece5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "modelname = get_input(\"model\")\n",
    "model_url = deploy_model(cdse_connection(), custom_model, pattern=modelname)\n",
    "print(f\"Your model can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4204b6",
   "metadata": {},
   "source": [
    "### 5. Generate your custom crop type map\n",
    "\n",
    "Using your custom model, we generate a map for your region and season of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63748f",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest (AOI)**\n",
    "\n",
    "Provide a bounding box specifying the region for which you would like to create your map.<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Processing area:</b><br> \n",
    "The WorldCereal system is currently optimized to process <b>20 x 20 km</b> tiles.<br>\n",
    "In case your AOI exceeds this area, it will be automatically split, creating multiple map generation jobs.\n",
    "\n",
    "We ALWAYS recommend you to select a small area to start with, whenever trying out a model for the first time!\n",
    "\n",
    "A run of 400 km¬≤ will typically consume 40 credits and last around 20 mins.<br>\n",
    "</div>\n",
    "\n",
    "We refer to [Section 1 of this notebook](###-1.-Gather-and-prepare-your-training-data) for instructions on how to use our interactive application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101aae5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map(area_limit=1200) # area_limit in km¬≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c9627",
   "metadata": {},
   "source": [
    "Optionally save your drawn bounding box to a file for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ab9d4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.production import bbox_extent_to_gdf\n",
    "from pathlib import Path\n",
    "\n",
    "bbox_name = input('Enter the name for the output bbox file (without extension): ')\n",
    "outfile = Path(f'./bbox/{bbox_name}.gpkg')\n",
    "processing_extent = map.get_extent(projection='latlon')\n",
    "bbox_extent_to_gdf(processing_extent, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0f342",
   "metadata": {},
   "source": [
    "**Step 2: Select your year and season of interest**\n",
    "\n",
    "We always recommend to select a similar growing season as compared to the season for which you trained your model.<br>\n",
    "In case your training data was restricted to 1 or 2 years, applying your model to other years will likely result in lower quality maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468cef9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "processing_slider = date_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4b58e",
   "metadata": {},
   "source": [
    "**Step 3: Set processing parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefd58a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Do you want to automatically mask temporary crops using the default WorldCereal temporary crops mask?\n",
    "# By default we do not mask temporary crops.\n",
    "mask_cropland = False\n",
    "\n",
    "# In case you set mask_cropland to True, choose whether you want to store the cropland mask as separate output\n",
    "save_mask = False\n",
    "\n",
    "# Choose whether or not you want to spatially clean the classification results\n",
    "postprocess_result = True\n",
    "\n",
    "# Choose the postprocessing method you want to use [\"smooth_probabilities\", \"majority_vote\"]\n",
    "# (\"smooth_probabilities will do limited spatial cleaning,\n",
    "# while \"majority_vote\" will do more aggressive spatial cleaning, depending on the value of kernel_size)\n",
    "postprocess_method = \"majority_vote\"\n",
    "\n",
    "# Additional parameter for the majority vote method\n",
    "# (the higher the value, the more aggressive the spatial cleaning,\n",
    "# should be an odd number, not larger than 25, default = 5)\n",
    "kernel_size = 5\n",
    "\n",
    "# Do you want to save the intermediate results? (before applying the postprocessing)\n",
    "save_intermediate = True\n",
    "\n",
    "# Do you want to save all class probabilities in the final product?\n",
    "# If set to False, you will only get the final classification label and confidence of the winning class per pixel\n",
    "keep_class_probs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf0683",
   "metadata": {},
   "source": [
    "**Step 4: Start map production**\n",
    "\n",
    "The next cell takes care of splitting your area of interest into small tiles (size is specified through `tile_resolution` parameter) and generate a map for each tile.<br>\n",
    "\n",
    "You will be able to track progress through the automated reporting.<br>\n",
    "\n",
    "Results will be automatically saved to a folder containing your model name:<br> `runs/CROPTYPE_custom_{your_modelname}_{timestamp}`<br>\n",
    "\n",
    "The first time you run this, you will be asked to authenticate with your CDSE account by clicking the link provided below the cell.<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case of interruption?</b><br> \n",
    "In case processing got interrupted, just make sure to manually set `output_dir` to the directory you previously used. In this case, processing will just continue where it stopped.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from worldcereal.job import PostprocessParameters\n",
    "from worldcereal.job import WorldCerealProductType, CropTypeParameters\n",
    "from notebook_utils.production import start_production_process, monitor_production_process\n",
    "\n",
    "# The output directory is named after the model\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_dir = Path('./runs') / f'CROPTYPE_custom_{modelname}_{timestamp}'\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Get all postprocessing parameters\n",
    "postprocess_parameters = PostprocessParameters(\n",
    "    enable=postprocess_result,\n",
    "    method=postprocess_method,\n",
    "    kernel_size=kernel_size,\n",
    "    save_intermediate=save_intermediate,\n",
    "    keep_class_probs=keep_class_probs,\n",
    ")\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Update parameters with user-defined values\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "parameters.save_mask = save_mask\n",
    "parameters.mask_cropland = mask_cropland\n",
    "\n",
    "# Get processing period and area\n",
    "processing_period = processing_slider.get_selected_dates()\n",
    "processing_extent = map.get_extent(projection='latlon')\n",
    "tile_resolution = 20   # in km\n",
    "\n",
    "# job_options={\"image-name\":\"registry.prod.warsaw.openeo.dataspace.copernicus.eu/prod/openeo-geotrellis-kube-python311:20250619-34\"}\n",
    "\n",
    "args = (processing_extent, processing_period, output_dir)\n",
    "kwargs = dict(\n",
    "    tile_resolution=tile_resolution,\n",
    "    product_type=WorldCerealProductType.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    postprocess_parameters=postprocess_parameters,\n",
    "    # job_options=job_options,\n",
    ")\n",
    "\n",
    "proc, queue, stop_event = start_production_process(args, kwargs)\n",
    "status_df = monitor_production_process(proc, queue, stop_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156038d",
   "metadata": {},
   "source": [
    "**Step 5: Create merged product**\n",
    "\n",
    "Once production across your tiles is finalized, you can use the cell below to merge the different tiles together into one map.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.production import merge_maps\n",
    "\n",
    "merged_path = merge_maps(output_dir, product='croptype')\n",
    "print(f\"Results merged to {merged_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76baf63",
   "metadata": {},
   "source": [
    "**Step 6: Inspect your map**\n",
    "\n",
    "Up to four products are generated:\n",
    "- `croptype-raw` --> your custom crop type product\n",
    "- `croptype` --> your custom crop type product after post-processing\n",
    "- `cropland-raw` --> cropland mask produced using the global WorldCereal cropland model\n",
    "- `cropland` --> cropland mask, after post-processing\n",
    "\n",
    "For each of these products, you will get a raster file containing at least two bands:\n",
    "1. The label of the winning class\n",
    "2. The probability of the winning class [50 - 100]\n",
    "3. and beyond (optional, depending on settings): Class probabilities of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daedb2a",
   "metadata": {},
   "source": [
    "You can use the next cell to quickly visualize your crop type product in this notebook.\n",
    "\n",
    "In case you want to compare all products, we recommend you to use QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_product\n",
    "from worldcereal.utils.models import load_model_lut\n",
    "\n",
    "lut = load_model_lut(model_url)\n",
    "visualize_product(merged_path, product='croptype', lut=lut, write=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba24481",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>WARNING:</b> <br>\n",
    "In case you run this notebook through the Terrascope environment, ALWAYS make sure you download the resulting files to your local system!<br>\n",
    "The Terrascope environment will be cleaned automatically upon exit!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47960734",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
