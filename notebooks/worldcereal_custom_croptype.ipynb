{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](./resources/Custom_croptype_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [Introduction](###-Introduction)\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Gather and prepare your training data](###-1.-Gather-and-prepare-your-training-data)\n",
    "- [2. Prepare training features](###-2.-Prepare-training-features)\n",
    "- [3. Train custom classification model](###-3.-Train-custom-classification-model)\n",
    "- [4. Deploy your custom model](###-4.-Deploy-your-custom-model)\n",
    "- [5. Generate your custom crop type map](###-5.-Generate-your-custom-crop-type-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model for your area, season and crop types of interest.\n",
    "\n",
    "For training the model, you can use a combination of:\n",
    "- publicly available reference data harmonized by the WorldCereal consortium;\n",
    "- your own private reference data.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "In case you would like to use private reference data to train your model, make sure to first complete the workflow as outlined in our separate notebook <b>worldcereal_private_extractions.ipynb</b>.\n",
    "</div>\n",
    "\n",
    "After model training, we deploy your custom model to the cloud, from where it can be accessed by OpenEO, allowing you to apply your model on your area and season of interest and generate your custom crop type map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "#### Option 1: Run on Terrascope\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment. Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">When you click the button, you will be prompted with \"Server Options\". Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident? Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2Fworldcereal_custom_croptype.ipynb&branch=main\"><img src=\"https://img.shields.io/badge/Generate%20custom%20crop%20type%20map-Terrascope-brightgreen\" alt=\"Generate custom crop type map\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "#### Option 2: Install Locally\n",
    "\n",
    "If you prefer to install the package locally, you can create the WorldCereal environment using **Conda** or **pip**.\n",
    "\n",
    "First clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/WorldCereal/worldcereal-classification.git\n",
    "cd worldcereal-classification\n",
    "```\n",
    "Next, install the package locally:\n",
    "- for Conda: `conda env create -f environment.yml`\n",
    "- for Pip: `pip install .[train,notebooks]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gather and prepare your training data\n",
    "\n",
    "Note:\n",
    "In case you would like to explore the availability of publicly available reference data for your region of interest, you can:\n",
    "\n",
    "- use the WorldCereal Reference Data Module user interface, available [here](https://rdm.esa-worldcereal.org/). More explanation can be found [here](https://worldcereal.github.io/worldcereal-documentation/rdm/explore.html#explore-data-through-our-user-interface).\n",
    "- use our dedicated notebook [worldcereal_RDM_demo.ipynb](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_RDM_demo.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest**\n",
    "\n",
    "Draw a bounding box specifying the region for which you want to generate a crop type map. \n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Processing area:</b><br> \n",
    "The WorldCereal system is currently optimized to process <b>20 x 20 km</b> tiles.<br>\n",
    "We recommend to not exceed this size, as this will result in considerable processing costs.\n",
    "\n",
    "For testing purposes, we definitely recommend you to select a small area to start with.\n",
    "\n",
    "A run of 250 km¬≤ will typically consume 40 credits and last around 20 mins.<br>\n",
    "A run of 750 km¬≤ will typically consume 90 credits and last around 50 mins.<br>\n",
    "A run of 2500 km¬≤ will typically consume 250 credits and last around 1h 40 mins.\n",
    "</div>\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.\n",
    "The widget will automatically store the coordinates of the last rectangle you drew on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map(area_limit=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2: Get all available reference data**\n",
    "\n",
    "Now we query both public and private extractions and retrieve the relevant samples based on our defined area and season of interest.\n",
    "\n",
    "By default, a spatial buffer of 250 km is applied to your area of interest to ensure sufficient training data is found.<br>\n",
    "You can freely expand this search perimeter by changing the value of the `buffer` parameter.\n",
    "\n",
    "As we are interested in training a custom crop type model, we explicitly apply a filter to only retain temporary crop samples.\n",
    "Note that this implies mapping of permanent crops is currently not supported.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case no samples were found? Or in case you only have observations for a single crop type?</b><br> \n",
    "\n",
    "1. **Increase the buffer size**: Try increasing the buffer size by adjusting the `buffer` parameter.  *Current setting is: 250 km.*\n",
    "2. **Pick another area**: Consult our [Reference Data Module](https://rdm.esa-worldcereal.org) to find areas with higher data density.\n",
    "3. **Contribute data**: Collect some data and contribute to our global database! üåçüåæ [Learn how to contribute here.](https://worldcereal.github.io/worldcereal-documentation/rdm/upload.html)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.extractions import query_extractions\n",
    "\n",
    "# Retrieve the polygon you drew on the map\n",
    "polygon = map.get_polygon_latlon()\n",
    "\n",
    "# Specify a buffer distance to expand your search perimeter\n",
    "buffer = 250000  # meters\n",
    "\n",
    "# Specify the path to the private extractions data; if you followed the private extractions notebook, your extractions path\n",
    "# should be the one commented below; if you leave this None, only public data will be queried\n",
    "private_extractions_path = None\n",
    "# private_extractions_path = Path('./extractions/worldcereal_merged_extractions.parquet')\n",
    "\n",
    "# Query our public database of training data\n",
    "extractions = query_extractions(polygon, buffer, private_parquet_path=private_extractions_path)\n",
    "extractions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3: Perform a quick quality check**\n",
    "\n",
    "In this optional step, we provide you with some tools to quickly assess the quality of the datasets.\n",
    "\n",
    "Especially the visualization of the time series might help you better define your season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import get_band_statistics, visualize_timeseries\n",
    "\n",
    "dataset_name = input('Enter the dataset name: ')\n",
    "subset_data = extractions.loc[extractions['ref_id'] == dataset_name]\n",
    "\n",
    "# Check band statistics\n",
    "band_stats = get_band_statistics(subset_data)\n",
    "\n",
    "# Visualize timeseries for a few samples\n",
    "visualize_timeseries(subset_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the reported contents or quality check of the datasets, you might want to drop some of the selected data before proceeding.<br>\n",
    "\n",
    "Here is an example on how to drop a complete dataset from the extracted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Drop a specific dataset\n",
    "# dataset_name = '2021_AUT_LPIS_POLY_110'\n",
    "# extractions = extractions.loc[extractions['ref_id'] != dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4: Select your season of interest**\n",
    "\n",
    "To gain a better understanding of crop seasonality in your area of interest, you can consult the WorldCereal crop calendars (by executing the next cell), or check out the [USDA crop calendars](https://ipad.fas.usda.gov/ogamaps/cropcalendar.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import retrieve_worldcereal_seasons\n",
    "\n",
    "spatial_extent = map.get_extent()\n",
    "seasons = retrieve_worldcereal_seasons(spatial_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now use the slider to select your season of interest.<br>\n",
    "\n",
    "Note that we always require you to specify a processing period of **12 months**.<br>\n",
    "Just make sure your season of interest is nicely centered within the year you select.<br>\n",
    "The `Season center` underneath the slider indicates the center of your selected period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "slider = date_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 5: Filter your training data based on timing of observation**\n",
    "\n",
    "In this step, our training data is first converted into a format which can be used by our training feature computation and model training routines.\n",
    "\n",
    "Then, we filter out any sample for which the observation date (attribute `valid_time`) does not match the selected season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from worldcereal.utils.refdata import process_extractions_df\n",
    "\n",
    "# Retrieve the date range you just selected\n",
    "processing_period = slider.get_processing_period()\n",
    "\n",
    "# Process the merged data\n",
    "training_df = process_extractions_df(extractions, processing_period)\n",
    "\n",
    "# Report on the contents of the data\n",
    "print(f'Samples originating from {training_df[\"ref_id\"].nunique()} unique reference datasets.')\n",
    "print('Distribution of samples across years:')\n",
    "print(training_df.year.value_counts())\n",
    "ncroptypes = training_df['ewoc_code'].nunique()\n",
    "print(f'Number of crop types remaining: {ncroptypes}')\n",
    "if ncroptypes <= 1:\n",
    "    raise ValueError(\"Not enough crop types found in the remaining data to train a model, cannot continue.\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 6: Select your crops of interest**\n",
    "\n",
    "The following widget will display all available crop types in your training dataframe.\n",
    "\n",
    "Tick the checkbox for each crop type you wish to explicitly include in your model.<br>\n",
    "In case you wish to group multiple crops together, just tick the parent node in the hierarchy.\n",
    "\n",
    "Not selected crops will be merged together in an `other_temporary_crops` class.\n",
    "\n",
    "After selecting all your crop types of interest, hit the \"Apply\" button.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Minimum number of samples:</b> \n",
    "In order to train a model, we recommend a minimum of 30 samples to be available for each unique crop type.<br>\n",
    "Any crop type in the dataframe with fewer than 30 samples will not be available for selection.<br>\n",
    "You can adjust this threshold through the `count_threshold` parameter.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import CropTypePicker\n",
    "\n",
    "croptypepicker = CropTypePicker(sample_df=training_df, count_threshold=30, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell, we apply your selection to your training dataframe. The new dataframe will contain a `downstream_class` attribute, denoting the final label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import apply_croptypepicker_to_df\n",
    "\n",
    "training_df = apply_croptypepicker_to_df(training_df, croptypepicker)\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 7: Save your final training dataframe for future reference\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a unique name for your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "df_name = get_input(\"name dataframe\")\n",
    "\n",
    "training_dir = Path('./training_data')\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outfile = training_dir / f'{df_name}.csv'\n",
    "\n",
    "if outfile.exists():\n",
    "    raise ValueError(f\"File {outfile} already exists. Please delete it or choose a different name.\")\n",
    "\n",
    "training_df.to_csv(outfile)\n",
    "\n",
    "print(f\"Dataframe saved to {outfile}\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare training features\n",
    "\n",
    "Using a deep learning framework (Presto), we derive classification features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting *embeddings* and the *target* labels to train on will be returned as a training dataframe which we will use for downstream model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import prepare_training_dataframe\n",
    "\n",
    "training_dataframe = prepare_training_dataframe(training_df)\n",
    "training_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train custom classification model\n",
    "\n",
    "We train a catboost model for the selected crop types. By default, we apply class balancing to ensure minority classes are not discarded. However, depending on the class distribution this may lead to undesired results. There is no golden rule here. You can set `balance_classes=False` if you do not wish to apply class balancing. \n",
    "\n",
    "Before training, the available training data has been automatically split into a calibration and validation part. The validation report already provides you with a first idea on your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model, report, confusion_matrix = train_classifier(\n",
    "    training_dataframe, balance_classes=True\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Deploy your custom model\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used by OpenEO for inference.\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a clear and short name for your custom model.\n",
    "\n",
    "Note that these models are only kept in cloud storage for a limited amount of time. Make sure to download your model (using the link provided) if you wish to store it for a longer period of time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "modelname = get_input(\"model\")\n",
    "model_url = deploy_model(cdse_connection(), custom_model, pattern=modelname)\n",
    "print(f\"Your model can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Generate your custom crop type map\n",
    "\n",
    "Using our custom model, we generate a map for our region and season of interest.\n",
    "\n",
    "In the next cell, we provide an overview of other processing options that are available to further tune your crop type map. If you just want to use default processing options, do not change anything in this cell.<br>\n",
    "\n",
    "Results will be automatically saved to a folder containing your model name:<br> `runs/CROPTYPE_custom_{your_modelname}_{timestamp}`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.job import PostprocessParameters\n",
    "from pathlib import Path\n",
    "\n",
    "# The output directory is named after the model\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_dir = Path('./runs') / f'CROPTYPE_custom_{modelname}_{timestamp}'\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "\n",
    "### OPTIONAL PARAMETERS\n",
    "\n",
    "# Choose whether you want to store the cropland mask as separate output file\n",
    "save_mask = True\n",
    "\n",
    "# Choose whether or not you want to spatially clean the classification results\n",
    "postprocess_result = True\n",
    "\n",
    "# Choose the postprocessing method you want to use [\"smooth_probabilities\", \"majority_vote\"]\n",
    "# (\"smooth_probabilities will do limited spatial cleaning,\n",
    "# while \"majority_vote\" will do more aggressive spatial cleaning, depending on the value of kernel_size)\n",
    "postprocess_method = \"majority_vote\"\n",
    "\n",
    "# Additional parameter for the majority vote method\n",
    "# (the higher the value, the more aggressive the spatial cleaning,\n",
    "# should be an odd number, not larger than 25, default = 5)\n",
    "kernel_size = 5\n",
    "\n",
    "# Do you want to save the intermediate results? (before applying the postprocessing)\n",
    "save_intermediate = True\n",
    "\n",
    "# Do you want to save all class probabilities in the final product? (default is False)\n",
    "keep_class_probs = True\n",
    "\n",
    "postprocess_parameters = PostprocessParameters(\n",
    "    enable=postprocess_result,\n",
    "    method=postprocess_method,\n",
    "    kernel_size=kernel_size,\n",
    "    save_intermediate=save_intermediate,\n",
    "    keep_class_probs=keep_class_probs,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have all information we need to generate our map!<br>\n",
    "\n",
    "The next cell will submit a map inference job on CDSE through OpenEO.<br>\n",
    "The first time you run this, you will be asked to authenticate with your CDSE account by clicking the link provided below the cell.<br>\n",
    "\n",
    "Then sit back and wait untill your map is ready..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.job import WorldCerealProductType, generate_map, CropTypeParameters\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Change the URL to your custom classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "parameters.save_mask = save_mask\n",
    "\n",
    "# Get processing period and area\n",
    "processing_period = slider.get_processing_period()\n",
    "processing_extent = map.get_extent()\n",
    "\n",
    "# Launch the job\n",
    "job_results = generate_map(\n",
    "    processing_extent,\n",
    "    processing_period,\n",
    "    output_dir=output_dir,\n",
    "    product_type=WorldCerealProductType.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    postprocess_parameters=postprocess_parameters,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this cell to quickly inspect which results are available\n",
    "\n",
    "# The results contain the openeo job id...\n",
    "print(f\"Job id: {job_results.job_id}\")\n",
    "print(f\"Location of metadata: {job_results.metadata}\")\n",
    "# ... a list of products that were downloaded...\n",
    "print(f\"Products: {job_results.products.keys()}\")\n",
    "# ... for each product:\n",
    "print(\"-- For each product --\")\n",
    "print(f\"Type: {job_results.products['croptype']['type']}\")\n",
    "print(f\"Temporal extent: {job_results.products['croptype']['temporal_extent']}\")\n",
    "print(f\"Look-up table: {job_results.products['croptype']['lut']}\")\n",
    "print(f\"URL: {job_results.products['croptype']['url']}\")\n",
    "print(f\"Local path: {job_results.products['croptype']['path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classification results will be automatically downloaded in .tif format.\n",
    "\n",
    "For a model with two classes, you get a raster file containing up to four bands:\n",
    "1. The label of the winning class\n",
    "2. The probability of the winning class [50 - 100]\n",
    "3. and beyond (optional, depending on settings): Class probabilities of each class, ordered according to the look-up table. The look-up table for each product can be consulted in the 'results' object as produced by the `generate_map` function.\n",
    "\n",
    "Using the function below, we split this information into separate .tif files, thereby adding metadata and a color map, to ease interpretation and visualization:\n",
    "- \"croptype_classification_start-date_end-date.tif\" --> contains the classification labels. A class look-up table is included in the .tif metadata.\n",
    "- \"croptype_probability_start-date_end-date.tif\" -->  contains the probability associated with the prediction [0 - 100]\n",
    "\n",
    "In case you chose to store the original per-class probabilities, these are NOT written to a separate file and need to be consulted in the original result downloaded from OpenEO.\n",
    "\n",
    "Note that in case you chose to apply post-processing AND save intermediate results, you will also get a \"croptype-raw_xxx.tif\" output, which holds the classification labels and probabilities BEFORE post-processing.\n",
    "\n",
    "Also note that if you chose to save the cropland mask as a separate output, you will also get a cropland (and potentially cropland-raw) product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import prepare_visualization\n",
    "\n",
    "filepaths = prepare_visualization(job_results)\n",
    "print(filepaths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulting raster files can be visualized in QGIS.<br>\n",
    "To get a quick idea of what the result looks like, you can use the cell below to plot the resulting map.\n",
    "\n",
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>WARNING:</b> <br>\n",
    "In case you run this notebook through the Terrascope environment, ALWAYS make sure you download the resulting files to your local system!<br>\n",
    "The Terrascope environment will be cleaned automatically upon exit!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_classification\n",
    "\n",
    "visualize_classification(filepaths, \"croptype\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
