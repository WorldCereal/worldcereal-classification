{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301a591",
   "metadata": {},
   "source": [
    "![](./resources/Custom_croptype_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a284b",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [Introduction](###-Introduction)\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Gather and prepare your training data](###-1.-Gather-and-prepare-your-training-data)\n",
    "- [2. Train custom classification model](###-2.-Train-custom-classification-model)\n",
    "- [3. Deploy your custom model](###-3.-Deploy-your-custom-model)\n",
    "- [4. Generate your custom crop type map](###-4.-Generate-your-custom-crop-type-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c162856",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model for your area, season and crop types of interest.\n",
    "\n",
    "For training the model, you can use a combination of:\n",
    "- publicly available reference data harmonized by the WorldCereal consortium;\n",
    "- your own private reference data.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "In case you would like to use private reference data to train your model, make sure to first complete the workflow as outlined in our separate notebook <b>worldcereal_private_extractions.ipynb</b>.\n",
    "</div>\n",
    "\n",
    "After model training, we deploy your custom model to the cloud, from where it can be accessed by OpenEO, allowing you to apply your model on your area and season of interest and generate your custom crop type map."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4436d",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "#### Option 1: Run on Terrascope\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment. Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">When you click the button, you will be prompted with \"Server Options\".<br>\n",
    "Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident?<br>\n",
    "Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2Fworldcereal_custom_croptype.ipynb&branch=main\"><img src=\"https://img.shields.io/badge/Generate%20custom%20crop%20type%20map-Terrascope-brightgreen\" alt=\"Generate custom crop type map\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> <br>\n",
    "Every time you click the above link, the latest version of the notebook will be fetched, potentially leading to conflicts with changes you have made yourself.<br>\n",
    "To avoid such code conflicts, we recommend you to make a copy of the notebook and make changes only in your copied version.\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Option 2: Install Locally\n",
    "\n",
    "If you prefer to install the package locally, you can create the WorldCereal environment using **Conda** or **pip**.\n",
    "\n",
    "First clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/WorldCereal/worldcereal-classification.git\n",
    "cd worldcereal-classification\n",
    "```\n",
    "Next, install the package locally:\n",
    "- for Conda: `conda env create -f environment.yml`\n",
    "- for Pip: `pip install .[train,notebooks]`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb9cc",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).<br>\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "373b4c28",
   "metadata": {},
   "source": [
    "##### Optional fix in case of issues with \"proj\"\n",
    "\n",
    "Run the following cell in case you experience issues with version conflicts in proj.db further down this notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184f3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Set PROJ environment variables to avoid PROJ database version conflicts\n",
    "# This ensures PROJ uses the database from the current conda environment\n",
    "proj_path = os.path.join(sys.prefix, 'share', 'proj')\n",
    "os.environ['PROJ_LIB'] = proj_path\n",
    "os.environ['PROJ_DATA'] = proj_path\n",
    "\n",
    "print(f\"PROJ paths set to: {proj_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116e791",
   "metadata": {},
   "source": [
    "### 1. Gather and prepare your training data\n",
    "\n",
    "For training a crop type model, you can use a combination of:\n",
    "- publicly available reference data harmonized by the WorldCereal consortium;\n",
    "- your own private reference data.\n",
    "\n",
    "The cell below provides you with a quick overview of the publicly exposed reference datasets for which WorldCereal has already done satellite extractions. Hence these are ready to be plugged into model training.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note on reference data availability:</b><br>\n",
    "\n",
    "For a detailed exploration of available reference data for your region of interest, you can:\n",
    "\n",
    "- use the WorldCereal Reference Data Module user interface, available [here](https://rdm.esa-worldcereal.org/). More explanation can be found [here](https://worldcereal.github.io/worldcereal-documentation/rdm/explore.html#explore-data-through-our-user-interface).\n",
    "- use our dedicated notebook [worldcereal_RDM_demo.ipynb](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_RDM_demo.ipynb).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20aa9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import retrieve_extractions_extent\n",
    "\n",
    "extents, extent_map = retrieve_extractions_extent()\n",
    "print(f\"Found {len(extents)} datasets with extractions.\")\n",
    "display(extent_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64e8c9",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest (AOI)**\n",
    "\n",
    "Provide a bounding box specifying the region in which you would like to look for available reference data.<br>\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.<br>\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.<br>\n",
    "The widget will automatically store the coordinates of the last rectangle you drew on the map.<br>\n",
    "\n",
    "Alternatively, you can also upload a vector file (either zipped shapefile or GeoPackage) delineating<br>\n",
    "your area of interest. In case your vector file contains multiple polygons or points, the total bounds<br>\n",
    "will be automatically computed and serve as your AOI. Files containing only a single point are not allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4b0f1",
   "metadata": {},
   "source": [
    "**Step 2: Get all available reference data**\n",
    "\n",
    "Now we query both public and private extractions and retrieve the relevant samples based on your defined area of interest.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note on the use of private data</b><br>\n",
    "In case you would like to include your private data, you will need to:<br>\n",
    "\n",
    "1. Add your reference data to the [Reference Data Module](https://rdm.esa-worldcereal.org/). Detailed instructions can be found [HERE](https://worldcereal.github.io/worldcereal-documentation/rdm/upload.html).<br>\n",
    "2. Extract satellite data for your reference data by following the steps in [THIS NOTEBOOK](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_private_extractions.ipynb).<br>\n",
    "3. In the code cell below, make sure to specify the path where your private extractions reside.\n",
    "\n",
    "</div>\n",
    "\n",
    "By default, a spatial buffer of 250 km is applied to your area of interest to ensure sufficient training data is found.<br>\n",
    "You can freely expand this search perimeter by changing the value of the `buffer` parameter.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important consideration on model scope!</b><br>\n",
    "\n",
    "By default, we filter the reference data explicitly to only retain temporary crops, by setting the `filter_temporary_crops` parameter to `True`.<br>\n",
    "This effectively means that you will (by default) only be able to train a model distinguishing different types of temporary crops.<br>\n",
    "In case you would like to expand your scope towards other land cover and/or permanent crops, please set `filter_temporary_crops` to `False`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1721e1",
   "metadata": {
    "kernelspec": {
     "display_name": "worldcereal",
     "language": "python",
     "name": "python3"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "ipython",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "python",
     "nbconvert_exporter": "python",
     "pygments_lexer": "ipython3",
     "version": "3.10.0"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.extractions import query_extractions\n",
    "\n",
    "# Retrieve the polygon you drew on the map\n",
    "polygon = map.get_polygon_latlon()\n",
    "\n",
    "# Specify a buffer distance to expand your search perimeter\n",
    "buffer = 250000  # meters\n",
    "\n",
    "# Specify the path to the private extractions data; \n",
    "# if you followed the private extractions notebook, your extractions path should be the one commented below;\n",
    "# if you leave this None, only public data will be queried\n",
    "private_extractions_path = None\n",
    "# private_extractions_path = Path('./extractions/worldcereal_merged_extractions.parquet')\n",
    "\n",
    "# Specify whether you are only interested in temporary crops only (True) or all available classes (False)\n",
    "filter_temporary_crops = True\n",
    "\n",
    "# Query our public database of training data\n",
    "extractions = query_extractions(bbox_poly=polygon, buffer=buffer, private_parquet_path=private_extractions_path, filter_cropland=filter_temporary_crops)\n",
    "extractions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2d4258",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case no samples were found? Or in case you only have observations for a single crop type?</b><br> \n",
    "\n",
    "1. **Increase the buffer size**: Try increasing the buffer size by adjusting the `buffer` parameter.<br>  *Current setting is: 250 km.*\n",
    "2. **Pick another area**: Consult our [Reference Data Module](https://rdm.esa-worldcereal.org) to find areas with higher data density.\n",
    "3. **Contribute data**: Collect some data and contribute to our global database! <br>\n",
    "üåçüåæ [Learn how to contribute here.](https://worldcereal.github.io/worldcereal-documentation/rdm/upload.html)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4662ef28",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Need more control on reference data selection?</b><br>\n",
    "\n",
    "Right now we extracted ALL available reference data for your region of interest. However, we also offer more customizable ways of sampling reference data across different regions, datasets, years, crop types etc., but this is beyond the scope of this demo.<br>\n",
    "\n",
    "If you are interested in these options, make sure to check out the `sample_extractions` function, demonstrated in [this notebook](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/UN_handbook/0_data_preparation.ipynb).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e4487",
   "metadata": {},
   "source": [
    "**Step 3: Perform a quick quality check**\n",
    "\n",
    "In this optional step, we provide you with some tools to quickly assess the quality of the datasets.\n",
    "\n",
    "Upon executing this cell, you will be prompted to enter a dataset name (ref_id) for inspection.\n",
    "\n",
    "Especially the visualization of the time series might help you better define your season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d333",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import get_band_statistics, visualize_timeseries\n",
    "\n",
    "dataset_name = input('Enter the dataset name: ')\n",
    "subset_data = extractions.loc[extractions['ref_id'] == dataset_name]\n",
    "\n",
    "# Check band statistics\n",
    "band_stats = get_band_statistics(subset_data)\n",
    "\n",
    "# Visualize timeseries for a few samples (5 by default)\n",
    "visualize_timeseries(subset_data, nsamples=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e405a2dc",
   "metadata": {},
   "source": [
    "Based on the reported contents or quality check of the datasets, you might want to drop some of the selected data before proceeding.<br>\n",
    "\n",
    "Here is an example on how to drop a complete dataset from the extracted data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10432e58",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "## Drop a specific dataset\n",
    "# dataset_name = '2021_AUT_LPIS_POLY_110'\n",
    "# extractions = extractions.loc[extractions['ref_id'] != dataset_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e73d1",
   "metadata": {},
   "source": [
    "**Step 4: Select your season of interest**\n",
    "\n",
    "Keep in mind that in WorldCereal, we train **season-specific** crop classifiers.<br>\n",
    "In this step, you are asked to specify your cropping season of interest.<br>\n",
    "Based on this information, we get rid of irrelevant training data and prepare the classification features in the next step.<br>\n",
    "\n",
    "To gain a better understanding of crop seasonality in your area of interest, you can consult the WorldCereal crop calendars (by executing the next cell), or check out the [USDA crop calendars](https://ipad.fas.usda.gov/ogamaps/cropcalendar.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcf426",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import retrieve_worldcereal_seasons\n",
    "\n",
    "spatial_extent = map.get_extent()\n",
    "seasons = retrieve_worldcereal_seasons(spatial_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df51a81",
   "metadata": {},
   "source": [
    "Now let's also check the distribution of `valid_time` in your reference data.<br>\n",
    "This attribute indicates the date for which the crop label is actually valid.<br>\n",
    "This is important to consider when selecting your season of interest: it does not make too much sense to train a classifier for a season in which you have barely any valid reference data to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dbe73",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import valid_time_distribution\n",
    "\n",
    "valid_time_distribution(extractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83cfa",
   "metadata": {},
   "source": [
    "Now use the controls below to pin down the exact **growing season window** you plan to target (maximum 12 consecutive months).\n",
    "\n",
    "1. Pick a representative year from the dropdown (used only to help visualize the season).\n",
    "2. Drag the slider handles to the desired start/end months.\n",
    "3. The summary reports both the growing-season window and a derived full-year processing period.\n",
    "\n",
    "The growing-season window will be used to filter samples by their `valid_time`. The same selection will be reused later during inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb02a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "slider = date_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511027f9",
   "metadata": {},
   "source": [
    "**Step 5: Align extractions with your season**\n",
    "\n",
    "This step filters your training samples to match your selected growing season and ensures all samples have exactly 12 monthly timesteps for consistent embedding computation.\n",
    "\n",
    "The system validates that each sample has sufficient satellite data coverage for the selected processing period. Samples are dropped if:\n",
    "- Their satellite extractions don't span the full 12-month processing period\n",
    "- Their `valid_time` falls outside the selected season window (e.g., Aug 1 - Dec 31)\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note on data coverage:</b><br>\n",
    "If you see many samples being dropped with warnings about \"temporal extent\", it means those samples don't have satellite observations covering the complete processing period (e.g., they have Feb-Oct data but the processing period requires Jan-Dec).<br><br>\n",
    "This is expected behavior - the system requires consistent 12-month coverage to ensure reliable model training and inference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f80de",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import align_extractions_to_season\n",
    "import pandas as pd\n",
    "\n",
    "# Retrieve the derived season + processing windows from the slider selection\n",
    "selection = slider.get_selection()\n",
    "season_selection = selection  # persist for downstream inference\n",
    "season_window = selection.season_window\n",
    "processing_period = selection.processing_period\n",
    "\n",
    "# OPTION A: Align extractions to the processing period\n",
    "# season_window will filter by valid_time\n",
    "training_df = align_extractions_to_season(\n",
    "    extractions,\n",
    "    season_window=season_window,\n",
    ")\n",
    "\n",
    "# OPTION B: Strict filtering - require complete temporal coverage (commented out)\n",
    "# Uncomment this if you want to enforce that all samples have data for the full processing period\n",
    "# training_df = align_extractions_to_season(\n",
    "#     extractions,\n",
    "#     processing_period\n",
    "#     season_window=season_window,\n",
    "# )\n",
    "\n",
    "# training_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5a9e5",
   "metadata": {},
   "source": [
    "**Step 6: Select your crops of interest**\n",
    "\n",
    "The following widget will display all available land cover classes and crop types in your training dataframe.\n",
    "\n",
    "Tick the checkbox for each crop type you wish to explicitly include in your model.<br>\n",
    "In case you wish to group multiple crops together, just tick the parent node in the hierarchy.\n",
    "\n",
    "Non-selected crops will be merged together in an `other` class.\n",
    "\n",
    "After selecting all your crop types of interest, hit the \"Apply\" button.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Minimum number of samples:</b><br>\n",
    "In order to train a model, we recommend a minimum of 30-50 samples to be available for each unique crop type.<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70716157",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import CropTypePicker\n",
    "\n",
    "croptypepicker = CropTypePicker(sample_df=training_df, expand=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe53569",
   "metadata": {},
   "source": [
    "In the next cell, we apply your selection to your training dataframe.<br>\n",
    "The new dataframe will contain a `downstream_class` attribute, denoting the final label that will be used during model training.<br>\n",
    "\n",
    "Let's first check which classes ended up in the \"other\" class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd192cb8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import apply_croptypepicker_to_df\n",
    "from worldcereal.utils.legend import translate_ewoc_codes\n",
    "\n",
    "training_df = apply_croptypepicker_to_df(training_df, croptypepicker)\n",
    "other_count = training_df.loc[training_df['downstream_class'] == 'other']['ewoc_code'].value_counts()\n",
    "other_labels = translate_ewoc_codes(other_count.index.tolist())\n",
    "other_count.to_frame().merge(other_labels, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e8190",
   "metadata": {},
   "source": [
    "Based on this list, you might consider dropping some classes.<br>\n",
    "This can be done by providing the \"ewoc_codes\" in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d282d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# CASE 1: drop specific ewoc codes (fill in the list below)\n",
    "# to_drop = [1114060010]\n",
    "\n",
    "# CASE 2: drop all ewoc codes that were labeled as 'other'\n",
    "# to_drop = other_labels.index.tolist()\n",
    "\n",
    "# CASE 3: do not drop anything\n",
    "to_drop = []\n",
    "\n",
    "# Then drop them from the training dataframe\n",
    "if len(to_drop) > 0:\n",
    "    training_df = training_df.loc[~training_df['ewoc_code'].isin(to_drop)]\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eff31d",
   "metadata": {},
   "source": [
    "Finally, you could opt to combine some classes using the code snippet below as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2d225",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Example for combining classes:\n",
    "# combine_classes = {\n",
    "#     'cereals': ['winter_barley', 'oats', 'millet', 'winter_rye', 'wheat']}\n",
    "\n",
    "# In case you do not want to combine any classes, leave the dictionary empty:\n",
    "combine_classes = {}\n",
    "\n",
    "# Apply the class combinations\n",
    "for new_class, old_classes in combine_classes.items():\n",
    "    training_df.loc[training_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "\n",
    "# Report on the contents of the data\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38a25e",
   "metadata": {},
   "source": [
    "**Step 7: Save your final training dataframe for future reference**\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a unique name for your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a9c9b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "df_name = get_input(\"Name dataframe\")\n",
    "\n",
    "training_dir = Path('./training_data')\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outfile = training_dir / f'{df_name}.csv'\n",
    "\n",
    "if outfile.exists():\n",
    "    raise ValueError(f\"File {outfile} already exists. Please delete it or choose a different name.\")\n",
    "\n",
    "training_df.to_csv(outfile)\n",
    "\n",
    "print(f\"Dataframe saved to {outfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffca8811",
   "metadata": {},
   "source": [
    "**Step 8: Compute geospatial embeddings using a finetuned foundation model**\n",
    "\n",
    "Using a geospatial foundation model (Presto), we derive training features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting 128 *embeddings* (`presto_ft_0` -> `presto_ft_127`) nicely condense the Sentinel-1, Sentinel-2, meteo timeseries and ancillary data for your season of interest into a limited number of meaningful features which we will use for downstream model training.\n",
    "\n",
    "We provide several options aimed at increasing temporal robustness and handling real-world data gaps in your final crop model. This is controlled by the following arguments:\n",
    "- `augment` parameter: when set to `True`, introduces slight temporal jittering of the processing window, making the model more robust to variations in seasonality across different years. By default, this option is set to `True`, but especially when training a model for a specific region and year with good local data, disabling this option could be considered.\n",
    "- `mask_on_training` parameter: when `True`, applies sensor masking augmentations (e.g., simulating S1/S2 dropouts, additional clouds, ancillary feature removals) only to the training split to improve robustness to real-world data gaps. The validation/test split is kept untouched for fair evaluation. This is enabled by default (`True`).\n",
    "- `repeats` parameter: number of times each training sample is (re)drawn with its augmentations. Higher values (>1) create more variants (with jitter/masking) and enlarge the effective training set, potentially improving generalization at the cost of longer embedding computation time. Default is 3.\n",
    "\n",
    "The embeddings are computed by pooling Presto's time-explicit representations over your specified growing season window, ensuring features capture the seasonal crop dynamics relevant to your classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7034e9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import compute_seasonal_presto_embeddings\n",
    "\n",
    "season_id = \"ShortRains\"\n",
    "\n",
    "embeddings_df = compute_seasonal_presto_embeddings(\n",
    "    training_df,\n",
    "    season_id=season_id,\n",
    "    mask_on_training=True,  # apply sensor masking to training split\n",
    "    repeats=3,  # number of times to augment each training sample\n",
    "    val_size=0.15,\n",
    "    test_size=0.2,\n",
    "    season_window=season_window,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65beebf",
   "metadata": {},
   "source": [
    "### 2. Train a seasonal torch head\n",
    "\n",
    "Instead of fitting a CatBoost tree ensemble, we now fine-tune a lightweight PyTorch head that plugs directly into the seasonal Presto backbone. The helper `train_seasonal_torch_head()` handles class balancing, train/val/test splits, and a hyperparameter search over learning rate and weight decay, producing a ready-to-use seasonal head with comprehensive metrics, confusion matrices, and training logs written to disk.\n",
    "\n",
    "The resulting artifacts (model weights + config + packaged `.zip`) are stored under `./downstream_heads/<season_id>_<timestamp>/`. Keep this directory around: the zip bundle will be uploaded to CDSE in the next step and the config is reused whenever you redeploy or troubleshoot the head.\n",
    "\n",
    "Key parameters you can adjust:\n",
    "- `head_type`: Model architecture - `\"linear\"` for a simple linear classifier (default) or `\"mlp\"` for a multi-layer perceptron with more capacity\n",
    "- `epochs`: Number of training epochs (default: 40)\n",
    "- `lr_`: Learning rate (default: 1e-2)\n",
    "- `weight_decay`: L2 regularization strength (default: 0.0)\n",
    "- `use_balancing`: Whether to apply class balancing to handle imbalanced datasets (default: True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8237d6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from notebook_utils.classifier import train_seasonal_torch_head\n",
    "\n",
    "head_run_name = f\"{season_id}_{datetime.utcnow().strftime('%Y%m%d-%H%M%S')}\"\n",
    "head_output_dir = Path(\"./downstream_heads\") / head_run_name\n",
    "head_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "torch_head = train_seasonal_torch_head(\n",
    "    embeddings_df,\n",
    "    season_id=season_id,\n",
    "    head_task=\"croptype\",\n",
    "    output_dir=head_output_dir,\n",
    "    head_type=\"mlp\",  # \"mlp\" also supported\n",
    "    use_balancing=True,\n",
    ")\n",
    "\n",
    "head_config_path = head_output_dir / \"config.json\"\n",
    "if not head_config_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Torch head config not found at {head_config_path}. Check the training logs above.\"\n",
    "    )\n",
    "\n",
    "with head_config_path.open() as fp:\n",
    "    head_config = json.load(fp)\n",
    "\n",
    "head_package_name = head_config[\"artifacts\"][\"packages\"][\"head\"]\n",
    "head_package_path = head_output_dir / head_package_name\n",
    "print(f\"Torch head saved to: {head_output_dir}\")\n",
    "print(f\"Packaged archive ready at: {head_package_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87456094",
   "metadata": {},
   "source": [
    "### 3. Deploy your custom torch head\n",
    "\n",
    "The training step produced a zipped bundle containing the PyTorch weights plus the accompanying configuration metadata. Upload that `.zip` file to the secure CDSE artifact bucket so the openEO workflow can download it during map generation. The next cell reads `head_package_path` from the previous step, prompts you to choose a short identifier for storage, and returns a presigned download URL to use in the production workflow.\n",
    "\n",
    "Keep a local copy of the entire `downstream_heads/<season_id>_<timestamp>/` directory‚Äîthe archive and `config.json` are required if you ever need to redeploy the same head, inspect its metadata, or troubleshoot issues. The cloud copy has a limited retention period."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f1649",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>CDSE authentication:</b><br>\n",
    "After first login, your CDSE credentials will be stored on your machine avoiding the need for repeating authentication in the future. If you would want to switch CDSE account, execute the following lines of code:<br>\n",
    "<br>\n",
    "from notebook_utils.openeo import clear_openeo_token_cache<br>\n",
    "clear_openeo_token_cache()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0ece5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import get_input\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "from worldcereal.utils.upload import OpenEOArtifactHelper\n",
    "\n",
    "if \"head_package_path\" not in globals():\n",
    "    raise ValueError(\n",
    "        \"Run the torch head training cell first so `head_package_path` is defined.\"\n",
    "    )\n",
    "if not head_package_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Torch head archive not found at {head_package_path}. Re-run the training step.\"\n",
    "    )\n",
    "\n",
    "modelname = get_input(\"model identifier (for storage)\")\n",
    "artifact_helper = OpenEOArtifactHelper.from_openeo_connection(cdse_connection())\n",
    "target_object_name = f\"{modelname}_{head_package_path.name}\"\n",
    "print(f\"Uploading torch head archive as {target_object_name} ...\")\n",
    "\n",
    "model_s3_uri = artifact_helper.upload_file(target_object_name, str(head_package_path))\n",
    "model_url = artifact_helper.get_presigned_url(model_s3_uri)\n",
    "\n",
    "print(f\"S3 URI: {model_s3_uri}\")\n",
    "print(f\"Your torch head can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4204b6",
   "metadata": {},
   "source": [
    "### 4. Generate your custom crop type map\n",
    "\n",
    "Using your custom model, we generate a map for your region and season of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63748f",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest (AOI)**\n",
    "\n",
    "Provide a bounding box specifying the region for which you would like to create your map.<br>\n",
    "The WorldCereal system is currently optimized to process <b>20 x 20 km</b> tiles.<br>\n",
    "In case your AOI exceeds this area, it will be automatically split, creating multiple map generation jobs.<br>\n",
    "\n",
    "Every processing job will consume a number of CDSE credits (depending on size). <br>\n",
    "Every CDSE user has 10,000 processing credits available each month for free.<br>\n",
    "Additional credits can be purchased to support large-scale processing.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>IMPORTANT NOTES ON UPSCALING:</b><br> \n",
    "\n",
    "- We ALWAYS recommend you to first run the model on a <b>representative set of small test areas</b> (up to 100 km¬≤) to visually check for model performance BEFORE upscaling to large areas!!\n",
    "\n",
    "- By default, CDSE users are limited to running 2 processing jobs in parallel. This will result in long processing times for large areas. When engaging in country-scale mapping, we therefore recommend to <b>contact the WorldCereal team</b> for dedicated support to speed up processing through [our contact form](https://esa-worldcereal.org/en/contact).\n",
    "\n",
    "</div>\n",
    "\n",
    "We refer to [Section 1 of this notebook](###-1.-Gather-and-prepare-your-training-data) for instructions on how to use our interactive application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101aae5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map(area_limit=1200) # area_limit in km¬≤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2c9627",
   "metadata": {},
   "source": [
    "Optionally save your drawn bounding box to a file for future reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4ab9d4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.production import bbox_extent_to_gdf\n",
    "from pathlib import Path\n",
    "\n",
    "bbox_name = input('Enter the name for the output bbox file (without extension): ')\n",
    "outfile = Path(f'./bbox/{bbox_name}.gpkg')\n",
    "processing_extent = map.get_extent(projection='latlon')\n",
    "bbox_extent_to_gdf(processing_extent, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0f342",
   "metadata": {},
   "source": [
    "**Step 2: Confirm your year and season of interest**\n",
    "\n",
    "We automatically reuse the growing-season window (and derived processing period) that you selected earlier in this notebook during Step 4. The same season window used for training will be applied during inference to ensure consistency.\n",
    "\n",
    "If you need to target a different year or shift the window, scroll back to *Step 4: Select your season of interest*, adjust the slider, rerun the alignment and embedding computation cells, and then return here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4b58e",
   "metadata": {},
   "source": [
    "**Step 3: Set processing parameters**\n",
    "\n",
    "Configure the inference and post-processing parameters:\n",
    "\n",
    "- `mask_cropland`: Apply cropland masking during croptype predictions (recommended: True)\n",
    "- `enable_cropland_head`: Also export cropland probability rasters for quality assurance (default: True)\n",
    "- `export_class_probs`: Emit per-class probability layers for each crop type (default: True)\n",
    "- `croptype_postprocess_enabled`: Apply spatial post-processing to croptype classifications (default: True)\n",
    "- `croptype_postprocess_method`: Post-processing algorithm (e.g., \"majority_vote\")\n",
    "- `croptype_postprocess_kernel`: Kernel size for post-processing filter (default: 5)\n",
    "- `cropland_postprocess_enabled`: Apply spatial post-processing to cropland mask (default: True)\n",
    "- `cropland_postprocess_method`: Post-processing algorithm for cropland\n",
    "- `cropland_postprocess_kernel`: Kernel size for cropland post-processing (default: 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefd58a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Seasonal inference knobs for the Phase II workflow.\n",
    "mask_cropland = True  # keep cropland gating when running croptype predictions\n",
    "enable_cropland_head = True  # also export cropland rasters for QA\n",
    "export_class_probs = True  # emit per-class probabilities for each selected season\n",
    "\n",
    "croptype_postprocess_enabled = True\n",
    "croptype_postprocess_method = \"majority_vote\"\n",
    "croptype_postprocess_kernel = 5\n",
    "\n",
    "cropland_postprocess_enabled = True\n",
    "cropland_postprocess_method = \"majority_vote\"\n",
    "cropland_postprocess_kernel = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf0683",
   "metadata": {},
   "source": [
    "**Step 4: Start map production**\n",
    "\n",
    "The next cell configures and launches the production workflow:\n",
    "\n",
    "1. **Configuration**: Builds a workflow configuration using your trained model URL, season selection, and processing parameters\n",
    "2. **Tiling**: Splits your area of interest into tiles (default: 50x50 km) for parallel processing\n",
    "3. **Execution**: Launches OpenEO jobs to generate crop type maps for each tile\n",
    "\n",
    "You will be able to track progress through automated reporting. Progress is displayed in real-time and saved to the output directory.\n",
    "\n",
    "As a free tier CDSE user, individual processing jobs can take several hours depending on system load. Results are automatically saved to: `runs/CROPTYPE_custom_{your_modelname}_{timestamp}`\n",
    "\n",
    "The first time you run this, you will be prompted to authenticate with your CDSE account.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>How to stop processing?</b><br> \n",
    "Simply interrupt the Python kernel to stop processing.<br>\n",
    "Make sure to manually cancel any running jobs in the backend to avoid unnecessary costs!<br>\n",
    "For this, visit the job tracking page in the\n",
    "<a href='https://openeo.dataspace.copernicus.eu/' target='_blank' rel='noopener'>CDSE backend dashboard</a> <br><br>\n",
    "\n",
    "<b>What to do in case of interruption?</b><br> \n",
    "In case processing got interrupted, just make sure to manually set `output_dir` to the directory you previously used. When running the below cell again, processing will just continue where it stopped.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from worldcereal.parameters import WorldCerealProductType\n",
    "from worldcereal.openeo.workflow_config import WorldCerealWorkflowConfig\n",
    "from notebook_utils.production import run_map_production\n",
    "\n",
    "# The output directory is named after the model\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_dir = Path('./runs') / f'CROPTYPE_custom_{modelname}_{timestamp}'\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Retrieve the derived season + processing windows from the slider selection\n",
    "selection = slider.get_selection()\n",
    "processing_period = selection.processing_period\n",
    "season_window = selection.season_window\n",
    "selected_season_id = season_id\n",
    "season_windows = {\n",
    "    selected_season_id: (\n",
    "        str(season_window.start_date),\n",
    "        str(season_window.end_date),\n",
    "    )\n",
    "}\n",
    "\n",
    "# Parameterize the workflow\n",
    "workflow_builder = (\n",
    "    WorldCerealWorkflowConfig.builder()\n",
    "    .season_ids([selected_season_id])\n",
    "    .season_windows(season_windows)\n",
    "    .croptype_head_zip(model_url)\n",
    "    .enable_croptype_head(True)\n",
    "    .enable_cropland_head(enable_cropland_head)\n",
    "    .enforce_cropland_gate(mask_cropland)\n",
    "    .export_class_probabilities(export_class_probs)\n",
    ")\n",
    "workflow_builder = workflow_builder.cropland_postprocess(\n",
    "    enabled=cropland_postprocess_enabled,\n",
    "    method=cropland_postprocess_method,\n",
    "    kernel_size=cropland_postprocess_kernel,\n",
    ")\n",
    "workflow_builder = workflow_builder.croptype_postprocess(\n",
    "    enabled=croptype_postprocess_enabled,\n",
    "    method=croptype_postprocess_method,\n",
    "    kernel_size=croptype_postprocess_kernel,\n",
    ")\n",
    "workflow_config = workflow_builder.build()\n",
    "\n",
    "# Get processing area\n",
    "processing_extent = map.get_extent(projection='latlon')\n",
    "tile_resolution = 50   # in km\n",
    "\n",
    "# Run the production workflow with the specified parameters and retrieve the status dataframe\n",
    "status_df = run_map_production(\n",
    "    spatial_extent= processing_extent,\n",
    "    temporal_extent= processing_period,\n",
    "    output_dir= output_dir,\n",
    "    tile_resolution= tile_resolution,\n",
    "    product_type= WorldCerealProductType.CROPTYPE,\n",
    "    workflow_config=workflow_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156038d",
   "metadata": {},
   "source": [
    "**Step 5: Create merged product**\n",
    "\n",
    "Once production across your tiles is finalized, you can use the cell below to merge the different tiles together into one map.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.production import merge_maps\n",
    "\n",
    "merged_paths = merge_maps(output_dir)\n",
    "merged_list = \"\\n\".join(\n",
    "    f\"{name} -> {path}\"\n",
    "    for name, path in merged_paths.items()\n",
    ")\n",
    "print(\"Results merged:\\n\" + merged_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76baf63",
   "metadata": {},
   "source": [
    "**Step 6: Inspect your map**\n",
    "\n",
    "Up to four products are generated depending on your configuration settings:\n",
    "- `croptype-raw` ‚Üí Your custom crop type product (raw model output)\n",
    "- `croptype` ‚Üí Your custom crop type product after spatial post-processing (if enabled)\n",
    "- `cropland-raw` ‚Üí Cropland mask produced using the global WorldCereal cropland model (if enabled)\n",
    "- `cropland` ‚Üí Cropland mask after spatial post-processing (if enabled)\n",
    "\n",
    "For each of these products, you will get a raster file containing multiple bands:\n",
    "1. **Classification band**: The label of the winning class\n",
    "2. **Confidence band**: The probability of the winning class [50-100]\n",
    "3. **Class probability bands** (optional, if `export_class_probabilities=True`): Individual probability layers for each crop type class in your model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daedb2a",
   "metadata": {},
   "source": [
    "You can use the next cell to quickly visualize your products in this notebook.\n",
    "\n",
    "The visualization loads the class metadata from your trained torch head artifact to properly display crop type labels and creates an interactive map showing your classification and probability layers.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Supported visualization modes:</b><br>\n",
    "By default (`interactive_mode=False`), your product is shown using matplotlib for quick visual inspection.<br>\n",
    "By setting `interactive_mode=True`, both your classification and probability layers will be visualized in an interactive ipyleaflet window. You can toggle individual layers on/off using the layer control in the upper-right corner.\n",
    "\n",
    "<b>NOTE:</b> For the interactive mode to work in a VSCode environment, you need to enable port forwarding for port 8889.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_products\n",
    "from worldcereal.openeo.inference import load_model_artifact\n",
    "\n",
    "if \"model_url\" not in globals():\n",
    "    raise ValueError(\n",
    "        \"`model_url` is undefined. Upload your torch head archive before visualizing the map.\",\n",
    "    )\n",
    "\n",
    "artifact = load_model_artifact(model_url)\n",
    "heads = artifact.manifest.get(\"heads\", [])\n",
    "luts = {}\n",
    "for task in (\"cropland\", \"croptype\"):\n",
    "    head = next(\n",
    "        (head for head in heads if head.get(\"task\") == task), None\n",
    "    )\n",
    "    if head and head.get(\"class_names\"):\n",
    "        luts[task] = {\n",
    "            name: idx for idx, name in enumerate(head[\"class_names\"])\n",
    "        }\n",
    "if \"croptype\" not in luts:\n",
    "    raise ValueError(\"Torch head manifest is missing croptype class metadata.\")\n",
    "\n",
    "visualize_products(merged_paths, luts=luts, interactive_mode=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47960734",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
