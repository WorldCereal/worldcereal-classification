{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Create WorldCereal Croptype UDP\n",
                "\n",
                "This notebook is a step-by-step guide to create a new `worldcereal_crop_type` UDP based on the user's current `worldcereal-classification` version present in the environment used to run this notebook. "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Set some postprocess parameters. They will be parametrized in the UDP anyway, so these can be left unchanged."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from worldcereal.job import PostprocessParameters\n",
                "\n",
                "### OPTIONAL PARAMETERS\n",
                "\n",
                "# Choose whether you want to store the cropland mask as separate output file\n",
                "save_mask = True\n",
                "\n",
                "# Choose whether or not you want to spatially clean the classification results\n",
                "postprocess_result = True\n",
                "\n",
                "# Choose the postprocessing method you want to use [\"smooth_probabilities\", \"majority_vote\"]\n",
                "# (\"smooth_probabilities will do limited spatial cleaning,\n",
                "# while \"majority_vote\" will do more aggressive spatial cleaning, depending on the value of kernel_size)\n",
                "postprocess_method = \"majority_vote\"\n",
                "\n",
                "# Additional parameter for the majority vote method\n",
                "# (the higher the value, the more aggressive the spatial cleaning,\n",
                "# should be an odd number, not larger than 25, default = 5)\n",
                "kernel_size = 5\n",
                "\n",
                "# Do you want to save the intermediate results? (before applying the postprocessing)\n",
                "save_intermediate = True\n",
                "\n",
                "# Do you want to save all class probabilities in the final product? (default is False)\n",
                "keep_class_probs = True\n",
                "\n",
                "postprocess_parameters = PostprocessParameters(\n",
                "    enable=postprocess_result,\n",
                "    method=postprocess_method,\n",
                "    kernel_size=kernel_size,\n",
                "    save_intermediate=save_intermediate,\n",
                "    keep_class_probs=keep_class_probs,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, define all cropland/croptype parameters and the spatiotemporal extent. Again, since they will be paramatrized anyway in the UDP, these can be left unchanged by the user as well."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from worldcereal.job import CropLandParameters, CropTypeParameters\n",
                "from openeo_gfmap import TemporalContext, BoundingBoxExtent\n",
                "\n",
                "# Initializes default parameters\n",
                "cropland_parameters = CropLandParameters()\n",
                "croptype_parameters = CropTypeParameters()\n",
                "\n",
                "model_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/tests/be_multiclass-test_custommodel.onnx\"\n",
                "\n",
                "# Customize the parameters\n",
                "cropland_parameters.feature_parameters.compile_presto = True\n",
                "\n",
                "croptype_parameters.classifier_parameters.classifier_url = model_url\n",
                "croptype_parameters.save_mask = save_mask\n",
                "croptype_parameters.feature_parameters.compile_presto = True\n",
                "\n",
                "# Get processing period and area\n",
                "# temporal_extent = TemporalContext(start_date='2020-12-01', end_date='2021-11-30') \n",
                "# spatial_extent = BoundingBoxExtent(west=549260.0538727192, south=5643096.65598935, east=550221.062129418, north=5643965.825801395, epsg=32631) \n",
                "\n",
                "\n",
                "temporal_extent = TemporalContext(start_date=\"2023-10-01\", end_date=\"2024-09-30\") \n",
                "spatial_extent = BoundingBoxExtent(west=664000, south=5611134, east=684000, north=5631134, epsg=32631) \n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Next, we call the `create_inference_process_graph` function from the `worldcereal-classification` repository. This function will return an openEO process graph, which will form the basis for the UDP."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Authenticated using refresh token.\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "2025-07-23 11:31:43,280 - openeo_gfmap.utils - INFO - Selected orbit state: ASCENDING. Reason: Orbit has more cumulative intersected area. 13.033136612383506 > 7.983154394462191\n"
                    ]
                }
            ],
            "source": [
                "from worldcereal.job import WorldCerealProductType, create_inference_process_graph\n",
                "from openeo_gfmap import BackendContext, Backend\n",
                "\n",
                "pg = create_inference_process_graph(\n",
                "    spatial_extent=spatial_extent,\n",
                "    temporal_extent=temporal_extent,\n",
                "    product_type=WorldCerealProductType.CROPTYPE,\n",
                "    cropland_parameters=cropland_parameters,\n",
                "    croptype_parameters=croptype_parameters,\n",
                "    postprocess_parameters=postprocess_parameters,\n",
                "    backend_context=BackendContext(Backend.CDSE)\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "OPTIONAL: in case you want to make sure the process graph works (for example, in case you made changes to the `worldcereal-classification` codebase). You can send the process graph to the CDSE backend in order to run it and see if it runs successfully and produces meaningful results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0:00:00 Job 'j-2507230931534eb5a46172271a92d8ce': send 'start'\n",
                        "0:00:14 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:00:19 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:00:26 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:00:34 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:00:44 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:00:57 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:01:13 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:01:32 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:01:57 Job 'j-2507230931534eb5a46172271a92d8ce': queued (progress 0%)\n",
                        "0:02:28 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:03:07 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:03:55 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:04:54 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:05:55 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:06:56 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:07:57 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:08:57 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:09:58 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:10:59 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:12:00 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:13:01 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:14:02 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:15:02 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:16:03 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:17:04 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:18:05 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:19:05 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:20:06 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:21:07 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:22:08 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:23:08 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:24:09 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:25:10 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:26:11 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:27:11 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:28:12 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:29:13 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:30:14 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:31:14 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:32:15 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:33:16 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:34:17 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:35:18 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:36:19 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:37:19 Job 'j-2507230931534eb5a46172271a92d8ce': running (progress N/A)\n",
                        "0:38:20 Job 'j-2507230931534eb5a46172271a92d8ce': finished (progress 100%)\n"
                    ]
                },
                {
                    "data": {
                        "text/html": [
                            "\n",
                            "    <script>\n",
                            "    if (!window.customElements || !window.customElements.get('openeo-job')) {\n",
                            "        var el = document.createElement('script');\n",
                            "        el.src = \"https://cdn.jsdelivr.net/npm/@openeo/vue-components@2/assets/openeo.min.js\";\n",
                            "        document.head.appendChild(el);\n",
                            "\n",
                            "        var font = document.createElement('font');\n",
                            "        font.as = \"font\";\n",
                            "        font.type = \"font/woff2\";\n",
                            "        font.crossOrigin = true;\n",
                            "        font.href = \"https://use.fontawesome.com/releases/v5.13.0/webfonts/fa-solid-900.woff2\"\n",
                            "        document.head.appendChild(font);\n",
                            "    }\n",
                            "    </script>\n",
                            "    <openeo-job>\n",
                            "        <script type=\"application/json\">{\"currency\": \"credits\", \"job\": {\"costs\": 99, \"created\": \"2025-07-23T09:31:53Z\", \"id\": \"j-2507230931534eb5a46172271a92d8ce\", \"process\": {\"process_graph\": {\"aggregatetemporalperiod1\": {\"arguments\": {\"data\": {\"from_node\": \"apply1\"}, \"dimension\": \"t\", \"period\": \"month\", \"reducer\": {\"process_graph\": {\"median1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"median\", \"result\": true}}}}, \"process_id\": \"aggregate_temporal_period\"}, \"aggregatetemporalperiod2\": {\"arguments\": {\"data\": {\"from_node\": \"renamelabels3\"}, \"dimension\": \"t\", \"period\": \"month\", \"reducer\": {\"process_graph\": {\"mean1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"mean\", \"result\": true}}}}, \"process_id\": \"aggregate_temporal_period\"}, \"apply1\": {\"arguments\": {\"data\": {\"from_node\": \"renamelabels2\"}, \"process\": {\"process_graph\": {\"linearscalerange1\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 0, \"outputMax\": 65534, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply2\": {\"arguments\": {\"data\": {\"from_node\": \"aggregatetemporalperiod1\"}, \"process\": {\"process_graph\": {\"linearscalerange2\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 0, \"outputMax\": 65534, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply3\": {\"arguments\": {\"data\": {\"from_node\": \"applydimension1\"}, \"process\": {\"process_graph\": {\"linearscalerange3\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 1, \"outputMax\": 65534, \"outputMin\": 1, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply4\": {\"arguments\": {\"data\": {\"from_node\": \"resamplecubespatial1\"}, \"process\": {\"process_graph\": {\"linearscalerange4\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 0, \"outputMax\": 65534, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply5\": {\"arguments\": {\"data\": {\"from_node\": \"applyneighborhood5\"}, \"process\": {\"process_graph\": {\"linearscalerange5\": {\"arguments\": {\"inputMax\": 253, \"inputMin\": 0, \"outputMax\": 253, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply6\": {\"arguments\": {\"data\": {\"from_node\": \"filterbands1\"}, \"process\": {\"process_graph\": {\"eq3\": {\"arguments\": {\"x\": {\"from_parameter\": \"x\"}, \"y\": 0}, \"process_id\": \"eq\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"apply7\": {\"arguments\": {\"data\": {\"from_node\": \"applyneighborhood6\"}, \"process\": {\"process_graph\": {\"linearscalerange6\": {\"arguments\": {\"inputMax\": 65534, \"inputMin\": 0, \"outputMax\": 65534, \"outputMin\": 0, \"x\": {\"from_parameter\": \"x\"}}, \"process_id\": \"linear_scale_range\", \"result\": true}}}}, \"process_id\": \"apply\"}, \"applydimension1\": {\"arguments\": {\"data\": {\"from_node\": \"aggregatetemporalperiod2\"}, \"dimension\": \"bands\", \"process\": {\"process_graph\": {\"add1\": {\"arguments\": {\"x\": {\"from_node\": \"multiply1\"}, \"y\": 83.0}, \"process_id\": \"add\"}, \"add2\": {\"arguments\": {\"x\": {\"from_node\": \"multiply2\"}, \"y\": 83.0}, \"process_id\": \"add\"}, \"arraycreate1\": {\"arguments\": {\"data\": [{\"from_node\": \"power1\"}, {\"from_node\": \"power2\"}]}, \"process_id\": \"array_create\", \"result\": true}, \"arrayelement1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 0}, \"process_id\": \"array_element\"}, \"arrayelement2\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}, \"index\": 1}, \"process_id\": \"array_element\"}, \"divide1\": {\"arguments\": {\"x\": {\"from_node\": \"add1\"}, \"y\": 20.0}, \"process_id\": \"divide\"}, \"divide2\": {\"arguments\": {\"x\": {\"from_node\": \"add2\"}, \"y\": 20.0}, \"process_id\": \"divide\"}, \"log1\": {\"arguments\": {\"base\": 10, \"x\": {\"from_node\": \"arrayelement1\"}}, \"process_id\": \"log\"}, \"log2\": {\"arguments\": {\"base\": 10, \"x\": {\"from_node\": \"arrayelement2\"}}, \"process_id\": \"log\"}, \"multiply1\": {\"arguments\": {\"x\": 10.0, \"y\": {\"from_node\": \"log1\"}}, \"process_id\": \"multiply\"}, \"multiply2\": {\"arguments\": {\"x\": 10.0, \"y\": {\"from_node\": \"log2\"}}, \"process_id\": \"multiply\"}, \"power1\": {\"arguments\": {\"base\": 10, \"p\": {\"from_node\": \"divide1\"}}, \"process_id\": \"power\"}, \"power2\": {\"arguments\": {\"base\": 10, \"p\": {\"from_node\": \"divide2\"}}, \"process_id\": \"power\"}}}}, \"process_id\": \"apply_dimension\"}, \"applyneighborhood1\": {\"arguments\": {\"data\": {\"from_node\": \"filterbbox1\"}, \"overlap\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 0}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 0}], \"process\": {\"process_graph\": {\"runudf1\": {\"arguments\": {\"context\": {\"compile_presto\": true, \"presto_model_url\": \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/presto-prometheo-landcover-month-CROPTYPE27-augment%3DTrue-balance%3DTrue-timeexplicit%3DTrue-run%3D202507181013_encoder.pt\", \"rescale_s1\": false, \"target_date\": null, \"temporal_prediction\": true}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"\\\"\\\"\\\"Feature computer GFMAP compatible to compute Presto embeddings.\\\"\\\"\\\"\\n\\nimport copy\\nimport functools\\nimport random\\nimport sys\\nimport urllib.request\\nimport zipfile\\nfrom pathlib import Path\\nfrom typing import Optional\\n\\nimport numpy as np\\nimport xarray as xr\\nfrom openeo.metadata import CollectionMetadata\\nfrom openeo.udf import XarrayDataCube\\nfrom openeo.udf.udf_data import UdfData\\nfrom pyproj import Transformer\\nfrom pyproj.crs import CRS\\nfrom scipy.ndimage import (\\n    convolve,\\n    zoom,\\n)\\nfrom shapely.geometry import Point\\nfrom shapely.ops import transform\\n\\nsys.path.append(\\\"feature_deps\\\")\\n\\nimport torch  # noqa: E402\\n\\nPROMETHEO_WHL_URL = \\\"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/dependencies/prometheo-0.0.2-py3-none-any.whl\\\"\\n\\nGFMAP_BAND_MAPPING = {\\n    \\\"S2-L2A-B02\\\": \\\"B2\\\",\\n    \\\"S2-L2A-B03\\\": \\\"B3\\\",\\n    \\\"S2-L2A-B04\\\": \\\"B4\\\",\\n    \\\"S2-L2A-B05\\\": \\\"B5\\\",\\n    \\\"S2-L2A-B06\\\": \\\"B6\\\",\\n    \\\"S2-L2A-B07\\\": \\\"B7\\\",\\n    \\\"S2-L2A-B08\\\": \\\"B8\\\",\\n    \\\"S2-L2A-B8A\\\": \\\"B8A\\\",\\n    \\\"S2-L2A-B11\\\": \\\"B11\\\",\\n    \\\"S2-L2A-B12\\\": \\\"B12\\\",\\n    \\\"S1-SIGMA0-VH\\\": \\\"VH\\\",\\n    \\\"S1-SIGMA0-VV\\\": \\\"VV\\\",\\n    \\\"AGERA5-TMEAN\\\": \\\"temperature_2m\\\",\\n    \\\"AGERA5-PRECIP\\\": \\\"total_precipitation\\\",\\n}\\n\\nLAT_HARMONIZED_NAME = \\\"GEO-LAT\\\"\\nLON_HARMONIZED_NAME = \\\"GEO-LON\\\"\\nEPSG_HARMONIZED_NAME = \\\"GEO-EPSG\\\"\\n\\n\\n@functools.lru_cache(maxsize=6)\\ndef unpack_prometheo_wheel(wheel_url: str):\\n    destination_dir = Path.cwd() / \\\"dependencies\\\" / \\\"prometheo\\\"\\n    destination_dir.mkdir(exist_ok=True, parents=True)\\n\\n    # Downloads the wheel file\\n    modelfile, _ = urllib.request.urlretrieve(\\n        wheel_url, filename=Path.cwd() / Path(wheel_url).name\\n    )\\n    with zipfile.ZipFile(modelfile, \\\"r\\\") as zip_ref:\\n        zip_ref.extractall(destination_dir)\\n    return destination_dir\\n\\n\\n@functools.lru_cache(maxsize=6)\\ndef compile_encoder(presto_encoder):\\n    \\\"\\\"\\\"Helper function that compiles the encoder of a Presto model\\n    and performs a warm-up on dummy data. The lru_cache decorator\\n    ensures caching on compute nodes to be able to actually benefit\\n    from the compilation process.\\n\\n    Parameters\\n    ----------\\n    presto_encoder : nn.Module\\n        Encoder part of Presto model to compile\\n\\n    \\\"\\\"\\\"\\n\\n    presto_encoder = torch.compile(presto_encoder)  # type: ignore\\n\\n    for _ in range(3):\\n        presto_encoder(\\n            torch.rand((1, 12, 17)),\\n            torch.ones((1, 12)).long(),\\n            torch.rand(1, 2),\\n        )\\n\\n    return presto_encoder\\n\\n\\ndef get_output_labels() -> list:\\n    \\\"\\\"\\\"Returns the output labels from this UDF, which is the output labels\\n    of the presto embeddings\\\"\\\"\\\"\\n    return [f\\\"presto_ft_{i}\\\" for i in range(128)]\\n\\n\\ndef evaluate_resolution(inarr: xr.DataArray, epsg: int) -> int:\\n    \\\"\\\"\\\"Helper function to get the resolution in meters for\\n    the input array.\\n\\n    Parameters\\n    ----------\\n    inarr : xr.DataArray\\n        input array to determine resolution for.\\n\\n    Returns\\n    -------\\n    int\\n        resolution in meters.\\n    \\\"\\\"\\\"\\n\\n    if epsg == 4326:\\n        # self.logger.info(\\n        #     \\\"Converting WGS84 coordinates to EPSG:3857 to determine resolution.\\\"\\n        # )\\n\\n        transformer = Transformer.from_crs(epsg, 3857, always_xy=True)\\n        points = [Point(x, y) for x, y in zip(inarr.x.values, inarr.y.values)]\\n        points = [transform(transformer.transform, point) for point in points]\\n\\n        resolution = abs(points[1].x - points[0].x)\\n\\n    else:\\n        resolution = abs(inarr.x[1].values - inarr.x[0].values)\\n\\n    # self.logger.info(f\\\"Resolution for computing slope: {resolution}\\\")\\n\\n    return resolution\\n\\n\\ndef compute_slope(inarr: xr.DataArray, resolution: int) -> xr.DataArray:\\n    \\\"\\\"\\\"Computes the slope using the scipy library. The input array should\\n    have the following bands: 'elevation' And no time dimension. Returns a\\n    new DataArray containing the new `slope` band.\\n\\n    Parameters\\n    ----------\\n    inarr : xr.DataArray\\n        input array containing a band 'elevation'.\\n    resolution : int\\n        resolution of the input array in meters.\\n\\n    Returns\\n    -------\\n    xr.DataArray\\n        output array containing 'slope' band in degrees.\\n    \\\"\\\"\\\"\\n\\n    def _rolling_fill(darr, max_iter=2):\\n        \\\"\\\"\\\"Helper function that also reflects values inside\\n        a patch with NaNs.\\\"\\\"\\\"\\n        if max_iter == 0:\\n            return darr\\n        else:\\n            max_iter -= 1\\n        # arr of shape (rows, cols)\\n        mask = np.isnan(darr)\\n\\n        if ~np.any(mask):\\n            return darr\\n\\n        roll_params = [(0, 1), (0, -1), (1, 0), (-1, 0)]\\n        random.shuffle(roll_params)\\n\\n        for roll_param in roll_params:\\n            rolled = np.roll(darr, roll_param, axis=(0, 1))\\n            darr[mask] = rolled[mask]\\n\\n        return _rolling_fill(darr, max_iter=max_iter)\\n\\n    def _downsample(arr: np.ndarray, factor: int) -> np.ndarray:\\n        \\\"\\\"\\\"Downsamples a 2D NumPy array by a given factor with average resampling and reflect padding.\\n\\n        Parameters\\n        ----------\\n        arr : np.ndarray\\n            The 2D input array.\\n        factor : int\\n            The factor by which to downsample. For example, factor=2 downsamples by 2x.\\n\\n        Returns\\n        -------\\n        np.ndarray\\n            Downsampled array.\\n        \\\"\\\"\\\"\\n\\n        # Get the original shape of the array\\n        X, Y = arr.shape\\n\\n        # Calculate how much padding is needed for each dimension\\n        pad_X = (\\n            factor - (X % factor)\\n        ) % factor  # Ensures padding is only applied if needed\\n        pad_Y = (\\n            factor - (Y % factor)\\n        ) % factor  # Ensures padding is only applied if needed\\n\\n        # Pad the array using 'reflect' mode\\n        padded = np.pad(arr, ((0, pad_X), (0, pad_Y)), mode=\\\"reflect\\\")\\n\\n        # Reshape the array to form blocks of size 'factor' x 'factor'\\n        reshaped = padded.reshape(\\n            (X + pad_X) // factor, factor, (Y + pad_Y) // factor, factor\\n        )\\n\\n        # Take the mean over the factor-sized blocks\\n        downsampled = np.nanmean(reshaped, axis=(1, 3))\\n\\n        return downsampled\\n\\n    dem = inarr.sel(bands=\\\"elevation\\\").values\\n    dem_arr = dem.astype(np.float32)\\n\\n    # Invalid to NaN and keep track of these pixels\\n    dem_arr[dem_arr == 65535] = np.nan\\n    idx_invalid = np.isnan(dem_arr)\\n\\n    # Fill NaNs with rolling fill\\n    dem_arr = _rolling_fill(dem_arr)\\n\\n    # We make sure DEM is at 20m for slope computation\\n    # compatible with global slope collection\\n    factor = int(20 / resolution)\\n    if factor < 1 or factor % 2 != 0:\\n        raise NotImplementedError(\\n            f\\\"Unsupported resolution for slope computation: {resolution}\\\"\\n        )\\n    dem_arr_downsampled = _downsample(dem_arr, factor)\\n    x_odd, y_odd = dem_arr.shape[0] % 2 != 0, dem_arr.shape[1] % 2 != 0\\n\\n    # Mask NaN values in the DEM data\\n    dem_masked = np.ma.masked_invalid(dem_arr_downsampled)\\n\\n    # Define convolution kernels for x and y gradients (simple finite difference approximation)\\n    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) / (\\n        8.0 * 20  # array is now at 20m resolution\\n    )  # x-derivative kernel\\n\\n    kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]) / (\\n        8.0 * 20  # array is now at 20m resolution\\n    )  # y-derivative kernel\\n\\n    # Apply convolution to compute gradients\\n    dx = convolve(dem_masked, kernel_x)  # Gradient in the x-direction\\n    dy = convolve(dem_masked, kernel_y)  # Gradient in the y-direction\\n\\n    # Reapply the mask to the gradients\\n    dx = np.ma.masked_where(dem_masked.mask, dx)\\n    dy = np.ma.masked_where(dem_masked.mask, dy)\\n\\n    # Calculate the magnitude of the gradient (rise/run)\\n    gradient_magnitude = np.ma.sqrt(dx**2 + dy**2)\\n\\n    # Convert gradient magnitude to slope (in degrees)\\n    slope = np.ma.arctan(gradient_magnitude) * (180 / np.pi)\\n\\n    # Upsample to original resolution with bilinear interpolation\\n    mask = slope.mask\\n    mask = zoom(mask, zoom=factor, order=0)\\n    slope = zoom(slope, zoom=factor, order=1)\\n    slope[mask] = 65535\\n\\n    # Strip one row or column if original array was odd in that dimension\\n    if x_odd:\\n        slope = slope[:-1, :]\\n    if y_odd:\\n        slope = slope[:, :-1]\\n\\n    # Fill slope values where the original DEM had NaNs\\n    slope[idx_invalid] = 65535\\n    slope[np.isnan(slope)] = 65535\\n    slope = slope.astype(np.uint16)\\n\\n    return xr.DataArray(\\n        slope[None, :, :],\\n        dims=(\\\"bands\\\", \\\"y\\\", \\\"x\\\"),\\n        coords={\\n            \\\"bands\\\": [\\\"slope\\\"],\\n            \\\"y\\\": inarr.y,\\n            \\\"x\\\": inarr.x,\\n        },\\n    )\\n\\n\\ndef select_timestep_from_temporal_features(\\n    features: xr.DataArray, target_date: Optional[str] = None\\n) -> xr.DataArray:\\n    \\\"\\\"\\\"Select a specific timestep from temporal features based on target date.\\n\\n    Parameters\\n    ----------\\n    features : xr.DataArray\\n        Temporal features with time dimension preserved.\\n    target_date : str, optional\\n        Target date in ISO format (YYYY-MM-DD). If None, selects middle timestep.\\n\\n    Returns\\n    -------\\n    xr.DataArray\\n        Features for the selected timestep with time dimension removed.\\n    \\\"\\\"\\\"\\n    if target_date is None:\\n        # Select middle timestep\\n        mid_idx = len(features.t) // 2\\n        features = features.isel(t=mid_idx)\\n    else:\\n        # Parse target date and find closest timestep\\n        target_datetime = np.datetime64(target_date)\\n\\n        # Check if target_datetime is within the temporal extent of features\\n        min_time = features.t.min().values\\n        max_time = features.t.max().values\\n\\n        if target_datetime < min_time or target_datetime > max_time:\\n            raise ValueError(\\n                f\\\"Target date {target_date} is outside the temporal extent of features. \\\"\\n                f\\\"Available time range: {min_time} to {max_time}\\\"\\n            )\\n\\n        # Find closest timestep\\n        features = features.sel(t=target_datetime, method=\\\"nearest\\\")\\n\\n    return features\\n\\n\\ndef execute(inarr: xr.DataArray, parameters: dict, epsg: int) -> xr.DataArray:\\n    if epsg is None:\\n        raise ValueError(\\n            \\\"EPSG code is required for Presto feature extraction, but was \\\"\\n            \\\"not correctly initialized.\\\"\\n        )\\n    if \\\"presto_model_url\\\" not in parameters:\\n        raise ValueError('Missing required parameter \\\"presto_model_url\\\"')\\n\\n    presto_model_url = parameters.get(\\\"presto_model_url\\\")\\n    # self.logger.info(f'Loading Presto model from \\\"{presto_model_url}\\\"')\\n    prometheo_wheel_url = parameters.get(\\\"prometheo_wheel_url\\\", PROMETHEO_WHL_URL)\\n    # self.logger.info(f'Loading Prometheo wheel from \\\"{prometheo_wheel_url}\\\"')\\n\\n    ignore_dependencies = parameters.get(\\\"ignore_dependencies\\\", False)\\n    # if ignore_dependencies:\\n    # self.logger.info(\\n    #     \\\"`ignore_dependencies` flag is set to True. Make sure that \\\"\\n    #     \\\"Presto and its dependencies are available on the runtime \\\"\\n    #     \\\"environment\\\"\\n    # )\\n\\n    # The below is required to avoid flipping of the result\\n    # when running on OpenEO backend!\\n    inarr = inarr.transpose(\\\"bands\\\", \\\"t\\\", \\\"x\\\", \\\"y\\\")\\n\\n    # Change the band names\\n    new_band_names = [GFMAP_BAND_MAPPING.get(b.item(), b.item()) for b in inarr.bands]\\n    inarr = inarr.assign_coords(bands=new_band_names)\\n\\n    # Handle NaN values in Presto compatible way\\n    inarr = inarr.fillna(65535)\\n\\n    if not ignore_dependencies:\\n        # Unzip the Presto dependencies on the backend\\n        # self.logger.info(\\\"Unpacking prometheo wheel\\\")\\n        deps_dir = unpack_prometheo_wheel(prometheo_wheel_url)\\n\\n        # self.logger.info(\\\"Appending dependencies\\\")\\n        sys.path.append(str(deps_dir))\\n\\n    if \\\"slope\\\" not in inarr.bands:\\n        # If 'slope' is not present we need to compute it here\\n        # self.logger.warning(\\\"`slope` not found in input array. Computing ...\\\")\\n        resolution = evaluate_resolution(inarr.isel(t=0), epsg)\\n        slope = compute_slope(inarr.isel(t=0), resolution)\\n        slope = slope.expand_dims({\\\"t\\\": inarr.t}, axis=0).astype(\\\"float32\\\")\\n\\n        inarr = xr.concat([inarr.astype(\\\"float32\\\"), slope], dim=\\\"bands\\\")\\n\\n    batch_size = parameters.get(\\\"batch_size\\\", 256)\\n    temporal_prediction = parameters.get(\\\"temporal_prediction\\\", False)\\n    target_date = parameters.get(\\\"target_date\\\", None)\\n\\n    # TODO: compile_presto not used for now?\\n    # compile_presto = parameters.get(\\\"compile_presto\\\", False)\\n    # self.logger.info(f\\\"Compile presto: {compile_presto}\\\")\\n\\n    # self.logger.info(\\\"Loading Presto model for inference\\\")\\n\\n    # TODO: try to take run_model_inference from worldcereal\\n    from prometheo.datasets.worldcereal import run_model_inference\\n    from prometheo.models import Presto\\n    from prometheo.models.pooling import PoolingMethods\\n    from prometheo.models.presto.wrapper import load_presto_weights\\n\\n    presto_model = Presto()\\n    presto_model = load_presto_weights(presto_model, presto_model_url)\\n\\n    # self.logger.info(\\\"Extracting presto features\\\")\\n    # Check if we have the expected 12 timesteps\\n    if len(inarr.t) != 12:\\n        raise ValueError(f\\\"Can only run Presto on 12 timesteps, got: {len(inarr.t)}\\\")\\n\\n    # Determine pooling method based on temporal_prediction parameter\\n    pooling_method = (\\n        PoolingMethods.TIME if temporal_prediction else PoolingMethods.GLOBAL\\n    )\\n\\n    features = run_model_inference(\\n        inarr,\\n        presto_model,\\n        epsg=epsg,\\n        batch_size=batch_size,\\n        pooling_method=pooling_method,\\n    )\\n\\n    # If temporal prediction, select specific timestep based on target_date\\n    if temporal_prediction:\\n        features = select_timestep_from_temporal_features(features, target_date)\\n\\n    return features\\n\\n\\ndef get_latlons(inarr: xr.DataArray, epsg: int) -> xr.DataArray:\\n    \\\"\\\"\\\"Returns the latitude and longitude coordinates of the given array in\\n    a dataarray. Returns a dataarray with the same width/height of the input\\n    array, but with two bands, one for latitude and one for longitude. The\\n    metadata coordinates of the output array are the same as the input\\n    array, as the array wasn't reprojected but instead new features were\\n    computed.\\n\\n    The latitude and longitude band names are standardized to the names\\n    `LAT_HARMONIZED_NAME` and `LON_HARMONIZED_NAME` respectively.\\n    \\\"\\\"\\\"\\n\\n    lon = inarr.coords[\\\"x\\\"]\\n    lat = inarr.coords[\\\"y\\\"]\\n    lon, lat = np.meshgrid(lon, lat)\\n\\n    if epsg is None:\\n        raise Exception(\\n            \\\"EPSG code was not defined, cannot extract lat/lon array \\\"\\n            \\\"as the CRS is unknown.\\\"\\n        )\\n\\n    # If the coordiantes are not in EPSG:4326, we need to reproject them\\n    if epsg != 4326:\\n        # Initializes a pyproj reprojection object\\n        transformer = Transformer.from_crs(\\n            crs_from=CRS.from_epsg(epsg),\\n            crs_to=CRS.from_epsg(4326),\\n            always_xy=True,\\n        )\\n        lon, lat = transformer.transform(xx=lon, yy=lat)\\n\\n    # Create a two channel numpy array of the lat and lons together by stacking\\n    latlon = np.stack([lat, lon])\\n\\n    # Repack in a dataarray\\n    return xr.DataArray(\\n        latlon,\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": [LAT_HARMONIZED_NAME, LON_HARMONIZED_NAME],\\n            \\\"y\\\": inarr.coords[\\\"y\\\"],\\n            \\\"x\\\": inarr.coords[\\\"x\\\"],\\n        },\\n    )\\n\\n\\ndef rescale_s1_backscatter(arr: xr.DataArray) -> xr.DataArray:\\n    \\\"\\\"\\\"Rescales the input array from uint16 to float32 decibel values.\\n    The input array should be in uint16 format, as this optimizes memory usage in Open-EO\\n    processes. This function is called automatically on the bands of the input array, except\\n    if the parameter `rescale_s1` is set to False.\\n    \\\"\\\"\\\"\\n    s1_bands = [\\\"S1-SIGMA0-VV\\\", \\\"S1-SIGMA0-VH\\\", \\\"S1-SIGMA0-HV\\\", \\\"S1-SIGMA0-HH\\\"]\\n    s1_bands_to_select = list(set(arr.bands.values) & set(s1_bands))\\n\\n    if len(s1_bands_to_select) == 0:\\n        return arr\\n\\n    data_to_rescale = arr.sel(bands=s1_bands_to_select).astype(np.float32).data\\n\\n    # Assert that the values are set between 1 and 65535\\n    if data_to_rescale.min().item() < 1 or data_to_rescale.max().item() > 65535:\\n        raise ValueError(\\n            \\\"The input array should be in uint16 format, with values between 1 and 65535. \\\"\\n            \\\"This restriction assures that the data was processed according to the S1 fetcher \\\"\\n            \\\"preprocessor. The user can disable this scaling manually by setting the \\\"\\n            \\\"`rescale_s1` parameter to False in the feature extractor.\\\"\\n        )\\n\\n    # Converting back to power values\\n    data_to_rescale = 20.0 * np.log10(data_to_rescale) - 83.0\\n    data_to_rescale = np.power(10, data_to_rescale / 10.0)\\n    data_to_rescale[~np.isfinite(data_to_rescale)] = np.nan\\n\\n    # Converting power values to decibels\\n    data_to_rescale = 10.0 * np.log10(data_to_rescale)\\n\\n    # Change the bands within the array\\n    arr.loc[dict(bands=s1_bands_to_select)] = data_to_rescale\\n    return arr\\n\\n\\n# Below comes the actual UDF part\\n\\n\\n# Apply the Feature Extraction UDF\\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\\n    \\\"\\\"\\\"This is the actual openeo UDF that will be executed by the backend.\\\"\\\"\\\"\\n\\n    cube = udf_data.datacube_list[0]\\n    parameters = copy.deepcopy(udf_data.user_context)\\n\\n    proj = udf_data.proj\\n    if proj is not None:\\n        proj = proj[\\\"EPSG\\\"]\\n\\n    parameters[EPSG_HARMONIZED_NAME] = proj\\n\\n    arr = cube.get_array().transpose(\\\"bands\\\", \\\"t\\\", \\\"y\\\", \\\"x\\\")\\n\\n    epsg = parameters.pop(EPSG_HARMONIZED_NAME)\\n\\n    if parameters.get(\\\"rescale_s1\\\", True):\\n        arr = rescale_s1_backscatter(arr)\\n\\n    arr = execute(inarr=arr, parameters=parameters, epsg=epsg).transpose(\\n        \\\"bands\\\", \\\"y\\\", \\\"x\\\"\\n    )\\n\\n    cube = XarrayDataCube(arr)\\n\\n    udf_data.datacube_list = [cube]\\n\\n    return udf_data\\n\\n\\n# Change band names\\ndef apply_metadata(metadata: CollectionMetadata, context: dict) -> CollectionMetadata:\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=get_output_labels())\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}, \"size\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 128}]}, \"process_id\": \"apply_neighborhood\"}, \"applyneighborhood2\": {\"arguments\": {\"data\": {\"from_node\": \"applyneighborhood1\"}, \"overlap\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 0}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 0}], \"process\": {\"process_graph\": {\"runudf2\": {\"arguments\": {\"context\": {\"classifier_url\": \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/tests/be_multiclass-test_custommodel.onnx\"}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"\\\"\\\"\\\"Model inference on Presto feature for binary classication\\\"\\\"\\\"\\n\\nimport functools\\nimport sys\\nimport copy\\n\\nfrom openeo.udf.udf_data import UdfData\\nfrom openeo.udf import XarrayDataCube\\nfrom openeo.metadata import CollectionMetadata\\nimport numpy as np\\n\\nimport requests\\nimport xarray as xr\\n\\nsys.path.append(\\\"onnx_deps\\\")\\nimport onnxruntime as ort  # noqa: E402\\n\\nEPSG_HARMONIZED_NAME = \\\"GEO-EPSG\\\"\\n\\n\\n@functools.lru_cache(maxsize=6)\\ndef load_and_prepare_model(model_url: str):\\n    \\\"\\\"\\\"Function to be used instead the default GFMap load_ort_model function.\\n    Loads the model, validates it and extracts LUT from the model metadata.\\n\\n\\n    Parameters\\n    ----------\\n    model_url : str\\n        Public URL to the ONNX classification model.\\n    \\\"\\\"\\\"\\n    # Load the model\\n    response = requests.get(model_url, timeout=120)\\n    model = ort.InferenceSession(response.content)\\n\\n    # Validate the model\\n    metadata = model.get_modelmeta().custom_metadata_map\\n\\n    if \\\"class_params\\\" not in metadata:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    class_params = eval(metadata[\\\"class_params\\\"], {\\\"__builtins__\\\": None}, {})\\n\\n    if \\\"class_names\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    if \\\"class_to_label\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class to labels in the model metadata.\\\")\\n\\n    # Load model LUT\\n    lut = dict(zip(class_params[\\\"class_names\\\"], class_params[\\\"class_to_label\\\"]))\\n    sorted_lut = {k: v for k, v in sorted(lut.items(), key=lambda item: item[1])}\\n\\n    return model, sorted_lut\\n\\n\\ndef get_output_labels(lut_sorted: dict) -> list:\\n    \\\"\\\"\\\"\\n    Returns the output labels for the classification.\\n\\n    LUT needs to be explicitly sorted here as openEO does\\n    not guarantee the order of a json object being preserved when decoding\\n    a process graph in the backend.\\n    \\\"\\\"\\\"\\n    class_names = lut_sorted.keys()\\n\\n    return [\\\"classification\\\", \\\"probability\\\"] + [\\n        f\\\"probability_{name}\\\" for name in class_names\\n    ]\\n\\ndef predict(onnx_session: ort.InferenceSession, lut_sorted: dict, features: np.ndarray) -> np.ndarray:\\n    \\\"\\\"\\\"\\n    Predicts labels using the provided features array.\\n\\n    LUT needs to be explicitly sorted here as openEO does\\n    not guarantee the order of a json object being preserved when decoding\\n    a process graph in the backend.\\n    \\\"\\\"\\\"\\n\\n    # Prepare input data for ONNX model\\n    outputs = onnx_session.run(None, {\\\"features\\\": features})\\n\\n    # Extract classes as INTs and probability of winning class values\\n    labels = np.zeros((len(outputs[0]),), dtype=np.uint16)\\n    probabilities = np.zeros((len(outputs[0]),), dtype=np.uint8)\\n    for i, (label, prob) in enumerate(zip(outputs[0], outputs[1])):\\n        labels[i] = lut_sorted[label]\\n        probabilities[i] = int(round(prob[label] * 100))\\n\\n    # Extract per class probabilities\\n    output_probabilities = []\\n    for output_px in outputs[1]:\\n        output_probabilities.append(\\n            [output_px[label] for label in lut_sorted.keys()]\\n        )\\n\\n    output_probabilities = (\\n        (np.array(output_probabilities) * 100).round().astype(np.uint8)\\n    )\\n\\n    return np.hstack(\\n        [labels[:, np.newaxis], probabilities[:, np.newaxis], output_probabilities]\\n    ).transpose()\\n\\ndef execute(inarr: xr.DataArray, parameters: dict, ) -> xr.DataArray:\\n\\n    if \\\"classifier_url\\\" not in parameters:\\n        raise ValueError('Missing required parameter \\\"classifier_url\\\"')\\n    classifier_url = parameters.get(\\\"classifier_url\\\")\\n    # self.logger.info(f'Loading classifier model from \\\"{classifier_url}\\\"')\\n\\n    # shape and indices for output (\\\"xy\\\", \\\"bands\\\")\\n    x_coords, y_coords = inarr.x.values, inarr.y.values\\n    inarr = inarr.transpose(\\\"bands\\\", \\\"x\\\", \\\"y\\\").stack(xy=[\\\"x\\\", \\\"y\\\"]).transpose()\\n\\n    onnx_session, lut_sorted = (\\n        load_and_prepare_model(classifier_url)\\n    )\\n\\n    # Run catboost classification\\n    # self.logger.info(\\\"Catboost classification with input shape: %s\\\", inarr.shape)\\n    classification = predict(onnx_session=onnx_session, lut_sorted=lut_sorted, features=inarr.values)\\n    # self.logger.info(\\\"Classification done with shape: %s\\\", inarr.shape)\\n\\n    output_labels = get_output_labels(lut_sorted)\\n\\n    classification_da = xr.DataArray(\\n        classification.reshape((len(output_labels), len(x_coords), len(y_coords))),\\n        dims=[\\\"bands\\\", \\\"x\\\", \\\"y\\\"],\\n        coords={\\n            \\\"bands\\\": output_labels,\\n            \\\"x\\\": x_coords,\\n            \\\"y\\\": y_coords,\\n        },\\n    )\\n\\n    return classification_da\\n\\n# Below comes the actual UDF part\\n\\n# Apply the Inference UDF\\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\\n    \\\"\\\"\\\"This is the actual openeo UDF that will be executed by the backend.\\\"\\\"\\\"\\n\\n    cube = udf_data.datacube_list[0]\\n    parameters = copy.deepcopy(udf_data.user_context)\\n\\n    proj = udf_data.proj\\n    if proj is not None:\\n        proj = proj.get(\\\"EPSG\\\")\\n\\n    parameters[EPSG_HARMONIZED_NAME] = proj\\n\\n    arr = cube.get_array().transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n    arr = execute(\\n        inarr=arr,\\n        parameters=parameters,\\n    ).transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n\\n    cube = XarrayDataCube(arr)\\n\\n    udf_data.datacube_list = [cube]\\n\\n    return udf_data\\n\\n\\n# Change band names, since the target labels are parameterized in the UDF\\ndef apply_metadata(metadata: CollectionMetadata, context: dict) -> CollectionMetadata:\\n\\n    _, lut_sorted = load_and_prepare_model(context[\\\"classifier_url\\\"])\\n\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=get_output_labels(lut_sorted))\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}, \"size\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"t\", \"value\": \"P1D\"}]}, \"process_id\": \"apply_neighborhood\"}, \"applyneighborhood3\": {\"arguments\": {\"data\": {\"from_node\": \"filterbbox1\"}, \"overlap\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 0}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 0}], \"process\": {\"process_graph\": {\"runudf3\": {\"arguments\": {\"context\": {\"compile_presto\": true, \"presto_model_url\": \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/presto-prometheo-landcover-month-LANDCOVER10-augment%3DTrue-balance%3DTrue-timeexplicit%3DFalse-run%3D202507170930_encoder.pt\", \"rescale_s1\": false, \"target_date\": null, \"temporal_prediction\": false}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"\\\"\\\"\\\"Feature computer GFMAP compatible to compute Presto embeddings.\\\"\\\"\\\"\\n\\nimport copy\\nimport functools\\nimport random\\nimport sys\\nimport urllib.request\\nimport zipfile\\nfrom pathlib import Path\\nfrom typing import Optional\\n\\nimport numpy as np\\nimport xarray as xr\\nfrom openeo.metadata import CollectionMetadata\\nfrom openeo.udf import XarrayDataCube\\nfrom openeo.udf.udf_data import UdfData\\nfrom pyproj import Transformer\\nfrom pyproj.crs import CRS\\nfrom scipy.ndimage import (\\n    convolve,\\n    zoom,\\n)\\nfrom shapely.geometry import Point\\nfrom shapely.ops import transform\\n\\nsys.path.append(\\\"feature_deps\\\")\\n\\nimport torch  # noqa: E402\\n\\nPROMETHEO_WHL_URL = \\\"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/dependencies/prometheo-0.0.2-py3-none-any.whl\\\"\\n\\nGFMAP_BAND_MAPPING = {\\n    \\\"S2-L2A-B02\\\": \\\"B2\\\",\\n    \\\"S2-L2A-B03\\\": \\\"B3\\\",\\n    \\\"S2-L2A-B04\\\": \\\"B4\\\",\\n    \\\"S2-L2A-B05\\\": \\\"B5\\\",\\n    \\\"S2-L2A-B06\\\": \\\"B6\\\",\\n    \\\"S2-L2A-B07\\\": \\\"B7\\\",\\n    \\\"S2-L2A-B08\\\": \\\"B8\\\",\\n    \\\"S2-L2A-B8A\\\": \\\"B8A\\\",\\n    \\\"S2-L2A-B11\\\": \\\"B11\\\",\\n    \\\"S2-L2A-B12\\\": \\\"B12\\\",\\n    \\\"S1-SIGMA0-VH\\\": \\\"VH\\\",\\n    \\\"S1-SIGMA0-VV\\\": \\\"VV\\\",\\n    \\\"AGERA5-TMEAN\\\": \\\"temperature_2m\\\",\\n    \\\"AGERA5-PRECIP\\\": \\\"total_precipitation\\\",\\n}\\n\\nLAT_HARMONIZED_NAME = \\\"GEO-LAT\\\"\\nLON_HARMONIZED_NAME = \\\"GEO-LON\\\"\\nEPSG_HARMONIZED_NAME = \\\"GEO-EPSG\\\"\\n\\n\\n@functools.lru_cache(maxsize=6)\\ndef unpack_prometheo_wheel(wheel_url: str):\\n    destination_dir = Path.cwd() / \\\"dependencies\\\" / \\\"prometheo\\\"\\n    destination_dir.mkdir(exist_ok=True, parents=True)\\n\\n    # Downloads the wheel file\\n    modelfile, _ = urllib.request.urlretrieve(\\n        wheel_url, filename=Path.cwd() / Path(wheel_url).name\\n    )\\n    with zipfile.ZipFile(modelfile, \\\"r\\\") as zip_ref:\\n        zip_ref.extractall(destination_dir)\\n    return destination_dir\\n\\n\\n@functools.lru_cache(maxsize=6)\\ndef compile_encoder(presto_encoder):\\n    \\\"\\\"\\\"Helper function that compiles the encoder of a Presto model\\n    and performs a warm-up on dummy data. The lru_cache decorator\\n    ensures caching on compute nodes to be able to actually benefit\\n    from the compilation process.\\n\\n    Parameters\\n    ----------\\n    presto_encoder : nn.Module\\n        Encoder part of Presto model to compile\\n\\n    \\\"\\\"\\\"\\n\\n    presto_encoder = torch.compile(presto_encoder)  # type: ignore\\n\\n    for _ in range(3):\\n        presto_encoder(\\n            torch.rand((1, 12, 17)),\\n            torch.ones((1, 12)).long(),\\n            torch.rand(1, 2),\\n        )\\n\\n    return presto_encoder\\n\\n\\ndef get_output_labels() -> list:\\n    \\\"\\\"\\\"Returns the output labels from this UDF, which is the output labels\\n    of the presto embeddings\\\"\\\"\\\"\\n    return [f\\\"presto_ft_{i}\\\" for i in range(128)]\\n\\n\\ndef evaluate_resolution(inarr: xr.DataArray, epsg: int) -> int:\\n    \\\"\\\"\\\"Helper function to get the resolution in meters for\\n    the input array.\\n\\n    Parameters\\n    ----------\\n    inarr : xr.DataArray\\n        input array to determine resolution for.\\n\\n    Returns\\n    -------\\n    int\\n        resolution in meters.\\n    \\\"\\\"\\\"\\n\\n    if epsg == 4326:\\n        # self.logger.info(\\n        #     \\\"Converting WGS84 coordinates to EPSG:3857 to determine resolution.\\\"\\n        # )\\n\\n        transformer = Transformer.from_crs(epsg, 3857, always_xy=True)\\n        points = [Point(x, y) for x, y in zip(inarr.x.values, inarr.y.values)]\\n        points = [transform(transformer.transform, point) for point in points]\\n\\n        resolution = abs(points[1].x - points[0].x)\\n\\n    else:\\n        resolution = abs(inarr.x[1].values - inarr.x[0].values)\\n\\n    # self.logger.info(f\\\"Resolution for computing slope: {resolution}\\\")\\n\\n    return resolution\\n\\n\\ndef compute_slope(inarr: xr.DataArray, resolution: int) -> xr.DataArray:\\n    \\\"\\\"\\\"Computes the slope using the scipy library. The input array should\\n    have the following bands: 'elevation' And no time dimension. Returns a\\n    new DataArray containing the new `slope` band.\\n\\n    Parameters\\n    ----------\\n    inarr : xr.DataArray\\n        input array containing a band 'elevation'.\\n    resolution : int\\n        resolution of the input array in meters.\\n\\n    Returns\\n    -------\\n    xr.DataArray\\n        output array containing 'slope' band in degrees.\\n    \\\"\\\"\\\"\\n\\n    def _rolling_fill(darr, max_iter=2):\\n        \\\"\\\"\\\"Helper function that also reflects values inside\\n        a patch with NaNs.\\\"\\\"\\\"\\n        if max_iter == 0:\\n            return darr\\n        else:\\n            max_iter -= 1\\n        # arr of shape (rows, cols)\\n        mask = np.isnan(darr)\\n\\n        if ~np.any(mask):\\n            return darr\\n\\n        roll_params = [(0, 1), (0, -1), (1, 0), (-1, 0)]\\n        random.shuffle(roll_params)\\n\\n        for roll_param in roll_params:\\n            rolled = np.roll(darr, roll_param, axis=(0, 1))\\n            darr[mask] = rolled[mask]\\n\\n        return _rolling_fill(darr, max_iter=max_iter)\\n\\n    def _downsample(arr: np.ndarray, factor: int) -> np.ndarray:\\n        \\\"\\\"\\\"Downsamples a 2D NumPy array by a given factor with average resampling and reflect padding.\\n\\n        Parameters\\n        ----------\\n        arr : np.ndarray\\n            The 2D input array.\\n        factor : int\\n            The factor by which to downsample. For example, factor=2 downsamples by 2x.\\n\\n        Returns\\n        -------\\n        np.ndarray\\n            Downsampled array.\\n        \\\"\\\"\\\"\\n\\n        # Get the original shape of the array\\n        X, Y = arr.shape\\n\\n        # Calculate how much padding is needed for each dimension\\n        pad_X = (\\n            factor - (X % factor)\\n        ) % factor  # Ensures padding is only applied if needed\\n        pad_Y = (\\n            factor - (Y % factor)\\n        ) % factor  # Ensures padding is only applied if needed\\n\\n        # Pad the array using 'reflect' mode\\n        padded = np.pad(arr, ((0, pad_X), (0, pad_Y)), mode=\\\"reflect\\\")\\n\\n        # Reshape the array to form blocks of size 'factor' x 'factor'\\n        reshaped = padded.reshape(\\n            (X + pad_X) // factor, factor, (Y + pad_Y) // factor, factor\\n        )\\n\\n        # Take the mean over the factor-sized blocks\\n        downsampled = np.nanmean(reshaped, axis=(1, 3))\\n\\n        return downsampled\\n\\n    dem = inarr.sel(bands=\\\"elevation\\\").values\\n    dem_arr = dem.astype(np.float32)\\n\\n    # Invalid to NaN and keep track of these pixels\\n    dem_arr[dem_arr == 65535] = np.nan\\n    idx_invalid = np.isnan(dem_arr)\\n\\n    # Fill NaNs with rolling fill\\n    dem_arr = _rolling_fill(dem_arr)\\n\\n    # We make sure DEM is at 20m for slope computation\\n    # compatible with global slope collection\\n    factor = int(20 / resolution)\\n    if factor < 1 or factor % 2 != 0:\\n        raise NotImplementedError(\\n            f\\\"Unsupported resolution for slope computation: {resolution}\\\"\\n        )\\n    dem_arr_downsampled = _downsample(dem_arr, factor)\\n    x_odd, y_odd = dem_arr.shape[0] % 2 != 0, dem_arr.shape[1] % 2 != 0\\n\\n    # Mask NaN values in the DEM data\\n    dem_masked = np.ma.masked_invalid(dem_arr_downsampled)\\n\\n    # Define convolution kernels for x and y gradients (simple finite difference approximation)\\n    kernel_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]]) / (\\n        8.0 * 20  # array is now at 20m resolution\\n    )  # x-derivative kernel\\n\\n    kernel_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]]) / (\\n        8.0 * 20  # array is now at 20m resolution\\n    )  # y-derivative kernel\\n\\n    # Apply convolution to compute gradients\\n    dx = convolve(dem_masked, kernel_x)  # Gradient in the x-direction\\n    dy = convolve(dem_masked, kernel_y)  # Gradient in the y-direction\\n\\n    # Reapply the mask to the gradients\\n    dx = np.ma.masked_where(dem_masked.mask, dx)\\n    dy = np.ma.masked_where(dem_masked.mask, dy)\\n\\n    # Calculate the magnitude of the gradient (rise/run)\\n    gradient_magnitude = np.ma.sqrt(dx**2 + dy**2)\\n\\n    # Convert gradient magnitude to slope (in degrees)\\n    slope = np.ma.arctan(gradient_magnitude) * (180 / np.pi)\\n\\n    # Upsample to original resolution with bilinear interpolation\\n    mask = slope.mask\\n    mask = zoom(mask, zoom=factor, order=0)\\n    slope = zoom(slope, zoom=factor, order=1)\\n    slope[mask] = 65535\\n\\n    # Strip one row or column if original array was odd in that dimension\\n    if x_odd:\\n        slope = slope[:-1, :]\\n    if y_odd:\\n        slope = slope[:, :-1]\\n\\n    # Fill slope values where the original DEM had NaNs\\n    slope[idx_invalid] = 65535\\n    slope[np.isnan(slope)] = 65535\\n    slope = slope.astype(np.uint16)\\n\\n    return xr.DataArray(\\n        slope[None, :, :],\\n        dims=(\\\"bands\\\", \\\"y\\\", \\\"x\\\"),\\n        coords={\\n            \\\"bands\\\": [\\\"slope\\\"],\\n            \\\"y\\\": inarr.y,\\n            \\\"x\\\": inarr.x,\\n        },\\n    )\\n\\n\\ndef select_timestep_from_temporal_features(\\n    features: xr.DataArray, target_date: Optional[str] = None\\n) -> xr.DataArray:\\n    \\\"\\\"\\\"Select a specific timestep from temporal features based on target date.\\n\\n    Parameters\\n    ----------\\n    features : xr.DataArray\\n        Temporal features with time dimension preserved.\\n    target_date : str, optional\\n        Target date in ISO format (YYYY-MM-DD). If None, selects middle timestep.\\n\\n    Returns\\n    -------\\n    xr.DataArray\\n        Features for the selected timestep with time dimension removed.\\n    \\\"\\\"\\\"\\n    if target_date is None:\\n        # Select middle timestep\\n        mid_idx = len(features.t) // 2\\n        features = features.isel(t=mid_idx)\\n    else:\\n        # Parse target date and find closest timestep\\n        target_datetime = np.datetime64(target_date)\\n\\n        # Check if target_datetime is within the temporal extent of features\\n        min_time = features.t.min().values\\n        max_time = features.t.max().values\\n\\n        if target_datetime < min_time or target_datetime > max_time:\\n            raise ValueError(\\n                f\\\"Target date {target_date} is outside the temporal extent of features. \\\"\\n                f\\\"Available time range: {min_time} to {max_time}\\\"\\n            )\\n\\n        # Find closest timestep\\n        features = features.sel(t=target_datetime, method=\\\"nearest\\\")\\n\\n    return features\\n\\n\\ndef execute(inarr: xr.DataArray, parameters: dict, epsg: int) -> xr.DataArray:\\n    if epsg is None:\\n        raise ValueError(\\n            \\\"EPSG code is required for Presto feature extraction, but was \\\"\\n            \\\"not correctly initialized.\\\"\\n        )\\n    if \\\"presto_model_url\\\" not in parameters:\\n        raise ValueError('Missing required parameter \\\"presto_model_url\\\"')\\n\\n    presto_model_url = parameters.get(\\\"presto_model_url\\\")\\n    # self.logger.info(f'Loading Presto model from \\\"{presto_model_url}\\\"')\\n    prometheo_wheel_url = parameters.get(\\\"prometheo_wheel_url\\\", PROMETHEO_WHL_URL)\\n    # self.logger.info(f'Loading Prometheo wheel from \\\"{prometheo_wheel_url}\\\"')\\n\\n    ignore_dependencies = parameters.get(\\\"ignore_dependencies\\\", False)\\n    # if ignore_dependencies:\\n    # self.logger.info(\\n    #     \\\"`ignore_dependencies` flag is set to True. Make sure that \\\"\\n    #     \\\"Presto and its dependencies are available on the runtime \\\"\\n    #     \\\"environment\\\"\\n    # )\\n\\n    # The below is required to avoid flipping of the result\\n    # when running on OpenEO backend!\\n    inarr = inarr.transpose(\\\"bands\\\", \\\"t\\\", \\\"x\\\", \\\"y\\\")\\n\\n    # Change the band names\\n    new_band_names = [GFMAP_BAND_MAPPING.get(b.item(), b.item()) for b in inarr.bands]\\n    inarr = inarr.assign_coords(bands=new_band_names)\\n\\n    # Handle NaN values in Presto compatible way\\n    inarr = inarr.fillna(65535)\\n\\n    if not ignore_dependencies:\\n        # Unzip the Presto dependencies on the backend\\n        # self.logger.info(\\\"Unpacking prometheo wheel\\\")\\n        deps_dir = unpack_prometheo_wheel(prometheo_wheel_url)\\n\\n        # self.logger.info(\\\"Appending dependencies\\\")\\n        sys.path.append(str(deps_dir))\\n\\n    if \\\"slope\\\" not in inarr.bands:\\n        # If 'slope' is not present we need to compute it here\\n        # self.logger.warning(\\\"`slope` not found in input array. Computing ...\\\")\\n        resolution = evaluate_resolution(inarr.isel(t=0), epsg)\\n        slope = compute_slope(inarr.isel(t=0), resolution)\\n        slope = slope.expand_dims({\\\"t\\\": inarr.t}, axis=0).astype(\\\"float32\\\")\\n\\n        inarr = xr.concat([inarr.astype(\\\"float32\\\"), slope], dim=\\\"bands\\\")\\n\\n    batch_size = parameters.get(\\\"batch_size\\\", 256)\\n    temporal_prediction = parameters.get(\\\"temporal_prediction\\\", False)\\n    target_date = parameters.get(\\\"target_date\\\", None)\\n\\n    # TODO: compile_presto not used for now?\\n    # compile_presto = parameters.get(\\\"compile_presto\\\", False)\\n    # self.logger.info(f\\\"Compile presto: {compile_presto}\\\")\\n\\n    # self.logger.info(\\\"Loading Presto model for inference\\\")\\n\\n    # TODO: try to take run_model_inference from worldcereal\\n    from prometheo.datasets.worldcereal import run_model_inference\\n    from prometheo.models import Presto\\n    from prometheo.models.pooling import PoolingMethods\\n    from prometheo.models.presto.wrapper import load_presto_weights\\n\\n    presto_model = Presto()\\n    presto_model = load_presto_weights(presto_model, presto_model_url)\\n\\n    # self.logger.info(\\\"Extracting presto features\\\")\\n    # Check if we have the expected 12 timesteps\\n    if len(inarr.t) != 12:\\n        raise ValueError(f\\\"Can only run Presto on 12 timesteps, got: {len(inarr.t)}\\\")\\n\\n    # Determine pooling method based on temporal_prediction parameter\\n    pooling_method = (\\n        PoolingMethods.TIME if temporal_prediction else PoolingMethods.GLOBAL\\n    )\\n\\n    features = run_model_inference(\\n        inarr,\\n        presto_model,\\n        epsg=epsg,\\n        batch_size=batch_size,\\n        pooling_method=pooling_method,\\n    )\\n\\n    # If temporal prediction, select specific timestep based on target_date\\n    if temporal_prediction:\\n        features = select_timestep_from_temporal_features(features, target_date)\\n\\n    return features\\n\\n\\ndef get_latlons(inarr: xr.DataArray, epsg: int) -> xr.DataArray:\\n    \\\"\\\"\\\"Returns the latitude and longitude coordinates of the given array in\\n    a dataarray. Returns a dataarray with the same width/height of the input\\n    array, but with two bands, one for latitude and one for longitude. The\\n    metadata coordinates of the output array are the same as the input\\n    array, as the array wasn't reprojected but instead new features were\\n    computed.\\n\\n    The latitude and longitude band names are standardized to the names\\n    `LAT_HARMONIZED_NAME` and `LON_HARMONIZED_NAME` respectively.\\n    \\\"\\\"\\\"\\n\\n    lon = inarr.coords[\\\"x\\\"]\\n    lat = inarr.coords[\\\"y\\\"]\\n    lon, lat = np.meshgrid(lon, lat)\\n\\n    if epsg is None:\\n        raise Exception(\\n            \\\"EPSG code was not defined, cannot extract lat/lon array \\\"\\n            \\\"as the CRS is unknown.\\\"\\n        )\\n\\n    # If the coordiantes are not in EPSG:4326, we need to reproject them\\n    if epsg != 4326:\\n        # Initializes a pyproj reprojection object\\n        transformer = Transformer.from_crs(\\n            crs_from=CRS.from_epsg(epsg),\\n            crs_to=CRS.from_epsg(4326),\\n            always_xy=True,\\n        )\\n        lon, lat = transformer.transform(xx=lon, yy=lat)\\n\\n    # Create a two channel numpy array of the lat and lons together by stacking\\n    latlon = np.stack([lat, lon])\\n\\n    # Repack in a dataarray\\n    return xr.DataArray(\\n        latlon,\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": [LAT_HARMONIZED_NAME, LON_HARMONIZED_NAME],\\n            \\\"y\\\": inarr.coords[\\\"y\\\"],\\n            \\\"x\\\": inarr.coords[\\\"x\\\"],\\n        },\\n    )\\n\\n\\ndef rescale_s1_backscatter(arr: xr.DataArray) -> xr.DataArray:\\n    \\\"\\\"\\\"Rescales the input array from uint16 to float32 decibel values.\\n    The input array should be in uint16 format, as this optimizes memory usage in Open-EO\\n    processes. This function is called automatically on the bands of the input array, except\\n    if the parameter `rescale_s1` is set to False.\\n    \\\"\\\"\\\"\\n    s1_bands = [\\\"S1-SIGMA0-VV\\\", \\\"S1-SIGMA0-VH\\\", \\\"S1-SIGMA0-HV\\\", \\\"S1-SIGMA0-HH\\\"]\\n    s1_bands_to_select = list(set(arr.bands.values) & set(s1_bands))\\n\\n    if len(s1_bands_to_select) == 0:\\n        return arr\\n\\n    data_to_rescale = arr.sel(bands=s1_bands_to_select).astype(np.float32).data\\n\\n    # Assert that the values are set between 1 and 65535\\n    if data_to_rescale.min().item() < 1 or data_to_rescale.max().item() > 65535:\\n        raise ValueError(\\n            \\\"The input array should be in uint16 format, with values between 1 and 65535. \\\"\\n            \\\"This restriction assures that the data was processed according to the S1 fetcher \\\"\\n            \\\"preprocessor. The user can disable this scaling manually by setting the \\\"\\n            \\\"`rescale_s1` parameter to False in the feature extractor.\\\"\\n        )\\n\\n    # Converting back to power values\\n    data_to_rescale = 20.0 * np.log10(data_to_rescale) - 83.0\\n    data_to_rescale = np.power(10, data_to_rescale / 10.0)\\n    data_to_rescale[~np.isfinite(data_to_rescale)] = np.nan\\n\\n    # Converting power values to decibels\\n    data_to_rescale = 10.0 * np.log10(data_to_rescale)\\n\\n    # Change the bands within the array\\n    arr.loc[dict(bands=s1_bands_to_select)] = data_to_rescale\\n    return arr\\n\\n\\n# Below comes the actual UDF part\\n\\n\\n# Apply the Feature Extraction UDF\\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\\n    \\\"\\\"\\\"This is the actual openeo UDF that will be executed by the backend.\\\"\\\"\\\"\\n\\n    cube = udf_data.datacube_list[0]\\n    parameters = copy.deepcopy(udf_data.user_context)\\n\\n    proj = udf_data.proj\\n    if proj is not None:\\n        proj = proj[\\\"EPSG\\\"]\\n\\n    parameters[EPSG_HARMONIZED_NAME] = proj\\n\\n    arr = cube.get_array().transpose(\\\"bands\\\", \\\"t\\\", \\\"y\\\", \\\"x\\\")\\n\\n    epsg = parameters.pop(EPSG_HARMONIZED_NAME)\\n\\n    if parameters.get(\\\"rescale_s1\\\", True):\\n        arr = rescale_s1_backscatter(arr)\\n\\n    arr = execute(inarr=arr, parameters=parameters, epsg=epsg).transpose(\\n        \\\"bands\\\", \\\"y\\\", \\\"x\\\"\\n    )\\n\\n    cube = XarrayDataCube(arr)\\n\\n    udf_data.datacube_list = [cube]\\n\\n    return udf_data\\n\\n\\n# Change band names\\ndef apply_metadata(metadata: CollectionMetadata, context: dict) -> CollectionMetadata:\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=get_output_labels())\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}, \"size\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 128}]}, \"process_id\": \"apply_neighborhood\"}, \"applyneighborhood4\": {\"arguments\": {\"data\": {\"from_node\": \"applyneighborhood3\"}, \"overlap\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 0}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 0}], \"process\": {\"process_graph\": {\"runudf4\": {\"arguments\": {\"context\": {\"classifier_url\": \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/PrestoDownstreamCatBoost_temporary-crops_v001-debug.onnx\"}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"\\\"\\\"\\\"Model inference on Presto feature for binary classication\\\"\\\"\\\"\\n\\nimport functools\\nimport sys\\nimport copy\\n\\nfrom openeo.udf.udf_data import UdfData\\nfrom openeo.udf import XarrayDataCube\\nfrom openeo.metadata import CollectionMetadata\\nimport numpy as np\\n\\nimport requests\\nimport xarray as xr\\n\\nsys.path.append(\\\"onnx_deps\\\")\\nimport onnxruntime as ort  # noqa: E402\\n\\nEPSG_HARMONIZED_NAME = \\\"GEO-EPSG\\\"\\n\\n\\n@functools.lru_cache(maxsize=6)\\ndef load_and_prepare_model(model_url: str):\\n    \\\"\\\"\\\"Function to be used instead the default GFMap load_ort_model function.\\n    Loads the model, validates it and extracts LUT from the model metadata.\\n\\n\\n    Parameters\\n    ----------\\n    model_url : str\\n        Public URL to the ONNX classification model.\\n    \\\"\\\"\\\"\\n    # Load the model\\n    response = requests.get(model_url, timeout=120)\\n    model = ort.InferenceSession(response.content)\\n\\n    # Validate the model\\n    metadata = model.get_modelmeta().custom_metadata_map\\n\\n    if \\\"class_params\\\" not in metadata:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    class_params = eval(metadata[\\\"class_params\\\"], {\\\"__builtins__\\\": None}, {})\\n\\n    if \\\"class_names\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    if \\\"class_to_label\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class to labels in the model metadata.\\\")\\n\\n    # Load model LUT\\n    lut = dict(zip(class_params[\\\"class_names\\\"], class_params[\\\"class_to_label\\\"]))\\n    sorted_lut = {k: v for k, v in sorted(lut.items(), key=lambda item: item[1])}\\n\\n    return model, sorted_lut\\n\\n\\ndef get_output_labels(lut_sorted: dict) -> list:\\n    \\\"\\\"\\\"\\n    Returns the output labels for the classification.\\n\\n    LUT needs to be explicitly sorted here as openEO does\\n    not guarantee the order of a json object being preserved when decoding\\n    a process graph in the backend.\\n    \\\"\\\"\\\"\\n    class_names = lut_sorted.keys()\\n\\n    return [\\\"classification\\\", \\\"probability\\\"] + [\\n        f\\\"probability_{name}\\\" for name in class_names\\n    ]\\n\\ndef predict(onnx_session: ort.InferenceSession, lut_sorted: dict, features: np.ndarray) -> np.ndarray:\\n    \\\"\\\"\\\"\\n    Predicts labels using the provided features array.\\n\\n    LUT needs to be explicitly sorted here as openEO does\\n    not guarantee the order of a json object being preserved when decoding\\n    a process graph in the backend.\\n    \\\"\\\"\\\"\\n\\n    # Prepare input data for ONNX model\\n    outputs = onnx_session.run(None, {\\\"features\\\": features})\\n\\n    # Extract classes as INTs and probability of winning class values\\n    labels = np.zeros((len(outputs[0]),), dtype=np.uint16)\\n    probabilities = np.zeros((len(outputs[0]),), dtype=np.uint8)\\n    for i, (label, prob) in enumerate(zip(outputs[0], outputs[1])):\\n        labels[i] = lut_sorted[label]\\n        probabilities[i] = int(round(prob[label] * 100))\\n\\n    # Extract per class probabilities\\n    output_probabilities = []\\n    for output_px in outputs[1]:\\n        output_probabilities.append(\\n            [output_px[label] for label in lut_sorted.keys()]\\n        )\\n\\n    output_probabilities = (\\n        (np.array(output_probabilities) * 100).round().astype(np.uint8)\\n    )\\n\\n    return np.hstack(\\n        [labels[:, np.newaxis], probabilities[:, np.newaxis], output_probabilities]\\n    ).transpose()\\n\\ndef execute(inarr: xr.DataArray, parameters: dict, ) -> xr.DataArray:\\n\\n    if \\\"classifier_url\\\" not in parameters:\\n        raise ValueError('Missing required parameter \\\"classifier_url\\\"')\\n    classifier_url = parameters.get(\\\"classifier_url\\\")\\n    # self.logger.info(f'Loading classifier model from \\\"{classifier_url}\\\"')\\n\\n    # shape and indices for output (\\\"xy\\\", \\\"bands\\\")\\n    x_coords, y_coords = inarr.x.values, inarr.y.values\\n    inarr = inarr.transpose(\\\"bands\\\", \\\"x\\\", \\\"y\\\").stack(xy=[\\\"x\\\", \\\"y\\\"]).transpose()\\n\\n    onnx_session, lut_sorted = (\\n        load_and_prepare_model(classifier_url)\\n    )\\n\\n    # Run catboost classification\\n    # self.logger.info(\\\"Catboost classification with input shape: %s\\\", inarr.shape)\\n    classification = predict(onnx_session=onnx_session, lut_sorted=lut_sorted, features=inarr.values)\\n    # self.logger.info(\\\"Classification done with shape: %s\\\", inarr.shape)\\n\\n    output_labels = get_output_labels(lut_sorted)\\n\\n    classification_da = xr.DataArray(\\n        classification.reshape((len(output_labels), len(x_coords), len(y_coords))),\\n        dims=[\\\"bands\\\", \\\"x\\\", \\\"y\\\"],\\n        coords={\\n            \\\"bands\\\": output_labels,\\n            \\\"x\\\": x_coords,\\n            \\\"y\\\": y_coords,\\n        },\\n    )\\n\\n    return classification_da\\n\\n# Below comes the actual UDF part\\n\\n# Apply the Inference UDF\\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\\n    \\\"\\\"\\\"This is the actual openeo UDF that will be executed by the backend.\\\"\\\"\\\"\\n\\n    cube = udf_data.datacube_list[0]\\n    parameters = copy.deepcopy(udf_data.user_context)\\n\\n    proj = udf_data.proj\\n    if proj is not None:\\n        proj = proj.get(\\\"EPSG\\\")\\n\\n    parameters[EPSG_HARMONIZED_NAME] = proj\\n\\n    arr = cube.get_array().transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n    arr = execute(\\n        inarr=arr,\\n        parameters=parameters,\\n    ).transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n\\n    cube = XarrayDataCube(arr)\\n\\n    udf_data.datacube_list = [cube]\\n\\n    return udf_data\\n\\n\\n# Change band names, since the target labels are parameterized in the UDF\\ndef apply_metadata(metadata: CollectionMetadata, context: dict) -> CollectionMetadata:\\n\\n    _, lut_sorted = load_and_prepare_model(context[\\\"classifier_url\\\"])\\n\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=get_output_labels(lut_sorted))\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}, \"size\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"t\", \"value\": \"P1D\"}]}, \"process_id\": \"apply_neighborhood\"}, \"applyneighborhood5\": {\"arguments\": {\"data\": {\"from_node\": \"saveresult1\"}, \"overlap\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 0}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 0}], \"process\": {\"process_graph\": {\"runudf5\": {\"arguments\": {\"context\": {\"classifier_url\": \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/PrestoDownstreamCatBoost_temporary-crops_v001-debug.onnx\", \"enable\": true, \"keep_class_probs\": true, \"kernel_size\": 5, \"method\": \"majority_vote\", \"save_intermediate\": true}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"import copy\\nimport functools\\nimport sys\\nimport requests\\nimport xarray as xr\\n\\nimport numpy as np\\nfrom scipy.signal import convolve2d\\n\\nfrom openeo.udf.udf_data import UdfData\\nfrom openeo.udf import XarrayDataCube\\nfrom openeo.metadata import CollectionMetadata\\n\\nsys.path.append(\\\"onnx_deps\\\")\\nimport onnxruntime as ort  # noqa: E402\\n\\n\\nEXCLUDED_VALUES = [254, 255, 65535]\\nNODATA = 255\\n\\n@functools.lru_cache(maxsize=6)\\ndef lut_from_url(model_url: str) -> dict:\\n    \\\"\\\"\\\"Method to extract lookup table from model URL.\\n    Loads the model, validates it and extracts LUT from the model metadata.\\n\\n    Parameters\\n    ----------\\n    model_url : str\\n        Public URL to the ONNX classification model.\\n    \\\"\\\"\\\"\\n\\n    # Load the model\\n    response = requests.get(model_url, timeout=120)\\n    model = ort.InferenceSession(response.content)\\n\\n    # Validate the model\\n    metadata = model.get_modelmeta().custom_metadata_map\\n\\n    if \\\"class_params\\\" not in metadata:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    class_params = eval(metadata[\\\"class_params\\\"], {\\\"__builtins__\\\": None}, {})\\n\\n    if \\\"class_names\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    if \\\"class_to_label\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class to labels in the model metadata.\\\")\\n\\n    # Load model LUT\\n    lut = dict(zip(class_params[\\\"class_names\\\"], class_params[\\\"class_to_label\\\"]))\\n    sorted_lut = {k: v for k, v in sorted(lut.items(), key=lambda item: item[1])}\\n\\n    return sorted_lut\\n\\n\\n\\ndef get_output_labels(sorted_lut: dict, parameters: dict) -> list:\\n    if parameters.get(\\\"keep_class_probs\\\", False):\\n        return [\\\"classification\\\", \\\"probability\\\"] + [\\n            f\\\"probability_{name}\\\" for name in sorted_lut.keys()\\n        ]\\n    return [\\\"classification\\\", \\\"probability\\\"]\\n\\n\\ndef majority_vote(\\n    base_labels: xr.DataArray,\\n    max_probabilities: xr.DataArray,\\n    kernel_size: int,\\n) -> xr.DataArray:\\n    \\\"\\\"\\\"Majority vote is performed using a sliding local kernel.\\n    For each pixel, the voting of a final class is done by counting\\n    neighbours values.\\n    Pixels that have one of the specified excluded values are\\n    excluded in the voting process and are unchanged.\\n\\n    The prediction probabilities are reevaluated by taking, for each pixel,\\n    the average of probabilities of the neighbors that belong to the winning class.\\n    (For example, if a pixel was voted to class 2 and there are three\\n    neighbors of that class, then the new probability is the sum of the\\n    old probabilities of each pixels divided by 3)\\n\\n    Parameters\\n    ----------\\n    base_labels : xr.DataArray\\n        The original predicted classification labels.\\n    max_probabilities : xr.DataArray\\n        The original probabilities of the winning class (ranging between 0 and 100).\\n    kernel_size : int\\n        The size of the kernel used for the neighbour around the pixel.\\n\\n    Returns\\n    -------\\n    xr.DataArray\\n        The cleaned classification labels and associated probabilities.\\n    \\\"\\\"\\\"\\n\\n\\n\\n    prediction = base_labels.values\\n    probability = max_probabilities.values\\n\\n    # As the probabilities are in integers between 0 and 100,\\n    # we use uint16 matrices to store the vote scores\\n    assert (\\n        kernel_size <= 25\\n    ), f\\\"Kernel value cannot be larger than 25 (currently: {kernel_size}) because it might lead to scenarios where the 16-bit count matrix is overflown\\\"\\n\\n    # Build a class mapping, so classes are converted to indexes and vice-versa\\n    unique_values = set(np.unique(prediction))\\n    unique_values = sorted(unique_values - set(EXCLUDED_VALUES))  # type: ignore\\n    index_value_lut = [(k, v) for k, v in enumerate(unique_values)]\\n\\n    counts = np.zeros(\\n        shape=(*prediction.shape, len(unique_values)), dtype=np.uint16\\n    )\\n    probabilities = np.zeros(\\n        shape=(*probability.shape, len(unique_values)), dtype=np.uint16\\n    )\\n\\n    # Iterates for each classes\\n    for cls_idx, cls_value in index_value_lut:\\n        # Take the binary mask of the interest class, and multiply by the probabilities\\n        class_mask = ((prediction == cls_value) * probability).astype(np.uint16)\\n\\n        # Set to 0 the class scores where the label is excluded\\n        for excluded_value in EXCLUDED_VALUES:\\n            class_mask[prediction == excluded_value] = 0\\n\\n        # Binary class mask, used to count HOW MANY neighbours pixels are used for this class\\n        binary_class_mask = (class_mask > 0).astype(np.uint16)\\n\\n        # Creates the kernel\\n        kernel = np.ones(shape=(kernel_size, kernel_size), dtype=np.uint16)\\n\\n        # Counts around the window the sum of probabilities for that given class\\n        counts[:, :, cls_idx] = convolve2d(class_mask, kernel, mode=\\\"same\\\")\\n\\n        # Counts the number of neighbors pixels that voted for that given class\\n        class_voters = convolve2d(binary_class_mask, kernel, mode=\\\"same\\\")\\n        # Remove the 0 values because might create divide by 0 issues\\n        class_voters[class_voters == 0] = 1\\n\\n        probabilities[:, :, cls_idx] = np.divide(\\n            counts[:, :, cls_idx], class_voters\\n        )\\n\\n    # Initializes output array\\n    aggregated_predictions = np.zeros(\\n        shape=(counts.shape[0], counts.shape[1]), dtype=np.uint16\\n    )\\n    # Initializes probabilities output array\\n    aggregated_probabilities = np.zeros(\\n        shape=(counts.shape[0], counts.shape[1]), dtype=np.uint16\\n    )\\n\\n    if len(unique_values) > 0:\\n        # Takes the indices that have the biggest scores\\n        aggregated_predictions_indices = np.argmax(counts, axis=2)\\n\\n        # Get the new probabilities of the predictions\\n        aggregated_probabilities = np.take_along_axis(\\n            probabilities,\\n            aggregated_predictions_indices.reshape(\\n                *aggregated_predictions_indices.shape, 1\\n            ),\\n            axis=2,\\n        ).squeeze()\\n\\n        # Check which pixels have a counts value equal to 0\\n        no_score_mask = np.sum(counts, axis=2) == 0\\n\\n        # convert back to values from indices\\n        for cls_idx, cls_value in index_value_lut:\\n            aggregated_predictions[aggregated_predictions_indices == cls_idx] = (\\n                cls_value\\n            )\\n            aggregated_predictions = aggregated_predictions.astype(np.uint16)\\n\\n        aggregated_predictions[no_score_mask] = NODATA\\n        aggregated_probabilities[no_score_mask] = NODATA\\n\\n    # Setting excluded values back to their original values\\n    for excluded_value in EXCLUDED_VALUES:\\n        aggregated_predictions[prediction == excluded_value] = excluded_value\\n        aggregated_probabilities[prediction == excluded_value] = excluded_value\\n\\n    return xr.DataArray(\\n        np.stack((aggregated_predictions, aggregated_probabilities)),\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": [\\\"classification\\\", \\\"probability\\\"],\\n            \\\"y\\\": base_labels.y,\\n            \\\"x\\\": base_labels.x,\\n        },\\n    )\\n\\n\\ndef smooth_probabilities(\\n    base_labels: xr.DataArray, class_probabilities: xr.DataArray\\n) -> xr.DataArray:\\n    \\\"\\\"\\\"Performs gaussian smoothing on the class probabilities. Requires the\\n    base labels to keep the pixels that are excluded away from smoothing.\\n    \\\"\\\"\\\"\\n\\n    base_labels_vals = base_labels.values\\n    probabilities_vals = class_probabilities.values\\n\\n    excluded_mask = np.in1d(\\n        base_labels_vals.reshape(-1),\\n        EXCLUDED_VALUES,\\n    ).reshape(*base_labels_vals.shape)\\n\\n    conv_kernel = np.array([[1, 2, 1], [2, 3, 2], [1, 2, 1]], dtype=np.int16)\\n\\n    for class_idx in range(probabilities_vals.shape[0]):\\n        probabilities_vals[class_idx] = (\\n            convolve2d(\\n                probabilities_vals[class_idx],\\n                conv_kernel,\\n                mode=\\\"same\\\",\\n                boundary=\\\"symm\\\",\\n            )\\n            / conv_kernel.sum()\\n        )\\n        probabilities_vals[class_idx][excluded_mask] = 0\\n\\n    # Sum of probabilities should be 1, cast to uint16\\n    probabilities_vals = np.round(\\n        probabilities_vals / probabilities_vals.sum(axis=0) * 100.0\\n    ).astype(\\\"uint16\\\")\\n\\n    return xr.DataArray(\\n        probabilities_vals,\\n        coords=class_probabilities.coords,\\n        dims=class_probabilities.dims,\\n    )\\n\\ndef reclassify(\\n    base_labels: xr.DataArray,\\n    base_max_probs: xr.DataArray,\\n    probabilities: xr.DataArray,\\n) -> xr.DataArray:\\n\\n    base_labels_vals = base_labels.values\\n    base_max_probs_vals = base_max_probs.values\\n\\n    excluded_mask = np.in1d(\\n        base_labels_vals.reshape(-1),\\n        EXCLUDED_VALUES,\\n    ).reshape(*base_labels_vals.shape)\\n\\n    new_labels_vals = np.argmax(probabilities.values, axis=0)\\n    new_max_probs_vals = np.max(probabilities.values, axis=0)\\n\\n    new_labels_vals[excluded_mask] = base_labels_vals[excluded_mask]\\n    new_max_probs_vals[excluded_mask] = base_max_probs_vals[excluded_mask]\\n\\n    return xr.DataArray(\\n        np.stack((new_labels_vals, new_max_probs_vals)),\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": [\\\"classification\\\", \\\"probability\\\"],\\n            \\\"y\\\": base_labels.y,\\n            \\\"x\\\": base_labels.x,\\n        },\\n    )\\n\\n\\ndef execute(inarr: xr.DataArray, parameters: dict) -> xr.DataArray:\\n\\n    if \\\"classifier_url\\\" not in parameters:\\n        raise ValueError('Missing required parameter \\\"classifier_url\\\"')\\n    classifier_url = parameters.get(\\\"classifier_url\\\")\\n\\n    lookup_table = lut_from_url(classifier_url)\\n\\n    if parameters.get(\\\"method\\\") == \\\"smooth_probabilities\\\":\\n        # Cast to float for more accurate gaussian smoothing\\n        class_probabilities = (\\n            inarr.isel(bands=slice(2, None)).astype(\\\"float32\\\") / 100.0\\n        )\\n\\n        # Peform probability smoothing\\n        class_probabilities = smooth_probabilities(\\n            inarr.sel(bands=\\\"classification\\\"), class_probabilities\\n        )\\n\\n        # Reclassify\\n        new_labels = reclassify(\\n            inarr.sel(bands=\\\"classification\\\"),\\n            inarr.sel(bands=\\\"probability\\\"),\\n            class_probabilities,\\n        )\\n\\n        # Re-apply labels\\n        class_labels = list(lookup_table.values())\\n        # create a final labels array with same dimensions as new_labels\\n        final_labels = xr.full_like(new_labels, fill_value=float(\\\"nan\\\"))\\n        for idx, label in enumerate(class_labels):\\n            final_labels.loc[{\\\"bands\\\": \\\"classification\\\"}] = xr.where(\\n                new_labels.sel(bands=\\\"classification\\\") == idx,\\n                label,\\n                final_labels.sel(bands=\\\"classification\\\"),\\n            )\\n        new_labels.sel(bands=\\\"classification\\\").values = final_labels.sel(\\n            bands=\\\"classification\\\"\\n        ).values\\n\\n        # Append the per-class probabalities if required\\n        if parameters.get(\\\"keep_class_probs\\\", False):\\n            new_labels = xr.concat([new_labels, class_probabilities], dim=\\\"bands\\\")\\n\\n    elif parameters.get(\\\"method\\\") == \\\"majority_vote\\\":\\n\\n        kernel_size = parameters.get(\\\"kernel_size\\\", 5)\\n\\n        new_labels = majority_vote(\\n            inarr.sel(bands=\\\"classification\\\"),\\n            inarr.sel(bands=\\\"probability\\\"),\\n            kernel_size=kernel_size,\\n        )\\n\\n        # Append the per-class probabalities if required\\n        if parameters.get(\\\"keep_class_probs\\\", False):\\n            class_probabilities = inarr.isel(bands=slice(2, None))\\n            new_labels = xr.concat([new_labels, class_probabilities], dim=\\\"bands\\\")\\n\\n    else:\\n        raise ValueError(\\n            f\\\"Unknown post-processing method: {parameters.get('method')}\\\"\\n        )\\n\\n    return new_labels\\n\\n\\n# Below comes the actual UDF part\\n\\n# Apply the Inference UDF\\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\\n    \\\"\\\"\\\"This is the actual openeo UDF that will be executed by the backend.\\\"\\\"\\\"\\n\\n    cube = udf_data.datacube_list[0]\\n    parameters = copy.deepcopy(udf_data.user_context)\\n\\n    arr = cube.get_array().transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n    arr = execute(\\n        inarr=arr,\\n        parameters=parameters,\\n    ).transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n\\n    cube = XarrayDataCube(arr)\\n\\n    udf_data.datacube_list = [cube]\\n\\n    return udf_data\\n\\n# Change band names, since the target labels are parameterized in the UDF\\ndef apply_metadata(metadata: CollectionMetadata, context: dict) -> CollectionMetadata:\\n\\n    lut_sorted = lut_from_url(context[\\\"classifier_url\\\"])\\n\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=get_output_labels(lut_sorted, context))\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}, \"size\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"t\", \"value\": \"P1D\"}]}, \"process_id\": \"apply_neighborhood\"}, \"applyneighborhood6\": {\"arguments\": {\"data\": {\"from_node\": \"saveresult3\"}, \"overlap\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 0}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 0}], \"process\": {\"process_graph\": {\"runudf6\": {\"arguments\": {\"context\": {\"classifier_url\": \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/tests/be_multiclass-test_custommodel.onnx\", \"enable\": true, \"keep_class_probs\": true, \"kernel_size\": 5, \"method\": \"majority_vote\", \"save_intermediate\": true}, \"data\": {\"from_parameter\": \"data\"}, \"runtime\": \"Python\", \"udf\": \"import copy\\nimport functools\\nimport sys\\nimport requests\\nimport xarray as xr\\n\\nimport numpy as np\\nfrom scipy.signal import convolve2d\\n\\nfrom openeo.udf.udf_data import UdfData\\nfrom openeo.udf import XarrayDataCube\\nfrom openeo.metadata import CollectionMetadata\\n\\nsys.path.append(\\\"onnx_deps\\\")\\nimport onnxruntime as ort  # noqa: E402\\n\\n\\nEXCLUDED_VALUES = [254, 255, 65535]\\nNODATA = 255\\n\\n@functools.lru_cache(maxsize=6)\\ndef lut_from_url(model_url: str) -> dict:\\n    \\\"\\\"\\\"Method to extract lookup table from model URL.\\n    Loads the model, validates it and extracts LUT from the model metadata.\\n\\n    Parameters\\n    ----------\\n    model_url : str\\n        Public URL to the ONNX classification model.\\n    \\\"\\\"\\\"\\n\\n    # Load the model\\n    response = requests.get(model_url, timeout=120)\\n    model = ort.InferenceSession(response.content)\\n\\n    # Validate the model\\n    metadata = model.get_modelmeta().custom_metadata_map\\n\\n    if \\\"class_params\\\" not in metadata:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    class_params = eval(metadata[\\\"class_params\\\"], {\\\"__builtins__\\\": None}, {})\\n\\n    if \\\"class_names\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class names in the model metadata.\\\")\\n\\n    if \\\"class_to_label\\\" not in class_params:\\n        raise ValueError(\\\"Could not find class to labels in the model metadata.\\\")\\n\\n    # Load model LUT\\n    lut = dict(zip(class_params[\\\"class_names\\\"], class_params[\\\"class_to_label\\\"]))\\n    sorted_lut = {k: v for k, v in sorted(lut.items(), key=lambda item: item[1])}\\n\\n    return sorted_lut\\n\\n\\n\\ndef get_output_labels(sorted_lut: dict, parameters: dict) -> list:\\n    if parameters.get(\\\"keep_class_probs\\\", False):\\n        return [\\\"classification\\\", \\\"probability\\\"] + [\\n            f\\\"probability_{name}\\\" for name in sorted_lut.keys()\\n        ]\\n    return [\\\"classification\\\", \\\"probability\\\"]\\n\\n\\ndef majority_vote(\\n    base_labels: xr.DataArray,\\n    max_probabilities: xr.DataArray,\\n    kernel_size: int,\\n) -> xr.DataArray:\\n    \\\"\\\"\\\"Majority vote is performed using a sliding local kernel.\\n    For each pixel, the voting of a final class is done by counting\\n    neighbours values.\\n    Pixels that have one of the specified excluded values are\\n    excluded in the voting process and are unchanged.\\n\\n    The prediction probabilities are reevaluated by taking, for each pixel,\\n    the average of probabilities of the neighbors that belong to the winning class.\\n    (For example, if a pixel was voted to class 2 and there are three\\n    neighbors of that class, then the new probability is the sum of the\\n    old probabilities of each pixels divided by 3)\\n\\n    Parameters\\n    ----------\\n    base_labels : xr.DataArray\\n        The original predicted classification labels.\\n    max_probabilities : xr.DataArray\\n        The original probabilities of the winning class (ranging between 0 and 100).\\n    kernel_size : int\\n        The size of the kernel used for the neighbour around the pixel.\\n\\n    Returns\\n    -------\\n    xr.DataArray\\n        The cleaned classification labels and associated probabilities.\\n    \\\"\\\"\\\"\\n\\n\\n\\n    prediction = base_labels.values\\n    probability = max_probabilities.values\\n\\n    # As the probabilities are in integers between 0 and 100,\\n    # we use uint16 matrices to store the vote scores\\n    assert (\\n        kernel_size <= 25\\n    ), f\\\"Kernel value cannot be larger than 25 (currently: {kernel_size}) because it might lead to scenarios where the 16-bit count matrix is overflown\\\"\\n\\n    # Build a class mapping, so classes are converted to indexes and vice-versa\\n    unique_values = set(np.unique(prediction))\\n    unique_values = sorted(unique_values - set(EXCLUDED_VALUES))  # type: ignore\\n    index_value_lut = [(k, v) for k, v in enumerate(unique_values)]\\n\\n    counts = np.zeros(\\n        shape=(*prediction.shape, len(unique_values)), dtype=np.uint16\\n    )\\n    probabilities = np.zeros(\\n        shape=(*probability.shape, len(unique_values)), dtype=np.uint16\\n    )\\n\\n    # Iterates for each classes\\n    for cls_idx, cls_value in index_value_lut:\\n        # Take the binary mask of the interest class, and multiply by the probabilities\\n        class_mask = ((prediction == cls_value) * probability).astype(np.uint16)\\n\\n        # Set to 0 the class scores where the label is excluded\\n        for excluded_value in EXCLUDED_VALUES:\\n            class_mask[prediction == excluded_value] = 0\\n\\n        # Binary class mask, used to count HOW MANY neighbours pixels are used for this class\\n        binary_class_mask = (class_mask > 0).astype(np.uint16)\\n\\n        # Creates the kernel\\n        kernel = np.ones(shape=(kernel_size, kernel_size), dtype=np.uint16)\\n\\n        # Counts around the window the sum of probabilities for that given class\\n        counts[:, :, cls_idx] = convolve2d(class_mask, kernel, mode=\\\"same\\\")\\n\\n        # Counts the number of neighbors pixels that voted for that given class\\n        class_voters = convolve2d(binary_class_mask, kernel, mode=\\\"same\\\")\\n        # Remove the 0 values because might create divide by 0 issues\\n        class_voters[class_voters == 0] = 1\\n\\n        probabilities[:, :, cls_idx] = np.divide(\\n            counts[:, :, cls_idx], class_voters\\n        )\\n\\n    # Initializes output array\\n    aggregated_predictions = np.zeros(\\n        shape=(counts.shape[0], counts.shape[1]), dtype=np.uint16\\n    )\\n    # Initializes probabilities output array\\n    aggregated_probabilities = np.zeros(\\n        shape=(counts.shape[0], counts.shape[1]), dtype=np.uint16\\n    )\\n\\n    if len(unique_values) > 0:\\n        # Takes the indices that have the biggest scores\\n        aggregated_predictions_indices = np.argmax(counts, axis=2)\\n\\n        # Get the new probabilities of the predictions\\n        aggregated_probabilities = np.take_along_axis(\\n            probabilities,\\n            aggregated_predictions_indices.reshape(\\n                *aggregated_predictions_indices.shape, 1\\n            ),\\n            axis=2,\\n        ).squeeze()\\n\\n        # Check which pixels have a counts value equal to 0\\n        no_score_mask = np.sum(counts, axis=2) == 0\\n\\n        # convert back to values from indices\\n        for cls_idx, cls_value in index_value_lut:\\n            aggregated_predictions[aggregated_predictions_indices == cls_idx] = (\\n                cls_value\\n            )\\n            aggregated_predictions = aggregated_predictions.astype(np.uint16)\\n\\n        aggregated_predictions[no_score_mask] = NODATA\\n        aggregated_probabilities[no_score_mask] = NODATA\\n\\n    # Setting excluded values back to their original values\\n    for excluded_value in EXCLUDED_VALUES:\\n        aggregated_predictions[prediction == excluded_value] = excluded_value\\n        aggregated_probabilities[prediction == excluded_value] = excluded_value\\n\\n    return xr.DataArray(\\n        np.stack((aggregated_predictions, aggregated_probabilities)),\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": [\\\"classification\\\", \\\"probability\\\"],\\n            \\\"y\\\": base_labels.y,\\n            \\\"x\\\": base_labels.x,\\n        },\\n    )\\n\\n\\ndef smooth_probabilities(\\n    base_labels: xr.DataArray, class_probabilities: xr.DataArray\\n) -> xr.DataArray:\\n    \\\"\\\"\\\"Performs gaussian smoothing on the class probabilities. Requires the\\n    base labels to keep the pixels that are excluded away from smoothing.\\n    \\\"\\\"\\\"\\n\\n    base_labels_vals = base_labels.values\\n    probabilities_vals = class_probabilities.values\\n\\n    excluded_mask = np.in1d(\\n        base_labels_vals.reshape(-1),\\n        EXCLUDED_VALUES,\\n    ).reshape(*base_labels_vals.shape)\\n\\n    conv_kernel = np.array([[1, 2, 1], [2, 3, 2], [1, 2, 1]], dtype=np.int16)\\n\\n    for class_idx in range(probabilities_vals.shape[0]):\\n        probabilities_vals[class_idx] = (\\n            convolve2d(\\n                probabilities_vals[class_idx],\\n                conv_kernel,\\n                mode=\\\"same\\\",\\n                boundary=\\\"symm\\\",\\n            )\\n            / conv_kernel.sum()\\n        )\\n        probabilities_vals[class_idx][excluded_mask] = 0\\n\\n    # Sum of probabilities should be 1, cast to uint16\\n    probabilities_vals = np.round(\\n        probabilities_vals / probabilities_vals.sum(axis=0) * 100.0\\n    ).astype(\\\"uint16\\\")\\n\\n    return xr.DataArray(\\n        probabilities_vals,\\n        coords=class_probabilities.coords,\\n        dims=class_probabilities.dims,\\n    )\\n\\ndef reclassify(\\n    base_labels: xr.DataArray,\\n    base_max_probs: xr.DataArray,\\n    probabilities: xr.DataArray,\\n) -> xr.DataArray:\\n\\n    base_labels_vals = base_labels.values\\n    base_max_probs_vals = base_max_probs.values\\n\\n    excluded_mask = np.in1d(\\n        base_labels_vals.reshape(-1),\\n        EXCLUDED_VALUES,\\n    ).reshape(*base_labels_vals.shape)\\n\\n    new_labels_vals = np.argmax(probabilities.values, axis=0)\\n    new_max_probs_vals = np.max(probabilities.values, axis=0)\\n\\n    new_labels_vals[excluded_mask] = base_labels_vals[excluded_mask]\\n    new_max_probs_vals[excluded_mask] = base_max_probs_vals[excluded_mask]\\n\\n    return xr.DataArray(\\n        np.stack((new_labels_vals, new_max_probs_vals)),\\n        dims=[\\\"bands\\\", \\\"y\\\", \\\"x\\\"],\\n        coords={\\n            \\\"bands\\\": [\\\"classification\\\", \\\"probability\\\"],\\n            \\\"y\\\": base_labels.y,\\n            \\\"x\\\": base_labels.x,\\n        },\\n    )\\n\\n\\ndef execute(inarr: xr.DataArray, parameters: dict) -> xr.DataArray:\\n\\n    if \\\"classifier_url\\\" not in parameters:\\n        raise ValueError('Missing required parameter \\\"classifier_url\\\"')\\n    classifier_url = parameters.get(\\\"classifier_url\\\")\\n\\n    lookup_table = lut_from_url(classifier_url)\\n\\n    if parameters.get(\\\"method\\\") == \\\"smooth_probabilities\\\":\\n        # Cast to float for more accurate gaussian smoothing\\n        class_probabilities = (\\n            inarr.isel(bands=slice(2, None)).astype(\\\"float32\\\") / 100.0\\n        )\\n\\n        # Peform probability smoothing\\n        class_probabilities = smooth_probabilities(\\n            inarr.sel(bands=\\\"classification\\\"), class_probabilities\\n        )\\n\\n        # Reclassify\\n        new_labels = reclassify(\\n            inarr.sel(bands=\\\"classification\\\"),\\n            inarr.sel(bands=\\\"probability\\\"),\\n            class_probabilities,\\n        )\\n\\n        # Re-apply labels\\n        class_labels = list(lookup_table.values())\\n        # create a final labels array with same dimensions as new_labels\\n        final_labels = xr.full_like(new_labels, fill_value=float(\\\"nan\\\"))\\n        for idx, label in enumerate(class_labels):\\n            final_labels.loc[{\\\"bands\\\": \\\"classification\\\"}] = xr.where(\\n                new_labels.sel(bands=\\\"classification\\\") == idx,\\n                label,\\n                final_labels.sel(bands=\\\"classification\\\"),\\n            )\\n        new_labels.sel(bands=\\\"classification\\\").values = final_labels.sel(\\n            bands=\\\"classification\\\"\\n        ).values\\n\\n        # Append the per-class probabalities if required\\n        if parameters.get(\\\"keep_class_probs\\\", False):\\n            new_labels = xr.concat([new_labels, class_probabilities], dim=\\\"bands\\\")\\n\\n    elif parameters.get(\\\"method\\\") == \\\"majority_vote\\\":\\n\\n        kernel_size = parameters.get(\\\"kernel_size\\\", 5)\\n\\n        new_labels = majority_vote(\\n            inarr.sel(bands=\\\"classification\\\"),\\n            inarr.sel(bands=\\\"probability\\\"),\\n            kernel_size=kernel_size,\\n        )\\n\\n        # Append the per-class probabalities if required\\n        if parameters.get(\\\"keep_class_probs\\\", False):\\n            class_probabilities = inarr.isel(bands=slice(2, None))\\n            new_labels = xr.concat([new_labels, class_probabilities], dim=\\\"bands\\\")\\n\\n    else:\\n        raise ValueError(\\n            f\\\"Unknown post-processing method: {parameters.get('method')}\\\"\\n        )\\n\\n    return new_labels\\n\\n\\n# Below comes the actual UDF part\\n\\n# Apply the Inference UDF\\ndef apply_udf_data(udf_data: UdfData) -> UdfData:\\n    \\\"\\\"\\\"This is the actual openeo UDF that will be executed by the backend.\\\"\\\"\\\"\\n\\n    cube = udf_data.datacube_list[0]\\n    parameters = copy.deepcopy(udf_data.user_context)\\n\\n    arr = cube.get_array().transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n    arr = execute(\\n        inarr=arr,\\n        parameters=parameters,\\n    ).transpose(\\\"bands\\\", \\\"y\\\", \\\"x\\\")\\n\\n    cube = XarrayDataCube(arr)\\n\\n    udf_data.datacube_list = [cube]\\n\\n    return udf_data\\n\\n# Change band names, since the target labels are parameterized in the UDF\\ndef apply_metadata(metadata: CollectionMetadata, context: dict) -> CollectionMetadata:\\n\\n    lut_sorted = lut_from_url(context[\\\"classifier_url\\\"])\\n\\n    return metadata.rename_labels(dimension=\\\"bands\\\", target=get_output_labels(lut_sorted, context))\\n\"}, \"process_id\": \"run_udf\", \"result\": true}}}, \"size\": [{\"dimension\": \"x\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"y\", \"unit\": \"px\", \"value\": 128}, {\"dimension\": \"t\", \"value\": \"P1D\"}]}, \"process_id\": \"apply_neighborhood\"}, \"filterbands1\": {\"arguments\": {\"bands\": [\"classification\"], \"data\": {\"from_node\": \"saveresult2\"}}, \"process_id\": \"filter_bands\"}, \"filterbbox1\": {\"arguments\": {\"data\": {\"from_node\": \"mergecubes4\"}, \"extent\": {\"crs\": \"EPSG:32631\", \"east\": 684000, \"north\": 5631134, \"south\": 5611134, \"west\": 664000}}, \"process_id\": \"filter_bbox\"}, \"loadcollection1\": {\"arguments\": {\"bands\": [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"], \"featureflags\": {\"tilesize\": 128}, \"id\": \"SENTINEL2_L2A\", \"properties\": {\"eo:cloud_cover\": {\"process_graph\": {\"lte1\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": 95.0}, \"process_id\": \"lte\", \"result\": true}}}}, \"spatial_extent\": null, \"temporal_extent\": [\"2023-10-01\", \"2024-09-30\"]}, \"process_id\": \"load_collection\"}, \"loadcollection2\": {\"arguments\": {\"bands\": [\"SCL\"], \"id\": \"SENTINEL2_L2A\", \"properties\": {\"eo:cloud_cover\": {\"process_graph\": {\"lte2\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": 95.0}, \"process_id\": \"lte\", \"result\": true}}}}, \"spatial_extent\": null, \"temporal_extent\": [\"2023-10-01\", \"2024-09-30\"]}, \"process_id\": \"load_collection\"}, \"loadcollection3\": {\"arguments\": {\"bands\": [\"VH\", \"VV\"], \"featureflags\": {\"tilesize\": 128}, \"id\": \"SENTINEL1_GRD\", \"properties\": {\"polarisation\": {\"process_graph\": {\"eq2\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": \"VV&VH\"}, \"process_id\": \"eq\", \"result\": true}}}, \"sat:orbit_state\": {\"process_graph\": {\"eq1\": {\"arguments\": {\"x\": {\"from_parameter\": \"value\"}, \"y\": \"ASCENDING\"}, \"process_id\": \"eq\", \"result\": true}}}}, \"spatial_extent\": null, \"temporal_extent\": [\"2023-10-01\", \"2024-09-30\"]}, \"process_id\": \"load_collection\"}, \"loadcollection4\": {\"arguments\": {\"bands\": [\"DEM\"], \"id\": \"COPERNICUS_30\", \"spatial_extent\": null, \"temporal_extent\": null}, \"process_id\": \"load_collection\"}, \"loadstac1\": {\"arguments\": {\"bands\": [\"Slope\"], \"url\": \"https://stac.openeo.vito.be/collections/COPERNICUS30_DEM_SLOPE\"}, \"process_id\": \"load_stac\"}, \"loadstac2\": {\"arguments\": {\"bands\": [\"precipitation-flux\", \"temperature-mean\"], \"temporal_extent\": [\"2023-10-01\", \"2024-09-30\"], \"url\": \"https://stac.openeo.vito.be/collections/agera5_monthly\"}, \"process_id\": \"load_stac\"}, \"mask1\": {\"arguments\": {\"data\": {\"from_node\": \"loadcollection1\"}, \"mask\": {\"from_node\": \"renamelabels1\"}}, \"process_id\": \"mask\"}, \"mask2\": {\"arguments\": {\"data\": {\"from_node\": \"reducedimension3\"}, \"mask\": {\"from_node\": \"apply6\"}, \"replacement\": 254}, \"process_id\": \"mask\"}, \"mergecubes1\": {\"arguments\": {\"cube1\": {\"from_node\": \"apply2\"}, \"cube2\": {\"from_node\": \"apply3\"}}, \"process_id\": \"merge_cubes\"}, \"mergecubes2\": {\"arguments\": {\"cube1\": {\"from_node\": \"reducedimension1\"}, \"cube2\": {\"from_node\": \"renamelabels6\"}}, \"process_id\": \"merge_cubes\"}, \"mergecubes3\": {\"arguments\": {\"cube1\": {\"from_node\": \"mergecubes1\"}, \"cube2\": {\"from_node\": \"apply4\"}}, \"process_id\": \"merge_cubes\"}, \"mergecubes4\": {\"arguments\": {\"cube1\": {\"from_node\": \"mergecubes3\"}, \"cube2\": {\"from_node\": \"resamplecubespatial2\"}}, \"process_id\": \"merge_cubes\"}, \"reducedimension1\": {\"arguments\": {\"data\": {\"from_node\": \"renamelabels4\"}, \"dimension\": \"t\", \"reducer\": {\"process_graph\": {\"min1\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"min\", \"result\": true}}}}, \"process_id\": \"reduce_dimension\"}, \"reducedimension2\": {\"arguments\": {\"data\": {\"from_node\": \"loadcollection4\"}, \"dimension\": \"t\", \"reducer\": {\"process_graph\": {\"min2\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"min\", \"result\": true}}}}, \"process_id\": \"reduce_dimension\"}, \"reducedimension3\": {\"arguments\": {\"data\": {\"from_node\": \"applyneighborhood2\"}, \"dimension\": \"t\", \"reducer\": {\"process_graph\": {\"mean2\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"mean\", \"result\": true}}}}, \"process_id\": \"reduce_dimension\"}, \"reducedimension4\": {\"arguments\": {\"data\": {\"from_node\": \"applyneighborhood4\"}, \"dimension\": \"t\", \"reducer\": {\"process_graph\": {\"mean3\": {\"arguments\": {\"data\": {\"from_parameter\": \"data\"}}, \"process_id\": \"mean\", \"result\": true}}}}, \"process_id\": \"reduce_dimension\"}, \"renamelabels1\": {\"arguments\": {\"data\": {\"from_node\": \"toscldilationmask1\"}, \"dimension\": \"bands\", \"target\": [\"S2-L2A-SCL_DILATED_MASK\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels2\": {\"arguments\": {\"data\": {\"from_node\": \"mask1\"}, \"dimension\": \"bands\", \"source\": [\"B02\", \"B03\", \"B04\", \"B05\", \"B06\", \"B07\", \"B08\", \"B8A\", \"B11\", \"B12\"], \"target\": [\"S2-L2A-B02\", \"S2-L2A-B03\", \"S2-L2A-B04\", \"S2-L2A-B05\", \"S2-L2A-B06\", \"S2-L2A-B07\", \"S2-L2A-B08\", \"S2-L2A-B8A\", \"S2-L2A-B11\", \"S2-L2A-B12\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels3\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial2\"}, \"dimension\": \"bands\", \"source\": [\"VH\", \"VV\"], \"target\": [\"S1-SIGMA0-VH\", \"S1-SIGMA0-VV\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels4\": {\"arguments\": {\"data\": {\"from_node\": \"loadstac1\"}, \"dimension\": \"bands\", \"target\": [\"slope\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels5\": {\"arguments\": {\"data\": {\"from_node\": \"reducedimension2\"}, \"dimension\": \"bands\", \"source\": [\"DEM\"], \"target\": [\"COP-DEM\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels6\": {\"arguments\": {\"data\": {\"from_node\": \"renamelabels5\"}, \"dimension\": \"bands\", \"target\": [\"elevation\"]}, \"process_id\": \"rename_labels\"}, \"renamelabels7\": {\"arguments\": {\"data\": {\"from_node\": \"loadstac2\"}, \"dimension\": \"bands\", \"target\": [\"AGERA5-PRECIP\", \"AGERA5-TMEAN\"]}, \"process_id\": \"rename_labels\"}, \"resamplecubespatial1\": {\"arguments\": {\"data\": {\"from_node\": \"mergecubes2\"}, \"method\": \"bilinear\", \"target\": {\"from_node\": \"apply2\"}}, \"process_id\": \"resample_cube_spatial\"}, \"resamplecubespatial2\": {\"arguments\": {\"data\": {\"from_node\": \"renamelabels7\"}, \"method\": \"bilinear\", \"target\": {\"from_node\": \"apply2\"}}, \"process_id\": \"resample_cube_spatial\"}, \"resamplespatial1\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"loadcollection2\"}, \"method\": \"near\", \"projection\": null, \"resolution\": 10}, \"process_id\": \"resample_spatial\"}, \"resamplespatial2\": {\"arguments\": {\"align\": \"upper-left\", \"data\": {\"from_node\": \"sarbackscatter1\"}, \"method\": \"near\", \"projection\": null, \"resolution\": 20.0}, \"process_id\": \"resample_spatial\"}, \"sarbackscatter1\": {\"arguments\": {\"coefficient\": \"sigma0-ellipsoid\", \"contributing_area\": false, \"data\": {\"from_node\": \"loadcollection3\"}, \"elevation_model\": \"COPERNICUS_30\", \"ellipsoid_incidence_angle\": false, \"local_incidence_angle\": false, \"mask\": false, \"noise_removal\": true}, \"process_id\": \"sar_backscatter\"}, \"saveresult1\": {\"arguments\": {\"data\": {\"from_node\": \"reducedimension4\"}, \"format\": \"GTiff\", \"options\": {\"filename_prefix\": \"cropland-raw_2023-10-01_2024-09-30\"}}, \"process_id\": \"save_result\"}, \"saveresult2\": {\"arguments\": {\"data\": {\"from_node\": \"apply5\"}, \"format\": \"GTiff\", \"options\": {\"filename_prefix\": \"cropland_2023-10-01_2024-09-30\"}}, \"process_id\": \"save_result\"}, \"saveresult3\": {\"arguments\": {\"data\": {\"from_node\": \"mask2\"}, \"format\": \"GTiff\", \"options\": {\"filename_prefix\": \"croptype-raw_2023-10-01_2024-09-30\"}}, \"process_id\": \"save_result\"}, \"saveresult4\": {\"arguments\": {\"data\": {\"from_node\": \"apply7\"}, \"format\": \"GTiff\", \"options\": {\"filename_prefix\": \"croptype_2023-10-01_2024-09-30\"}}, \"process_id\": \"save_result\", \"result\": true}, \"toscldilationmask1\": {\"arguments\": {\"data\": {\"from_node\": \"resamplespatial1\"}, \"erosion_kernel_size\": 3, \"kernel1_size\": 17, \"kernel2_size\": 77, \"mask1_values\": [2, 4, 5, 6, 7], \"mask2_values\": [3, 8, 9, 10, 11], \"scl_band_name\": \"SCL\"}, \"process_id\": \"to_scl_dilation_mask\"}}}, \"progress\": 100, \"status\": \"finished\", \"title\": \"Test worldcereal croptype process graph\", \"updated\": \"2025-07-23T10:09:22Z\", \"usage\": {\"cpu\": {\"unit\": \"cpu-seconds\", \"value\": 32509.190274877004}, \"duration\": {\"unit\": \"seconds\", \"value\": 2226}, \"input_pixel\": {\"unit\": \"mega-pixel\", \"value\": 1923.3505992889404}, \"max_executor_memory\": {\"unit\": \"gb\", \"value\": 4.997936248779297}, \"memory\": {\"unit\": \"mb-seconds\", \"value\": 234724703.61786017}, \"network_received\": {\"unit\": \"b\", \"value\": 137971402327}, \"orfeo_backscatter_input_pixels\": {\"unit\": \"count\", \"value\": 123731968}, \"sar_backscatter_soft_errors\": {\"unit\": \"fraction\", \"value\": 0}}}}</script>\n",
                            "    </openeo-job>\n",
                            "    "
                        ],
                        "text/plain": [
                            "<BatchJob job_id='j-2507230931534eb5a46172271a92d8ce'>"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "# ONNX_DEPS_URL = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/openeo/onnx_dependencies_1.16.3.zip\"\n",
                "ONNX_DEPS_URL = \"https://s3.waw3-1.cloudferro.com/swift/v1/project_dependencies/onnx_deps_python311.zip\"\n",
                "TORCH_DEPS_URL = \"https://s3.waw3-1.cloudferro.com/swift/v1/project_dependencies/torch_deps_python311.zip\"\n",
                "\n",
                "job_options = {\n",
                "        \"driver-memory\": \"4g\",\n",
                "        \"executor-memory\": \"2g\",\n",
                "        \"executor-memoryOverhead\": \"1g\",\n",
                "        \"python-memory\": \"3g\",\n",
                "        \"soft-errors\": \"true\",\n",
                "        \"udf-dependency-archives\": [f\"{ONNX_DEPS_URL}#onnx_deps\", \n",
                "                                   f\"{TORCH_DEPS_URL}#feature_deps\"],\n",
                "        \"image-name\": \"python311\"\n",
                "    }\n",
                "\n",
                "\n",
                "pg.execute_batch(\n",
                "    title=\"Test worldcereal croptype process graph\",\n",
                "    job_options=job_options,\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In case your process graph works: you can save it to a JSON file locally."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import json\n",
                "\n",
                "path_to_json = \"./process_graph.json\"\n",
                "\n",
                "with open(path_to_json, \"w\") as f:\n",
                "    json.dump(pg.flat_graph(), f, indent=2)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "After this, the above JSON file can be used to create the UDP. From this point onwards, it's manual work (due to dependencies on GFMap). This might change in the future. \n",
                "\n",
                "It is recommend to use a previous version of the UDP, e.g.: https://github.com/WorldCereal/worldcereal-classification/blob/worldcereal_crop_type_v1.1.1/src/worldcereal/udp/worldcereal_crop_type.json.\n",
                "\n",
                "The following input parameters need to be parametrized. How to do this, can be seen in the UDP example above. \n",
                "\n",
                "- spatial_extent\n",
                "- temporal_extent\n",
                "- orbit_state\n",
                "- postprocess_method\n",
                "- postprocess_kernel_size\n",
                "- model_url\n",
                "\n",
                "After the UDP is finished, you can push it to a feature branch on Github. Using the RAW Github URL to your new UDP, you can test again if your UDP behaves as expected, using the code snippet below:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Authenticated using refresh token.\n",
                        "0:00:00 Job 'j-25072310144848918102642ca288ab48': send 'start'\n",
                        "0:00:13 Job 'j-25072310144848918102642ca288ab48': created (progress 0%)\n",
                        "0:00:19 Job 'j-25072310144848918102642ca288ab48': created (progress 0%)\n",
                        "0:00:25 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:00:33 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:00:44 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:00:56 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:01:11 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:01:31 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:01:55 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:02:25 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:03:03 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:03:49 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:04:48 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:05:48 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:06:49 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:07:49 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:08:49 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:09:49 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:10:50 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:11:50 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:12:51 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:13:51 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:14:51 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:15:51 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:16:52 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:17:52 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:18:53 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:19:53 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:20:53 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:21:54 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:22:54 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:23:54 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:24:54 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:25:55 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:26:55 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:27:55 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:28:55 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:29:56 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:30:56 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:31:56 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:32:56 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:33:57 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:34:57 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:35:57 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:36:58 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:37:58 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:38:58 Job 'j-25072310144848918102642ca288ab48': running (progress N/A)\n",
                        "0:39:59 Job 'j-25072310144848918102642ca288ab48': finished (progress 100%)\n"
                    ]
                }
            ],
            "source": [
                "import openeo\n",
                "\n",
                "c = openeo.connect('openeo.dataspace.copernicus.eu').authenticate_oidc()\n",
                "\n",
                "# Adjust this to the namespace of your newly created UDP\n",
                "namespace = 'https://raw.githubusercontent.com/WorldCereal/worldcereal-classification/refs/tags/worldcereal_crop_type_v1.1.0/src/worldcereal/udp/worldcereal_crop_type.json'\n",
                "\n",
                "model_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/models/PhaseII/downstream/tests/be_multiclass-test_custommodel.onnx\"\n",
                "# temporal_extent = [\"2020-12-01\", \"2021-11-30\"]\n",
                "# spatial_extent = {\"west\": 549260.0538727192, \"south\": 5643096.65598935, \"east\": 550221.062129418, \"north\": 5643965.825801395, \"crs\": \"EPSG:32631\"}\n",
                "\n",
                "temporal_extent = [\"2023-10-01\", \"2024-09-30\"]\n",
                "spatial_extent = {\"west\": 664000, \"south\": 5611134, \"east\": 684000, \"north\": 5631134, \"crs\": \"EPSG:32631\"}\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "orbit_state = \"ASCENDING\"  # optional parameter, default is \"DESCENDING\"\n",
                "postprocess_method = \"majority_vote\"  # optional parameter, default is \"smooth_probabilities\"\n",
                "postprocess_kernel_size = 5  # optional parameter,  default is 5\n",
                "\n",
                "\n",
                "cube = c.datacube_from_process(\n",
                "    process_id='worldcereal_crop_type',\n",
                "    namespace=namespace,\n",
                "    spatial_extent=spatial_extent,\n",
                "    temporal_extent=temporal_extent,\n",
                "    model_url=model_url,\n",
                "    orbit_state=orbit_state,\n",
                "    postprocess_method=postprocess_method,\n",
                "    postprocess_kernel_size=postprocess_kernel_size\n",
                ")\n",
                "\n",
                "job = cube.execute_batch(\n",
                "    title=\"Test worldcereal_crop_type UDP\",\n",
                ")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "worldcereal-dev",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
