{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301a591",
   "metadata": {},
   "source": [
    "![](../resources/Custom_croptype_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a284b",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [Introduction](###-Introduction)\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Choose finetuned Presto model for your experiments](###-1.-Choose-finetuned-Presto-model-for-your-experiments)\n",
    "- [2. Train your model](###-2.-Train-your-model)\n",
    "- [3. Local inference](###-3.-Local-inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c162856",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model for your area, season and crop types of interest.\n",
    "\n",
    "For training the model, you can use a combination of:\n",
    "- publicly available reference data harmonized by the WorldCereal consortium;\n",
    "- your own private reference data.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "In case you would like to use private reference data to train your model, make sure to first complete our <a href='https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_private_extractions_app.ipynb' target='_blank' rel='noopener'>private extractions workflow.</a>\n",
    "\n",
    "For the sake of simplicity here, we will only make use of public reference data.\n",
    "</div>\n",
    "\n",
    "After model training, we deploy your custom model to the cloud, from where it can be accessed by OpenEO, allowing you to apply your model on your area and season of interest and generate your custom crop type map.\n",
    "\n",
    "We also provide an alternative pathway to run inference locally, on a series of prepared patches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4436d",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "#### Option 1: Run on Terrascope\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment. Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">When you click the button, you will be prompted with \"Server Options\".<br>\n",
    "Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident?<br>\n",
    "Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2Ftrainings%2F20260212_Kenya_workshop_croptype.ipynb&branch=main\"><img src=\"https://img.shields.io/badge/Run%20notebook%20on-Terrascope-brightgreen\" alt=\"Run notebook\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> <br>\n",
    "Every time you click the above link, the latest version of the notebook will be fetched, potentially leading to conflicts with changes you have made yourself.<br>\n",
    "To avoid such code conflicts, we recommend you to make a copy of the notebook and make changes only in your copied version.\n",
    "</div>\n",
    "\n",
    "\n",
    "#### Option 2: Install Locally\n",
    "\n",
    "If you prefer to install the package locally, you can create the WorldCereal environment using **Conda** or **pip**.\n",
    "\n",
    "- **Conda**<br>\n",
    "First clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/WorldCereal/worldcereal-classification.git\n",
    "cd worldcereal-classification\n",
    "```\n",
    "Next, install the package locally:\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "\n",
    "- **Pip**<br>\n",
    "`pip install \"worldcereal-classification[train,notebooks] @ git+https://github.com/worldcereal/worldcereal-classification.git\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "249475dd",
   "metadata": {},
   "source": [
    "### Download test dataset\n",
    "\n",
    "Before starting the below exercise, you are encouraged to try out the [RDM](https://rdm.esa-worldcereal.org) data upload procedure using the dataset automatically downloaded to your \"download\" folder.\n",
    "\n",
    "Execute the next cell to start the download."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25f4939c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "target_path = Path(\"./download/zmb_north_test_dataset.gpkg\")\n",
    "target_path.parent.mkdir(exist_ok=True)\n",
    "# Download and extract the data if not already present\n",
    "if not target_path.exists():\n",
    "    url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/zambia/zmb_north_test_dataset.gpkg\"\n",
    "    # Download the file\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(url, target_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb9cc",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).<br>\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo.\n",
    "\n",
    "\n",
    "#### CDSE authentication\n",
    "\n",
    "Run the cell below to make sure you are connected to your CDSE account before starting the application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e253643a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo_gfmap.backend import cdse_connection\n",
    "cdse_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9953952",
   "metadata": {},
   "source": [
    "#### Ensure proper access to functionality\n",
    "\n",
    "Execute the next block of code to ensure this notebook has access to all functionalities needed in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71bdf57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dirctory to sys.path\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b8b10f",
   "metadata": {},
   "source": [
    "### 1. Choose finetuned Presto model for your experiments\n",
    "\n",
    "In the cell below, you have the choice to either use our default presto model that was trained for global requirements, or a more specialised model that was finetuned for Kenya.\n",
    "\n",
    "Simply set `model_bundle` parameter to either \"kenya\" or \"default\".\n",
    "\n",
    "We recommend to use the kenya model.\n",
    "\n",
    "Execute the next cell before continuing!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4eeece",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import urllib.request\n",
    "from worldcereal.train.backbone import checkpoint_fingerprint\n",
    "from worldcereal.openeo.parameters import DEFAULT_SEASONAL_MODEL_URL\n",
    "\n",
    "model_bundle = \"kenya\"\n",
    "# model_bundle = \"default\"\n",
    "\n",
    "if model_bundle == \"kenya\":\n",
    "    presto_model_path = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/kenya/presto-prometheo-kenya-finetuned-noaugment-month-augment=False-balance=True-timeexplicit=True-masking=enabled-run=202602101037_encoder.pt\"\n",
    "    seasonal_model_zip_path = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/kenya/presto-prometheo-kenya-finetuned-noaugment-month-augment=False-balance=True-timeexplicit=True-masking=enabled-run=202602101037.zip\"\n",
    "    # Download the kenya presto model to your machine to run training and local inference\n",
    "    local_pt = Path(\"./local_inference/kenya_local_presto_encoder.pt\")\n",
    "    local_pt.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not local_pt.exists():\n",
    "        urllib.request.urlretrieve(presto_model_path, local_pt)\n",
    "    # We'll need to explicitly check model's fingerprint here\n",
    "    presto_fp = checkpoint_fingerprint(local_pt)\n",
    "    \n",
    "    presto_model_package = {\"presto_remote_path\": presto_model_path,\n",
    "                            \"presto_local_path\": str(local_pt),\n",
    "                            \"presto_fingerprint\": presto_fp,\n",
    "                            \"seasonal_model_path\": seasonal_model_zip_path}\n",
    "\n",
    "    print(\"Finetuned Presto model for Kenya selected.\")\n",
    "    \n",
    "elif model_bundle == \"default\":\n",
    "    seasonal_model_zip_path = DEFAULT_SEASONAL_MODEL_URL\n",
    "    presto_model_package = None\n",
    "    \n",
    "    print(\"Globally finetuned Presto model selected.\")\n",
    "    \n",
    "else:\n",
    "    raise ValueError(f\"Unknown model bundle: {model_bundle}. Supported options are 'kenya' and 'default'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02002aa5",
   "metadata": {},
   "source": [
    "### 2. Train your model\n",
    "\n",
    "Launch the application in the next cell to train your crop type model for Kenya!\n",
    "\n",
    "Make sure to choose the option \"**Full workflow**\" in the welcome screen of the application.<br>\n",
    "\n",
    "Then complete steps 1 --> 6 (stop before deploying your model in step 7).<br>\n",
    "\n",
    "Brief outline of steps:\n",
    "1. Retrieve existing reference data (make sure to select Kenya as AOI!)\n",
    "2. Inspect the reference data\n",
    "3. Choose your season of interest and align your reference data to that season\n",
    "4. Compute Presto embeddings on your reference data\n",
    "5. Select data and compile the list of classes you want to include in your model\n",
    "6. Train your model\n",
    "\n",
    "Once finalized, **continue with the next cell in this notebook**.\n",
    "\n",
    "Later, you can still run steps 7 -> 9 (inference in the cloud for your area of interest)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094f523c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.training_app import WorldCerealTrainingApp\n",
    "\n",
    "app = WorldCerealTrainingApp().run(presto_model_package=presto_model_package)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a7d84",
   "metadata": {},
   "source": [
    "### 3. Local Inference\n",
    "\n",
    "As an alternative to the model deployment and inference steps as exposed in the application above (steps 7 -> 9), we offer here the possibility to quickly run your newly trained model on some prepared patches across Kenya. For these patches, we have already fetched the required pre-processed time series inputs from CDSE using openEO workflows. For more information on this procedure, you can consult the [worldcereal_preprocessed_inputs notebook](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_preprocessed_inputs.ipynb).\n",
    "\n",
    "The next cells load one of these prepared patches, show a random NDVI slice for context, and call `run_seasonal_inference()` with the seasonal backbone plus your custom croptype head to produce a croptype raster for the chosen season.\n",
    "\n",
    "This step is meant for fast QA and tuning of inference knobs and post-processing; it does not replace the full openEO production run. The output is written as a GeoTIFF under `./local_inference/` with a filename that includes the patch and head package, so you can inspect it in your GIS tools or compare with reference data.\n",
    "\n",
    "\n",
    "**Download and visualize one patch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761c28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "\n",
    "from pyproj import CRS\n",
    "import xarray as xr\n",
    "\n",
    "from notebook_utils.preprocessed_inputs import get_band_statistics_netcdf, visualize_timeseries_netcdf\n",
    "\n",
    "# randomly select an option from the following list:\n",
    "options = [\"01\", \"02\", \"03\", \"04\", \"05\", \"06\", \"07\", \"08\", \"09\", \"10\", \"11\", \"12\"]\n",
    "selected = random.choice(options)\n",
    "\n",
    "patch_id = f\"patch{selected}\"\n",
    "print(f\"Selected patch: {patch_id}\")\n",
    "\n",
    "# Download the demo patch from artifactory if the requested patch is missing locally.\n",
    "local_file_path = Path(f\"./local_inference/input_patches/preprocessed-inputs_{patch_id}.nc\")\n",
    "if not local_file_path.exists():\n",
    "    local_file_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if not local_file_path.exists():\n",
    "        print(f\"Downloading demo preprocessed inputs to {local_file_path}...\")\n",
    "        remote_url = (\n",
    "            f\"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/kenya/preprocessed-inputs_{patch_id}.nc\"\n",
    "        )\n",
    "        urllib.request.urlretrieve(remote_url, local_file_path)\n",
    "\n",
    "ds = xr.open_dataset(local_file_path, engine=\"netcdf4\")\n",
    "epsg = CRS.from_wkt(ds.crs.attrs[\"spatial_ref\"]).to_epsg()\n",
    "\n",
    "# Visualize a random timestamp from the patch\n",
    "ndvi = (ds[\"S2-L2A-B08\"] - ds[\"S2-L2A-B04\"]) / (ds[\"S2-L2A-B08\"] + ds[\"S2-L2A-B04\"])\n",
    "timestamp_ind = np.random.randint(0, ndvi.shape[0])\n",
    "ndvi.isel(t=timestamp_ind).plot(cmap=\"RdYlGn\", vmin=-0.8, vmax=0.8)\n",
    "\n",
    "# Show band statistics\n",
    "stats = get_band_statistics_netcdf(ds)\n",
    "\n",
    "# Visualize random time series\n",
    "visualize_timeseries_netcdf(ds, band=\"NDVI\", npixels=6, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc46081b",
   "metadata": {},
   "source": [
    "**Set processing parameters**\n",
    "\n",
    "Configure the inference and post-processing parameters:\n",
    "\n",
    "- `mask_cropland`: Apply cropland masking during croptype predictions\n",
    "- `enable_cropland_head`: Also export cropland probability rasters for quality assurance\n",
    "- `export_class_probs`: Emit per-class probability layers for each crop type\n",
    "- `croptype_postprocess_enabled`: Apply spatial post-processing to croptype classifications\n",
    "- `croptype_postprocess_method`: Post-processing algorithm (e.g., \"majority_vote\")\n",
    "- `croptype_postprocess_kernel`: Kernel size for post-processing filter\n",
    "- `cropland_postprocess_enabled`: Apply spatial post-processing to cropland mask\n",
    "- `cropland_postprocess_method`: Post-processing algorithm for cropland\n",
    "- `cropland_postprocess_kernel`: Kernel size for cropland post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47a93312",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "mask_cropland = True  # cropland masking using default cropland model\n",
    "enable_cropland_head = True  # also export cropland rasters for QA\n",
    "enable_croptype_head = True  # whether to run the croptype head at all (if False, only cropland predictions will be made)\n",
    "export_class_probs = True  # export per-class probabilities in the crop type product\n",
    "\n",
    "croptype_postprocess_enabled = True\n",
    "croptype_postprocess_method = \"majority_vote\"\n",
    "croptype_postprocess_kernel = 3\n",
    "\n",
    "cropland_postprocess_enabled = True\n",
    "cropland_postprocess_method = \"majority_vote\"\n",
    "cropland_postprocess_kernel = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d602ebf",
   "metadata": {},
   "source": [
    "**Specify year and season**\n",
    "\n",
    "For your information, we first display for which season_id and growing season period you have trained your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749a8d09",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "season_id = app.season_id\n",
    "print(f\"Model trained for season id: {season_id}\")\n",
    "season_window = app.season_window\n",
    "print(f\"Model trained for season: {season_window.start_date} - {season_window.end_date}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644e10e5",
   "metadata": {},
   "source": [
    "In the next cell, you can now manually set a start and end date + season id.\n",
    "\n",
    "**NOTE**: for the preprocessed input patches you are working with here, we only have data available between 2025-01-01 and 2026-01-01 !!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87f3dc4",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "season_id = \"xxx\"                 # e.g. LongRains \n",
    "season_start_date = \"YYYY-mm-dd\"  # e.g. 2021-03-01\n",
    "season_end_date = \"YYYY-mm-dd\"    # e.g. 2021-08-31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac498aef",
   "metadata": {},
   "source": [
    "**Run local inference**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75363d2",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from notebook_utils.local_inference import (\n",
    "    run_seasonal_inference,\n",
    "    build_postprocess_spec,\n",
    "    classification_to_geotiff,\n",
    ")\n",
    "\n",
    "season_windows = {\n",
    "    season_id: (str(season_start_date), str(season_end_date))\n",
    "}\n",
    "\n",
    "croptype_postprocess = build_postprocess_spec(\n",
    "    enabled=croptype_postprocess_enabled,\n",
    "    method=croptype_postprocess_method,\n",
    "    kernel_size=croptype_postprocess_kernel,\n",
    ")\n",
    "cropland_postprocess = build_postprocess_spec(\n",
    "    enabled=cropland_postprocess_enabled,\n",
    "    method=cropland_postprocess_method,\n",
    "    kernel_size=cropland_postprocess_kernel,\n",
    ")\n",
    "\n",
    "classification_result = run_seasonal_inference(\n",
    "    ds,  # or local_file_path\n",
    "    seasonal_model_zip=seasonal_model_zip_path,\n",
    "    croptype_head_zip=app.head_package_path,  # the crop type model you trained in the app\n",
    "    season_ids=[season_id],\n",
    "    season_windows=season_windows,\n",
    "    enforce_cropland_gate=mask_cropland,\n",
    "    export_class_probabilities=export_class_probs,\n",
    "    enable_cropland_head=enable_cropland_head,\n",
    "    enable_croptype_head=enable_croptype_head,\n",
    "    croptype_postprocess=croptype_postprocess,\n",
    "    cropland_postprocess=cropland_postprocess,\n",
    "    as_dataset=False,  # DataArray for GeoTIFF\n",
    ")\n",
    "\n",
    "# Specify output directory and name for the classification result\n",
    "output_dir = Path(\"./local_inference\")\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "# retrieve model name\n",
    "head_tag = Path(app.head_package_path).stem\n",
    "classification_result_path = output_dir / f\"croptype_{season_id}_{patch_id}_{head_tag}.tif\"\n",
    "\n",
    "# get model class names from the model config file\n",
    "head_output_dir = app.head_output_path\n",
    "head_config_path = head_output_dir / \"config.json\"\n",
    "if not head_config_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Torch head config not found at {head_config_path}. Check the training logs above.\"\n",
    "    )\n",
    "with head_config_path.open() as fp:\n",
    "    head_config = json.load(fp)\n",
    "class_map = {i: name for i, name in enumerate(head_config[\"classes_list\"])}\n",
    "\n",
    "# Finally, save to geotiff\n",
    "classification_to_geotiff(classification_result, epsg, classification_result_path, class_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a33b9f82",
   "metadata": {},
   "source": [
    "The following cell helps you to quickly visualize your maps.\n",
    "\n",
    "For more detailed inspection (for instance of probabilities), we advise to load the product(s) in QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd74663",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.local_inference import isolate_cropland_croptype_products\n",
    "from notebook_utils.visualization import visualize_products\n",
    "\n",
    "# split one raster into separate cropland and crop type products\n",
    "products = isolate_cropland_croptype_products(\n",
    "    classification_result_path,\n",
    "    enable_cropland_head)\n",
    "\n",
    "# Get class names from your model and convert to look-up table compatible with visualization function\n",
    "lut_croptype = {v: k for k, v in sorted(class_map.items(), key=lambda kv: kv[0])}\n",
    "luts = {'croptype': lut_croptype}\n",
    "\n",
    "# Run simple visualization of the classification bands\n",
    "visualize_products(products, luts=luts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47960734",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this demo!\n",
    "\n",
    "You can now go back to the app and run through steps 7 - 9 to launch a map production job in your area of choice!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
