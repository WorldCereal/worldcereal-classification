{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301a591",
   "metadata": {},
   "source": [
    "![](../resources/20251020_Spaceborne_EO_tech_school.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a284b",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [Introduction](###-Introduction)\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Gather and prepare your training data](###-1.-Gather-and-prepare-your-training-data)\n",
    "- [2. Train custom classification model](###-2.-Train-custom-classification-model)\n",
    "- [3. Deploy your custom model](###-3.-Deploy-your-custom-model)\n",
    "- [4. Testing your model locally](###-4.-Testing-your-model-locally)\n",
    "- [5. BONUS: Apply your model anywhere!](###-5.-BONUS:-Apply-your-model-anywhere!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c162856",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model using the WorldCereal crop mapping system.<br>\n",
    "\n",
    "For today's exercise we'll be constructing a model based on reference data from a data dense region (France) and apply this model to an area in Czech Republic to see how tranferable our model is across space.\n",
    "\n",
    "<div style=\"background-color:#fff3cd; border-left:5px solid #ffeeba; padding:10px; color:#856404;\">\n",
    "This colored box is used throughout the notebook to highlight questions, tasks, or reflections for you to consider while completing the exercise.<br>\n",
    "GOOD LUCK!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4436d",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment.<br>\n",
    "Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> <br>\n",
    "When you click the button, you will be prompted with \"Server Options\".<br>\n",
    "Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident?<br>\n",
    "Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2Ftrainings%2F20251020_Spaceborne_EO_tech_agri.ipynb&branch=main\"><img src=\"https://img.shields.io/badge/Run%20exercise%20on-Terrascope-brightgreen\" alt=\"Generate custom crop type map\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>WARNING:</b> <br>\n",
    "Every time you click the above link, the latest version of the notebook will be fetched, potentially leading to conflicts with changes you have made yourself.<br>\n",
    "To avoid such code conflicts, we recommend you to make a copy of the notebook and make changes only in your copied version.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb9cc",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).<br>\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo.\n",
    "\n",
    "Execute the next block of code to ensure this notebook has access to all functionalities needed in this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6f4d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dirctory to sys.path\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116e791",
   "metadata": {},
   "source": [
    "### 1. Gather and prepare your training data\n",
    "\n",
    "For training a crop type model, you can use a combination of:\n",
    "- publicly available reference data harmonized by the WorldCereal consortium;\n",
    "- your own private reference data (not part of today's exercise).\n",
    "\n",
    "The cell below provides you with a quick overview of the publicly exposed reference datasets for which WorldCereal has already done satellite extractions. Hence these are ready to be plugged into model training. In the next few weeks, this extractions database will receive a major update, adding many more datasets for you to use in model training.\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note on reference data availability:</b><br>\n",
    "\n",
    "For a detailed exploration of available reference data for your region of interest, you can:\n",
    "\n",
    "- use the WorldCereal Reference Data Module user interface, available [here](https://rdm.esa-worldcereal.org/). More explanation can be found [here](https://worldcereal.github.io/worldcereal-documentation/rdm/explore.html#explore-data-through-our-user-interface).\n",
    "- use our dedicated notebook [worldcereal_RDM_demo.ipynb](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_RDM_demo.ipynb).\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4183ab6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import retrieve_extractions_extent\n",
    "\n",
    "extents = retrieve_extractions_extent()\n",
    "print(f\"Found {len(extents)} datasets with extractions.\")\n",
    "extents.explore(\n",
    "            style_kwds={\n",
    "                \"fillOpacity\": 0.05,  # Transparency of polygon fill (0 = fully transparent, 1 = opaque)\n",
    "                \"weight\": 1,  # Border line width\n",
    "            },\n",
    "            highlight=False,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64e8c9",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest (AOI)**\n",
    "\n",
    "Provide a bounding box specifying the region in which you would like to look for available reference data.<br>\n",
    "\n",
    "When running the code snippet below, an interactive map will be visualized.<br>\n",
    "Click the Rectangle button on the left hand side of the map to start drawing your region of interest.<br>\n",
    "The widget will automatically store the coordinates of the last rectangle you drew on the map.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4e10d9",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff3cd; border-left:5px solid #ffeeba; padding:10px; color:#856404;\">\n",
    "<b>Your turn:</b><br>\n",
    "For the purpose of this exercise, select a bounding box in France, not exceeding 1000 kmÂ².<br>\n",
    "(the larger the area, the longer the request for reference data will take...)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3c0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "map = ui_map(area_limit=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4b0f1",
   "metadata": {},
   "source": [
    "**Step 2: Get all available reference data**\n",
    "\n",
    "You can now query both public and private extractions and retrieve the relevant samples based on your defined area of interest.<br>\n",
    "By default, a spatial buffer of 250 km is applied to your area of interest to ensure sufficient training data is found.<br>\n",
    "You can freely expand this search perimeter by changing the value of the `buffer` parameter.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Note on the use of private data:</b><br>\n",
    "In case you would like to include your private training data, make sure to first prepare the necessary extractions through our dedicated notebook --> <b><a href=https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_private_extractions.ipynb>worldcereal_private_extractions.ipynb.</a></b><br>\n",
    "\n",
    "Then, specify the private_extractions_path in the cell below, where your private extractions reside!\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Important consideration on model scope!</b><br>\n",
    "\n",
    "By default, we filter the reference data explicitly to only retain temporary crops, by setting the `filter_temporary_crops` parameter to `True`.<br>\n",
    "This effectively means that you will (by default) only be able to train a model distinguishing different types of temporary crops.<br>\n",
    "In case you would like to expand your scope towards other land cover and/or permanent crops, please set `filter_temporary_crops` to `False`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a815d57",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff3cd; border-left:5px solid #ffeeba; padding:10px; color:#856404;\">\n",
    "For this exercise, we only use public data on temporary crops<br>\n",
    "The datasets in France contain many crop types. We have limited the query to a fixed number of crops to not make things overly complex.<br>\n",
    "No need to change anything in the next cell.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1721e1",
   "metadata": {
    "kernelspec": {
     "display_name": "worldcereal",
     "language": "python",
     "name": "python3"
    },
    "language_info": {
     "codemirror_mode": {
      "name": "ipython",
      "version": 3
     },
     "file_extension": ".py",
     "mimetype": "text/x-python",
     "name": "python",
     "nbconvert_exporter": "python",
     "pygments_lexer": "ipython3",
     "version": "3.10.0"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.extractions import query_extractions\n",
    "\n",
    "# Retrieve the polygon you drew on the map\n",
    "polygon = map.get_polygon_latlon()\n",
    "\n",
    "# Specify a buffer distance to expand your search perimeter\n",
    "buffer = 250000  # meters\n",
    "\n",
    "# Specify the path to the private extractions data; \n",
    "# if you followed the private extractions notebook, your extractions path should be the one commented below;\n",
    "# if you leave this None, only public data will be queried\n",
    "private_extractions_path = None\n",
    "# private_extractions_path = Path('./extractions/worldcereal_merged_extractions.parquet')\n",
    "\n",
    "# Specify whether you are only interested in temporary crops only (True) or all available classes (False)\n",
    "filter_temporary_crops = True\n",
    "\n",
    "# For the purpose of this exercise, we limit the number of crops to be considered\n",
    "crop_types = [1101060000, 1103080080, 1103090060, 1106000031, 1111000010, 1111020010, 1101060001, 1106000020, 1101010011, 1101020001, 1101020002, 1103060000, 1103060040, 1103110040, 1111000000, 1105010010, 1105010020, 1107000010, 1106000030, 1106000010, 1105010040, 1105000030, 1103090040, 1107000031, 1108020010]\n",
    "\n",
    "# Query our public database of training data\n",
    "extractions = query_extractions(polygon, buffer, private_parquet_path=private_extractions_path, filter_cropland=filter_temporary_crops, crop_types=crop_types)\n",
    "extractions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e4487",
   "metadata": {},
   "source": [
    "**Step 3: Perform a quick quality check**\n",
    "\n",
    "In this step, we provide you with some tools to quickly assess the quality of the datasets.\n",
    "\n",
    "Upon executing this cell, you will be prompted to enter a dataset name (ref_id) for inspection.\n",
    "\n",
    "Especially the visualization of the time series might help you better define your season of interest later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d333",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import get_band_statistics, visualize_timeseries\n",
    "\n",
    "dataset_name = input('Enter the dataset name: ')\n",
    "subset_data = extractions.loc[extractions['ref_id'] == dataset_name]\n",
    "# Optionally, filter by crop group:\n",
    "# subset_data = subset_data[subset_data['sampling_label'] == 'wheat']\n",
    "\n",
    "# Check band statistics\n",
    "band_stats = get_band_statistics(subset_data)\n",
    "\n",
    "# Visualize NDVI timeseries for a few samples\n",
    "visualize_timeseries(subset_data, band='NDVI', nsamples=3, random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7a08f4",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff3cd; border-left:5px solid #ffeeba; padding:10px; color:#856404;\">\n",
    "Optionally also try to visualize the Sentinel-1 VV band using the visualize_timeseries function.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19e73d1",
   "metadata": {},
   "source": [
    "**Step 4: Select your season of interest**\n",
    "\n",
    "Keep in mind that in WorldCereal, we train **season-specific** crop classifiers.<br>\n",
    "In this step, you are asked to specify your cropping season of interest.<br>\n",
    "Based on this information, we get rid of irrelevant training data and prepare the classification features in the next step.<br>\n",
    "\n",
    "To gain a better understanding of crop seasonality in your area of interest, you can consult the WorldCereal crop calendars (by executing the next cell), or check out the [USDA crop calendars](https://ipad.fas.usda.gov/ogamaps/cropcalendar.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcf426",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import retrieve_worldcereal_seasons\n",
    "\n",
    "spatial_extent = map.get_extent()\n",
    "seasons = retrieve_worldcereal_seasons(spatial_extent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df51a81",
   "metadata": {},
   "source": [
    "Now let's also check the distribution of `valid_time` in your reference data.<br>\n",
    "This attribute indicates the date for which the crop label is actually valid.<br>\n",
    "This is important to consider when selecting your season of interest: it does not make too much sense to train a classifier for a season in which you have barely any valid reference data to work with!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871dbe73",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import valid_time_distribution\n",
    "\n",
    "valid_time_distribution(extractions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49c83cfa",
   "metadata": {},
   "source": [
    "Now use the slider to select your season of interest.<br>\n",
    "\n",
    "Note that WorldCereal models are always trained on time series of **12 months**.<br>\n",
    "However, the models are instructed to pay the most attention to the center of your specified period.<br>\n",
    "In practice, this means the best strategy is to make sure the center of your season of interest nicely coincides with the `Season center` as indicated below the slider.<br>\n",
    "In the future it will be possible to more exactly specify your season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffefb02a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import season_slider\n",
    "\n",
    "slider = season_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "511027f9",
   "metadata": {},
   "source": [
    "**Step 5: Compute training features**\n",
    "\n",
    "Using a pretrained geospatial foundation model (Presto), we derive training features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting 128 *embeddings* (`presto_ft_0` -> `presto_ft_127`) nicely condense the Sentinel-1, Sentinel-2, meteo timeseries and ancillary data for your season of interest into a limited number of meaningful features which we will use for downstream model training.<br>\n",
    "\n",
    "Reference data for which the `valid_time` signficantly deviates from the center of your season of interest will be discarded automatically.<br>\n",
    "Users have the option to increase/decrease the value of `valid_time_buffer` (expressed in months) if they want to be more/less strict in aligning the reference data to their season of interest.<br>\n",
    "This parameter defines the minimum distance between the valid_time of a sample and the edge of the 12 months extent you have selected.<br>\n",
    "The `valid_time_buffer` is allowed to vary between 0 and 6 months. By default we use a value of 2 months.<br>\n",
    "\n",
    "Finally, we provide one more option during training feature computation aimed at increasing temporal robustness of the your final crop model.<br>\n",
    "This is controlled by the `augment` parameter: when set to `True`, it introduces slight temporal jittering of the processing window, making the model more robust against slight variations in seasonality across different years.<br>\n",
    "By default, this option is set to `False`, but especially when training a model across multiple years in areas with a lot of reference data, enabling this option could be considered.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f80de",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import compute_training_features\n",
    "\n",
    "# Retrieve the date range you just selected\n",
    "season = slider.get_selected_dates()\n",
    "\n",
    "# Prepare the training features for the selected season\n",
    "training_df = compute_training_features(extractions, season, valid_time_buffer=2, augment=False)\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5a9e5",
   "metadata": {},
   "source": [
    "**Step 5: Select your crops of interest**\n",
    "\n",
    "The following widget will display all available land cover classes and crop types in your training dataframe.\n",
    "\n",
    "Tick the checkbox for each crop type you wish to explicitly include in your model.<br>\n",
    "In case you wish to group multiple crops together, just tick the parent node in the hierarchy.\n",
    "\n",
    "Non-selected crops will be merged together in an `other` class.\n",
    "\n",
    "After selecting all your crop types of interest, hit the \"Apply\" button.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Minimum number of samples:</b><br>\n",
    "In order to train a model, we recommend a minimum of 30-50 samples to be available for each unique crop type.<br>\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15650fab",
   "metadata": {},
   "source": [
    "<div style=\"background-color:#fff3cd; border-left:5px solid #ffeeba; padding:10px; color:#856404;\">\n",
    "The area we'll be applying our model to has some soybeans, wheat and maize, so make sure you at least select these crops!<br>\n",
    "\n",
    "Choosing target crops is a key exercise when developing a crop mapping algorithm and often requires trial & error to find out whether specific combinations work well or not. There's no golden standard here. Start from a limited set of crops, keeping in mind the user needs and try to get to a working compromise. If a little further in this exercise your model performs badly, consider updating the chosen crop types and train the model again, until you're happy with the result.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70716157",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import CropTypePicker\n",
    "\n",
    "croptypepicker = CropTypePicker(sample_df=training_df, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe53569",
   "metadata": {},
   "source": [
    "In the next cell, we apply your selection to your training dataframe.<br>\n",
    "The new dataframe will contain a `downstream_class` attribute, denoting the final label that will be used during model training.<br>\n",
    "\n",
    "Let's first check which classes ended up in the \"other\" class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd192cb8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import apply_croptypepicker_to_df\n",
    "from worldcereal.utils.legend import translate_ewoc_codes\n",
    "\n",
    "training_df = apply_croptypepicker_to_df(training_df, croptypepicker)\n",
    "other_count = training_df.loc[training_df['downstream_class'] == 'other']['ewoc_code'].value_counts()\n",
    "other_labels = translate_ewoc_codes(other_count.index.tolist())\n",
    "other_count.to_frame().merge(other_labels, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e8190",
   "metadata": {},
   "source": [
    "Based on this list, you might consider dropping some classes.<br>\n",
    "This can be done by providing the \"ewoc_codes\" in the following cell.\n",
    "\n",
    "If the \"Other\" class becomes too powerful, i.e. containing a wide range of spectrally very diverse crops, it will deteriorate performance of the other classes by dragging a lot of predictive power into this class. In this case, it is better to either remove original classes so they won't influence the model, or add some more dedicated classes to the nomenclature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d282d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# drop classes\n",
    "# to_drop = [1111000000, 1111000010, 1111020010, 1101020001]\n",
    "to_drop = []\n",
    "if len(to_drop) > 0:\n",
    "    training_df = training_df.loc[~training_df['ewoc_code'].isin(to_drop)]\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70eff31d",
   "metadata": {},
   "source": [
    "Finally, you could opt to combine some classes using the code snippet below as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d2d225",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# combine_classes = {\n",
    "#     'cereals': ['winter_barley', 'oats', 'millet', 'winter_rye', 'wheat']}\n",
    "combine_classes = {}\n",
    "for new_class, old_classes in combine_classes.items():\n",
    "    training_df.loc[training_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "\n",
    "# Report on the contents of the data\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38a25e",
   "metadata": {},
   "source": [
    "**Step 6: Save your final training dataframe for future reference**\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a unique name for your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a9c9b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "df_name = get_input(\"Name dataframe\")\n",
    "\n",
    "training_dir = Path('./training_data')\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outfile = training_dir / f'{df_name}.csv'\n",
    "\n",
    "if outfile.exists():\n",
    "    raise ValueError(f\"File {outfile} already exists. Please delete it or choose a different name.\")\n",
    "\n",
    "training_df.to_csv(outfile)\n",
    "\n",
    "print(f\"Dataframe saved to {outfile}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65beebf",
   "metadata": {},
   "source": [
    "### 2. Train custom classification model\n",
    "\n",
    "We train a catboost model for the selected crop types.<br> \n",
    "\n",
    "By default, we apply **class balancing** to ensure minority classes are not discarded. However, depending on the class distribution this may lead to undesired results. There is no golden rule here. If your main goal is to make sure the most dominant classes in your training data are very precisely identified in your map, you can opt to NOT apply class balancing by setting: `balance_classes=False`. \n",
    "\n",
    "Before training, the available training data has been automatically split into a calibration and validation part. The validation report and confusion matrix already provide you with a first idea on your model's performance.<br>\n",
    "For visualizing the confusion matrix, you have several options through the `show_confusion_matrix` parameter:\n",
    "- `absolute`: print absolute sample counts in the confusion matrix\n",
    "- `relative`: plots the normalized confusion matrix\n",
    "- `none`: do not visualize a confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8237d6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model, report, confusion_matrix = train_classifier(\n",
    "    training_df, balance_classes=True, show_confusion_matrix='absolute',\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87456094",
   "metadata": {},
   "source": [
    "### 3. Deploy your custom model\n",
    "\n",
    "Once trained, your model is uploaded to a dedicated S3 bucket on CDSE, so it can be accessed by OpenEO for generating maps (see next step).<br>\n",
    "Your model is protected using your CDSE credentials and will not be accessible by anyone else.\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a clear and short name for your custom model.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Long term storage of your model:</b> <br>\n",
    "Note that your model is only kept in cloud storage for a limited amount of time. <br>\n",
    "\n",
    "Make sure to download your model (using the link provided) if you wish to store it for a longer period of time!<br>\n",
    "\n",
    "In case you would like to use your model for generating maps at a later point in time, you will need to host your model in a publicly available repository, e.g. Google Drive, and replace `model_url` with this public link during model inference.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169f1649",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>CDSE authentication:</b><br>\n",
    "After first login, your CDSE credentials will be stored on your machine avoiding the need for repeating authentication in the future. If you would want to switch CDSE account, execute the following lines of code:<br>\n",
    "<br>\n",
    "from notebook_utils.openeo import clear_openeo_token_cache<br>\n",
    "clear_openeo_token_cache()\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0ece5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "modelname = get_input(\"model\")\n",
    "model_url = deploy_model(cdse_connection(), custom_model, pattern=modelname)\n",
    "print(f\"Your model can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4204b6",
   "metadata": {},
   "source": [
    "### 4. Testing your model locally\n",
    "\n",
    "Using your custom model, we now generate a map for our area of interest in Czech Republic.\n",
    "\n",
    "The cell below references a preprocessed input file that will be downloaded locally the first time you run the workflow. This file contains all necessary features for a small region in Czech Republic and enables you to test your trained model without requiring cloud processing or repeated data downloads. By working with this local dataset, you can quickly validate your modelâ€™s performance and iterate on your workflow before scaling up to larger areas or deploying in the cloud.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Want to create your own patches of local data?</b><br>\n",
    "Check out <a href=\"https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_preprocessed_inputs.ipynb\" target=\"_blank\">this notebook</a> to learn more! \n",
    "</div>\n",
    "\n",
    "<div style=\"background-color:#fff3cd; border-left:5px solid #ffeeba; padding:10px; color:#856404;\">\n",
    "Investigate the contents of the xarray.Dataset, which contains the preprocessed inputs the model will use to classify cropland and crop types.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac88f0f6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "from pyproj import CRS\n",
    "\n",
    "local_file_path = Path(\"./local_inference/preprocessed_inputs.nc\")\n",
    "local_file_path.parent.mkdir(exist_ok=True)\n",
    "if not local_file_path.exists():\n",
    "    print(f\"Downloading demo preprocessed inputs to {local_file_path}...\")\n",
    "    remote_url = \"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/worldcereal-preprocessedinputs-Czech-demo.nc\"\n",
    "    import urllib.request\n",
    "    urllib.request.urlretrieve(remote_url, local_file_path)\n",
    "\n",
    "# Open the preprocessed inputs file\n",
    "ds = xr.open_dataset(local_file_path)\n",
    "\n",
    "# Get the EPSG code and convert to xarray DataArray\n",
    "crs_attrs = ds[\"crs\"].attrs\n",
    "epsg = CRS.from_wkt(ds.crs.attrs[\"spatial_ref\"]).to_epsg()  \n",
    "arr = ds.drop_vars(\"crs\").fillna(65535).astype(\"uint16\").to_array(dim=\"bands\")\n",
    "\n",
    "# Inspect the data\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f86117",
   "metadata": {},
   "source": [
    "The following step derives land cover embeddings and a baseline cropland mask. The preprocessed time series (arr) are passed to a lightweight Presto model finetuned on global land cover (WorldCereal reference data) to produce 128 `landcover_embeddings` capturing multi-sensor seasonal dynamics. In the same operation, the default WorldCereal global cropland classifier is applied, yielding `cropland_classification` bands. We will use the resulting cropland mask later to optionally constrain custom crop type inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2424d8ff",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.local_inference import run_cropland_mapping, classification_to_geotiff\n",
    "\n",
    "landcover_embeddings, cropland_classification = run_cropland_mapping(arr, epsg=epsg)\n",
    "\n",
    "cropland_path = Path(\"./local_inference/cropland_classification.tif\")\n",
    "cropland_path.parent.mkdir(exist_ok=True)\n",
    "classification_to_geotiff(\n",
    "    cropland_classification,\n",
    "    epsg,\n",
    "    cropland_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334ae2fa",
   "metadata": {},
   "source": [
    "Let's visualize the cropland mask you just computed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6f5f65",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_product\n",
    "\n",
    "visualize_product(cropland_path, product='cropland', interactive_mode=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f181cb",
   "metadata": {},
   "source": [
    "The next step is also exciting! ðŸŽ‰ Weâ€™ll use your custom crop type classifier to generate crop type embeddings and classifications. <br>\n",
    "Here's what happens:\n",
    "\n",
    "1. **Extract Crop Type Embeddings**: Using the same seasonal time series (arr) and spatial reference (epsg), we generate 128 crop-specific embeddings (`croptype_embeddings`) aligned with your selected crop season.\n",
    "2. **Run Your Classifier**: Your uploaded CatBoost model (model_url) predicts per-class probabilities and the final classification (`croptype_classification`).\n",
    "\n",
    "Key Highlights:\n",
    "\n",
    "- Input: Same preprocessed stack as cropland -> lightweight!\n",
    "- Output: Class ID, confidence, and probabilities for each crop type.\n",
    "- Pro Tip: Check class probabilities! Low confidence in large areas? It might mean season mismatch or not enough training samples. Adjust and try again! ðŸš€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941577b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.local_inference import run_croptype_mapping\n",
    "\n",
    "croptype_embeddings, croptype_classification = run_croptype_mapping(arr, epsg=epsg, classifier_url=model_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e0507",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.local_inference import classification_to_geotiff\n",
    "\n",
    "# Set all croptype_classification pixel values to 254 where cropland_classification 'classification' band == 0\n",
    "mask = cropland_classification.sel(bands=\"classification\") == 0\n",
    "croptype_classification = croptype_classification.where(~mask, 254)\n",
    "\n",
    "# save to GeoTIFF\n",
    "croptype_path = Path(\"local_inference\") / \"croptype_classification_v2.tif\"\n",
    "classification_to_geotiff(\n",
    "    classification=croptype_classification,\n",
    "    epsg=epsg,\n",
    "    out_path=croptype_path\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5a9cc7",
   "metadata": {},
   "source": [
    "Let's again visualize the output classification!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad0b03b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.models import load_model_lut\n",
    "from notebook_utils.visualization import visualize_product\n",
    "\n",
    "lut = load_model_lut(model_url)\n",
    "visualize_product(croptype_path, product='croptype', lut=lut, interactive_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23b5ee",
   "metadata": {},
   "source": [
    "Did you get a reasonable outcome?<br>\n",
    "\n",
    "Here is an image of the same area with some reference data, showing:\n",
    "- maize in red\n",
    "- soybean in yellow\n",
    "- winter wheat in purple\n",
    "\n",
    "![](./resources/Cze_exercise_result.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416ccc1c",
   "metadata": {},
   "source": [
    "### 5. BONUS: apply your model anywhere!\n",
    "\n",
    "Once you are happy with the performance of your model - both based on the metrics as well as from a visual check based on local inference - you are ready to create a wall-to-wall crop type map on the cloud! The steps below guide you through the process."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e63748f",
   "metadata": {},
   "source": [
    "**Step 1: Select your area of interest (AOI)**\n",
    "\n",
    "Provide a bounding box specifying the region for which you would like to create your map.<br>\n",
    "Of course this should be an area that is representative for the model you have trained.<br>\n",
    "Either draw a box directly on the map using the rectangle button, or upload a vector file (either zipped shapefile or GeoPackage) delineating your AOI.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Processing area:</b><br> \n",
    "The WorldCereal system is currently optimized to process <b>20 x 20 km</b> tiles.<br>\n",
    "In case your AOI exceeds this area, it will be automatically split, creating multiple map generation jobs.\n",
    "\n",
    "We ALWAYS recommend you to select a small area to start with, whenever trying out a model for the first time!\n",
    "\n",
    "A run of 400 kmÂ² will typically consume 40 credits and last around 20 mins.<br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4101aae5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.map import ui_map\n",
    "\n",
    "# We limit to a small area for faster processing\n",
    "map = ui_map(area_limit=1200) # area_limit in kmÂ²"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b0f342",
   "metadata": {},
   "source": [
    "**Step 2: Select your year and season of interest**\n",
    "\n",
    "We always recommend to select a similar growing season as compared to the season for which you trained your model.<br>\n",
    "\n",
    "In case your training data was restricted to 1 or 2 years, applying your model to other years will likely result in lower quality maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3468cef9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import date_slider\n",
    "\n",
    "processing_slider = date_slider()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f4b58e",
   "metadata": {},
   "source": [
    "**Step 3: Set processing parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefd58a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# Do you want to automatically mask temporary crops using the default WorldCereal temporary crops mask?\n",
    "# By default yes.\n",
    "mask_cropland = True\n",
    "\n",
    "# In case you set mask_cropland to True, choose whether you want to store the cropland mask as separate output\n",
    "save_mask = True\n",
    "\n",
    "# Choose whether or not you want to spatially clean the classification results\n",
    "postprocess_result = True\n",
    "\n",
    "# Choose the postprocessing method you want to use [\"smooth_probabilities\", \"majority_vote\"]\n",
    "# (\"smooth_probabilities will do limited spatial cleaning,\n",
    "# while \"majority_vote\" will do more aggressive spatial cleaning, depending on the value of kernel_size)\n",
    "postprocess_method = \"majority_vote\"\n",
    "\n",
    "# Additional parameter for the majority vote method\n",
    "# (the higher the value, the more aggressive the spatial cleaning,\n",
    "# should be an odd number, not larger than 25, default = 5)\n",
    "kernel_size = 5\n",
    "\n",
    "# Do you want to save the intermediate results? (before applying the postprocessing)\n",
    "save_intermediate = True\n",
    "\n",
    "# Do you want to save all class probabilities in the final product?\n",
    "# If set to False, you will only get the final classification label and confidence of the winning class per pixel\n",
    "keep_class_probs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1cf0683",
   "metadata": {},
   "source": [
    "**Step 4: Start map production**\n",
    "\n",
    "The next cell takes care of splitting your area of interest into small tiles (size is specified through `tile_resolution` parameter) and generate a map for each tile.<br>\n",
    "\n",
    "You will be able to track progress through the automated reporting.<br>\n",
    "\n",
    "Results will be automatically saved to a folder containing your model name:<br> `runs/CROPTYPE_custom_{your_modelname}_{timestamp}`<br>\n",
    "\n",
    "The first time you run this, you will be asked to authenticate with your CDSE account by clicking the link provided below the cell.<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case of interruption?</b><br> \n",
    "In case processing got interrupted, just make sure to manually set `output_dir` to the directory you previously used. In this case, processing will just continue where it stopped.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from worldcereal.job import PostprocessParameters\n",
    "from worldcereal.job import WorldCerealProductType, CropTypeParameters\n",
    "from notebook_utils.production import start_production_process, monitor_production_process\n",
    "\n",
    "# The output directory is named after the model\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_dir = Path('./runs') / f'CROPTYPE_custom_{modelname}_{timestamp}'\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "# Get all postprocessing parameters\n",
    "postprocess_parameters = PostprocessParameters(\n",
    "    enable=postprocess_result,\n",
    "    method=postprocess_method,\n",
    "    kernel_size=kernel_size,\n",
    "    save_intermediate=save_intermediate,\n",
    "    keep_class_probs=keep_class_probs,\n",
    ")\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Update parameters with user-defined values\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "parameters.save_mask = save_mask\n",
    "parameters.mask_cropland = mask_cropland\n",
    "\n",
    "# Get processing period and area\n",
    "processing_period = processing_slider.get_selected_dates()\n",
    "processing_extent = map.get_extent(projection='latlon')\n",
    "tile_resolution = 20   # in km\n",
    "\n",
    "args = (processing_extent, processing_period, output_dir)\n",
    "kwargs = dict(\n",
    "    tile_resolution=tile_resolution,\n",
    "    product_type=WorldCerealProductType.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    postprocess_parameters=postprocess_parameters,\n",
    ")\n",
    "\n",
    "proc, queue, stop_event = start_production_process(args, kwargs)\n",
    "status_df = monitor_production_process(proc, queue, stop_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156038d",
   "metadata": {},
   "source": [
    "**Step 5: Create merged product**\n",
    "\n",
    "Once production across your tiles is finalized, you can use the cell below to merge the different tiles together into one map.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.production import merge_maps\n",
    "\n",
    "merged_path = merge_maps(output_dir, product='croptype')\n",
    "print(f\"Results merged to {merged_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76baf63",
   "metadata": {},
   "source": [
    "**Step 6: Inspect your map**\n",
    "\n",
    "Up to four products are generated:\n",
    "- `croptype-raw` --> your custom crop type product\n",
    "- `croptype` --> your custom crop type product after post-processing\n",
    "- `cropland-raw` --> cropland mask produced using the global WorldCereal cropland model\n",
    "- `cropland` --> cropland mask, after post-processing\n",
    "\n",
    "For each of these products, you will get a raster file containing at least two bands:\n",
    "1. The label of the winning class\n",
    "2. The probability of the winning class [50 - 100]\n",
    "3. and beyond (optional, depending on settings): Class probabilities of each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daedb2a",
   "metadata": {},
   "source": [
    "You can use the next cell to quickly visualize your crop type product in this notebook.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Supported visualization modes:</b><br>\n",
    "By default, your product is shown using matplotlib for quick visual inspection.<br>\n",
    "By setting \"interactive_mode\" to True, both your classification and probability layers will be visualized in an interactive ipyleaflet window. By clicking the upper-right icon, followed by the button with 3 horizontal lines, you can toggle on/off individual layers and play around with layer transparency.\n",
    "\n",
    "NOTE in order for the interactive mode to work in a VSCode environment, you need to switch on port forwarding for port 8889.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_product\n",
    "from worldcereal.utils.models import load_model_lut\n",
    "\n",
    "lut = load_model_lut(model_url)\n",
    "visualize_product(merged_path, product='croptype', lut=lut, interactive_mode=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47960734",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this exercise!\n",
    "\n",
    "Want to know more after this session?\n",
    "\n",
    "- Check the [WorldCereal documentation](https://worldcereal.github.io/worldcereal-documentation/)\n",
    "- Ask questions on our [user forum](https://forum.esa-worldcereal.org/)\n",
    "- Subscribe to our [newsletter](https://esa-worldcereal.org/en#news) to get the latest updates\n",
    "- Follow us on [LinkedIn](https://www.linkedin.com/company/esa-worldcereal)!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
