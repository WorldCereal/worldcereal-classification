{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301a591",
   "metadata": {},
   "source": [
    "![](./resources/Custom_croptype_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3762385e",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Deprecation notice:</b> <br><br>\n",
    "\n",
    "Due to a major update to the WorldCereal classification system, this notebook is temporarily deprecated.<br><br>\n",
    "In its current state, the notebook still demonstrates the main steps involved in the WorldCereal mapping workflow, but will fail upon execution.<br><br>\n",
    "We are working hard to get this operational as soon as possible.<br>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11604d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add parent dirctory to sys.path\n",
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f41514-7a32-4efc-98c3-6d09f95919da",
   "metadata": {},
   "source": [
    "**Study the Effect of local data**\n",
    "\n",
    "In this notebook you will experiment the effect of local data on classification performance. \n",
    "\n",
    "- First we will experiment with the publicily available dataset in the region (Public datasets covering Zambia and Zimbabwe)\n",
    "- Next you will add the local data provided by CIMMYT as part of the use-case exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c9f999-0d3f-4ad6-bbfa-170d1dc53f5e",
   "metadata": {},
   "source": [
    "**Download the prepared Public and Local data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05767a7a-4bc3-4093-bbed-3fe9904c80dc",
   "metadata": {},
   "source": [
    "**Load public and local data**\n",
    "\n",
    "The public data covering Zambia and Zimbabwe has already been queried and stored as a parquet file for your convience. You can load it by running the cell below. \n",
    "\n",
    "It also loads the local data covering the country you selected (CIMMYT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2d9c8-1de4-4a1c-80ac-b2aaeb3772d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "from pathlib import Path\n",
    "training_fnames = ['public_zmb_zwe.parquet', 'local_zmb.parquet', 'local_zwe.parquet']\n",
    "\n",
    "for fname in training_fnames:\n",
    "    local_file_path = Path(f\"./training_data/{fname}\")\n",
    "    local_file_path.parent.mkdir(exist_ok=True)\n",
    "    local_deploy_dict = {}\n",
    "    if not local_file_path.exists():\n",
    "        print(f\"Downloading demo preprocessed inputs to {local_file_path}...\")\n",
    "        remote_url = f\"https://artifactory.vgt.vito.be/artifactory/auxdata-public/worldcereal/demo/zambia/{fname}\"\n",
    "        import urllib.request\n",
    "        urllib.request.urlretrieve(remote_url, local_file_path)\n",
    "        \n",
    "public_zmb_zwe_df = pd.read_parquet(\"./training_data/public_zmb_zwe.parquet\")\n",
    "local_country_df = pd.concat([pd.read_parquet(\"./training_data/local_zmb.parquet\"), pd.read_parquet(\"./training_data/local_zwe.parquet\")])\n",
    "\n",
    "local_id_label_mapper = dict(zip(list(local_country_df['sample_id']), list(local_country_df['label_full'])))\n",
    "public_id_label_mapper = dict(zip(list(public_zmb_zwe_df['sample_id']), list(public_zmb_zwe_df['label_full'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b66916-43a0-42b1-8ebe-ea40ca1243c3",
   "metadata": {},
   "source": [
    "**Explore which datasets are included in the private dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32eebbc4-700d-45a7-9e4b-c8ec70d1591a",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_zmb_zwe_df['ref_id'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b0c13be-eff5-4e68-8444-fdd4d4f70de6",
   "metadata": {},
   "source": [
    "**Check Valid time in public data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140d0fbf-a93a-42cb-b6a9-132d0949a75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import valid_time_distribution\n",
    "valid_time_distribution(public_zmb_zwe_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a867a0dd-7ab8-4318-89ae-fbd9784b66ce",
   "metadata": {},
   "source": [
    "**Check Valid time in local  data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e664b73-a74c-4b17-b6d4-5aec532aa4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_time_distribution(local_country_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d31e92-07d7-4521-a31f-82a3a1039532",
   "metadata": {},
   "source": [
    "Using the season slider below select a window that works best given the valid time of both the public and the local data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbd28a3-e814-4086-b280-1ee595fb4d22",
   "metadata": {},
   "source": [
    "**Set the season slider**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5bc5bb-43fd-4e17-8c32-a06e2c40171e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.dateslider import season_slider\n",
    "slider = season_slider()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b933984e-ce61-475e-8cf8-821620ec8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import align_extractions_to_season\n",
    "\n",
    "season = slider.get_selected_dates()\n",
    "\n",
    "# Align the extractions to the selected season\n",
    "public_zmb_zwe_df = align_extractions_to_season(public_zmb_zwe_df, season, valid_time_buffer=2)\n",
    "public_zmb_zwe_df.head()\n",
    "\n",
    "# Align the extractions to the selected season\n",
    "local_country_df = align_extractions_to_season(local_country_df, season, valid_time_buffer=2)\n",
    "local_country_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f98324-151f-4d8a-a10a-e0eec57e8dcb",
   "metadata": {},
   "source": [
    "**Compute training features**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea97857-7837-4cfd-a3ac-3b5af3bb5e93",
   "metadata": {},
   "source": [
    "Using a geospatial foundation model (Presto), we derive training features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting 128 *embeddings* (`presto_ft_0` -> `presto_ft_127`) nicely condense the Sentinel-1, Sentinel-2, meteo timeseries and ancillary data for your season of interest into a limited number of meaningful features which we will use for downstream model training.<br>\n",
    "\n",
    "We provide some options aimed at increasing temporal robustness of your final crop model.<br>\n",
    "This is controlled by the following arguments:\n",
    "- `augment` parameter: when set to `True`, it introduces slight temporal jittering of the processing window, making the model more robust to slight variations in seasonality across different years. By default, this option is set to `True`, but especially when training a model for a specific region and year with good local data, disabling this option could be considered.\n",
    "- `mask_on_training` parameter: when `True`, applies sensor masking augmentations (e.g. simulating S1/S2 dropouts, additional clouds, ancillary feature removals) only to the training split to improve robustness to real-world data gaps. The validation/test split is  kept untouched for fair evaluation.\n",
    "- `repeats` parameter: number of times each training sample is (re)drawn with its augmentations. Higher values (>1) create more variants (with jitter/masking) and enlarge the effective training set, potentially improving generalization at the cost of longer embedding inference time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7632e5d6-fae7-4347-9a36-3a6c0dd9daa5",
   "metadata": {},
   "source": [
    "We compute the embeddings for both the public and the local data by running the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499baf1-267f-453a-b902-9827d98ecc69",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import compute_presto_embeddings\n",
    "import pandas as pd\n",
    "\n",
    "public_zmb_zwe_df = compute_presto_embeddings(\n",
    "    public_zmb_zwe_df,\n",
    "    augment=True,\n",
    "    mask_on_training=True,\n",
    "    repeats=3\n",
    ")\n",
    "\n",
    "local_country_df = compute_presto_embeddings(\n",
    "    local_country_df,\n",
    "    augment=True,\n",
    "    mask_on_training=True,\n",
    "    repeats=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3bd2fd-c61e-4dec-a012-64250ae31aec",
   "metadata": {},
   "source": [
    "**Select common crops in both public and local for fair evaluation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ae152f-f26a-4ebf-bfcd-21238c09d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def drop_small_classes(df, label_col=\"label_full\", min_count=10):\n",
    "    counts = df[label_col].value_counts()\n",
    "    valid_labels = counts[counts >= min_count].index\n",
    "    df_filtered = df[df[label_col].isin(valid_labels)].copy()\n",
    "    return df_filtered\n",
    "\n",
    "public_zmb_zwe_df['label_full'] = public_zmb_zwe_df['sample_id'].apply(lambda x: public_id_label_mapper[x])\n",
    "local_country_df['label_full'] = local_country_df['sample_id'].apply(lambda x: local_id_label_mapper[x])\n",
    "\n",
    "public_zmb_zwe_df = drop_small_classes(public_zmb_zwe_df)\n",
    "local_country_df = drop_small_classes(local_country_df)\n",
    "\n",
    "common_labels = set(public_zmb_zwe_df['label_full'].unique()) & set(local_country_df['label_full'].unique())\n",
    "\n",
    "public_zmb_zwe_df = public_zmb_zwe_df[public_zmb_zwe_df['label_full'].isin(common_labels)].copy()\n",
    "local_country_df = local_country_df[local_country_df['label_full'].isin(common_labels)].copy()\n",
    "\n",
    "print(f\"Number of common labels: {len(common_labels)}\")\n",
    "print(\"Common crops for which the model will be trained:\", sorted(common_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b9dfad-667a-492c-8151-c047425671a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "crops_to_keep = {'maize', 'unspecified_millet', 'unspecified_sorghum'}\n",
    "crops_to_keep = {}  # example for empty set\n",
    "\n",
    "if crops_to_keep:\n",
    "    local_country_df.loc[~local_country_df['label_full'].isin(crops_to_keep), 'label_full'] = 'others'\n",
    "    public_zmb_zwe_df.loc[~public_zmb_zwe_df['label_full'].isin(crops_to_keep), 'label_full'] = 'others'\n",
    "else: \n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21adfd6d-fc26-436b-a1d7-1f79d41b0ec7",
   "metadata": {},
   "source": [
    "**Create and indenpendent test set from the local data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a6e0a2-4eb7-4839-87b5-92bc10a20528",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_local_country, test_local_country = train_test_split(\n",
    "    local_country_df,\n",
    "    test_size=0.2,\n",
    "    stratify=local_country_df[\"label_full\"],\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Public dataset:\", len(public_zmb_zwe_df), \"train,\")\n",
    "print(\"Local Zambia dataset:\", len(train_local_country), \"train,\", len(test_local_country), \"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ef6140e-0f58-43e0-aad3-56bfa63c2ec5",
   "metadata": {},
   "source": [
    "**Add a downstream class column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783e1419-354e-43d4-b56f-e1ce7fef45e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "public_zmb_zwe_df['downstream_class'] = public_zmb_zwe_df['label_full']\n",
    "train_local_country['downstream_class'] = train_local_country['label_full']\n",
    "test_local_country['downstream_class'] = test_local_country['label_full']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6794a0-c0eb-4f26-87b4-7f846911498a",
   "metadata": {},
   "source": [
    "**Train a classifier on the PUBLIC dataset alone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc85d6e-0f1b-48b4-89d8-ef8c808707eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model_pub, report, confusion_matrix = train_classifier(\n",
    "    public_zmb_zwe_df, balance_classes=True, show_confusion_matrix='absolute',\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e8439c-cc60-46f8-8db5-1328c359d85d",
   "metadata": {},
   "source": [
    "**Train a classifier on PUBLIC + LOCAL dataset alone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc49ab1-0aa6-4812-be21-5239e8499df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model_pub_loc, report, confusion_matrix = train_classifier(\n",
    "    pd.concat([public_zmb_zwe_df, train_local_country]), balance_classes=True, show_confusion_matrix='absolute',\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71070fe0-28ea-4b4d-846d-d7197ae50e0d",
   "metadata": {},
   "source": [
    "**Evaluate PUBLIC Model on independent LOCAL test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfdb3ae-0e8b-480d-a05c-67cd614556e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier, apply_classifier\n",
    "test_report_public, test_cm_public, _ = apply_classifier(\n",
    "    test_local_country,\n",
    "    custom_model_pub,\n",
    "    show_confusion_matrix='absolute',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70a0e3-1605-4abb-939c-99093f5fcecb",
   "metadata": {},
   "source": [
    "**Evaluate PUBLIC + LOCAL Model on independent LOCAL test data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaa3511-d0d3-4366-8d96-8c509ce3fc80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier, apply_classifier\n",
    "test_report_pub_loc, test_cm_pub_loc, _ = apply_classifier(\n",
    "    test_local_country,\n",
    "    custom_model_pub_loc,\n",
    "    show_confusion_matrix='absolute',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e4c61a5-322d-4f70-a8e9-e7634dfcca61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from notebook_utils.classifier import train_classifier, apply_classifier\n",
    "\n",
    "def create_fewshot_groups(train_local_country, label_col=\"label_full\", ks=[1, 5, 10, 20, \"all\"], random_state=42):\n",
    "    fewshot_groups = {}\n",
    "    grouped = train_local_country.groupby(label_col)\n",
    "    \n",
    "    for k in ks:\n",
    "        if k == \"all\":\n",
    "            fewshot_groups[k] = train_local_country.copy()\n",
    "        else:\n",
    "            sampled_df = grouped.apply(lambda x: x.sample(min(len(x), k), random_state=42)).reset_index(drop=True)\n",
    "            fewshot_groups[k] = sampled_df\n",
    "    \n",
    "    return fewshot_groups\n",
    "\n",
    "\n",
    "def run_fewshot_experiment(fewshot_groups, test_df, balance_classes=True):\n",
    "    results = []\n",
    "    crop_counts = {}\n",
    "    \n",
    "    for k, train_df in fewshot_groups.items():\n",
    "        print(f\"\\n=== Running {k}-shot setting ({len(train_df)} samples) ===\")\n",
    "        crop_counts[k] = train_df['label_full'].value_counts().to_dict()\n",
    "        print(crop_counts)\n",
    "        custom_model_loc, report, _ = train_classifier(\n",
    "            train_df,\n",
    "            balance_classes=balance_classes,\n",
    "            show_confusion_matrix=\"absolute\"\n",
    "        )\n",
    "        \n",
    "        test_report, _, _ = apply_classifier(\n",
    "            test_df,\n",
    "            custom_model_loc,\n",
    "            show_confusion_matrix=\"absolute\"\n",
    "        )\n",
    "        \n",
    "        row = {\"samples\": k}\n",
    "        for label, metrics in test_report.items():\n",
    "            if isinstance(metrics, dict) and \"f1-score\" in metrics:\n",
    "                row[label] = metrics[\"f1-score\"]\n",
    "        if \"accuracy\" in test_report:\n",
    "            row[\"overall_accuracy\"] = test_report[\"accuracy\"]\n",
    "        results.append(row)\n",
    "    \n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df, crop_counts\n",
    "\n",
    "\n",
    "def plot_fewshot_results(results_df, crop_counts):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    x = [int(k) if k != \"all\" else max([v for v in results_df[\"samples\"] if v != \"all\"]) * 1.1\n",
    "         for k in results_df[\"samples\"]]\n",
    "    \n",
    "    exclude = {\"macro avg\", \"weighted avg\", \"overall_accuracy\"}\n",
    "    crop_cols = [c for c in results_df.columns if c not in exclude and c != \"samples\"]\n",
    "\n",
    "    for crop in crop_cols:\n",
    "        ax.plot(x, results_df[crop], marker=\"o\", label=crop, alpha=0.6, linestyle=\"--\")\n",
    "\n",
    "    if \"overall_accuracy\" in results_df.columns:\n",
    "        ax.plot(x, results_df[\"overall_accuracy\"], marker=\"o\", color=\"black\", linewidth=2, label=\"Overall Accuracy\")\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xlabel(\"Samples per Class (Few-shot setting)\")\n",
    "    ax.set_ylabel(\"F1-score / Accuracy\")\n",
    "    ax.set_title(\"Few-shot Performance per Crop and Overall\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    ax.grid(True, linestyle=\":\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    count_table = pd.DataFrame(crop_counts).fillna(0).astype(int)\n",
    "    count_table.index.name = \"Crop\"\n",
    "    count_table = count_table.reset_index()\n",
    "    print(\"\\nActual samples used per crop and few-shot setting:\\n\")\n",
    "    display(count_table)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c4aa8d-4775-4ce1-a785-baf0e884f390",
   "metadata": {},
   "source": [
    "**Run sample count based experiments**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6edfc58d-df79-44a6-8e61-dc86a8baf75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = (10, 50, 100, 200, 'all') #'all' will use all the available local data for that crop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc82d6a-59b3-4ad7-a7bc-c5f2896b0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_groups = create_fewshot_groups(train_local_country, label_col=\"label_full\", ks=ks, random_state=42)\n",
    "results_df, crop_counts = run_fewshot_experiment(fewshot_groups, test_local_country, balance_classes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a76a4a2-bae5-4a1c-b4b9-0a73116d3547",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_fewshot_results(results_df, crop_counts):\n",
    "    fig, ax = plt.subplots(figsize=(10, 6))\n",
    "    \n",
    "    results_df[\"samples\"] = results_df[\"samples\"].astype(str)\n",
    "    x = []\n",
    "    for k in results_df[\"samples\"]:\n",
    "        if k == \"all\":\n",
    "            max_val = max([int(v) for v in results_df[\"samples\"] if v.isdigit()])\n",
    "            x.append(max_val * 1.1)\n",
    "        else:\n",
    "            x.append(int(k))\n",
    "    \n",
    "    exclude = {\"macro avg\", \"weighted avg\", \"overall_accuracy\"}\n",
    "    crop_cols = [c for c in results_df.columns if c not in exclude and c != \"samples\"]\n",
    "\n",
    "    for crop in crop_cols:\n",
    "        ax.plot(x, results_df[crop], marker=\"o\", label=crop, alpha=0.6, linestyle=\"--\")\n",
    "\n",
    "    if \"overall_accuracy\" in results_df.columns:\n",
    "        ax.plot(x, results_df[\"overall_accuracy\"], marker=\"o\", color=\"black\", linewidth=2, label=\"Overall Accuracy\")\n",
    "\n",
    "    ax.set_xscale(\"linear\")\n",
    "    ax.set_xlabel(\"Samples per Class (Few-shot setting)\")\n",
    "    ax.set_ylabel(\"F1-score / Accuracy\")\n",
    "    ax.set_title(\"Few-shot Performance per Crop and Overall\")\n",
    "    ax.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "    ax.grid(True, linestyle=\":\")\n",
    "    ax.set_ylim(bottom=0)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    count_table = pd.DataFrame(crop_counts).fillna(0).astype(int)\n",
    "    count_table.index.name = \"Crop\"\n",
    "    count_table = count_table.reset_index()\n",
    "    print(\"\\nActual samples used per crop and few-shot setting:\\n\")\n",
    "    display(count_table)\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "row_pub = {\"samples\": 0}\n",
    "for label, metrics in test_report_public.items():\n",
    "    if isinstance(metrics, dict) and \"f1-score\" in metrics:\n",
    "        row_pub[label] = metrics[\"f1-score\"]\n",
    "if \"accuracy\" in test_report_public:\n",
    "    row_pub[\"overall_accuracy\"] = test_report_public[\"accuracy\"]\n",
    "\n",
    "results_df = pd.concat([pd.DataFrame([row_pub]), results_df], ignore_index=True)\n",
    "\n",
    "zero_counts = {label: 0 for label in crop_counts[next(iter(crop_counts))].keys()}\n",
    "crop_counts = {0: zero_counts, **crop_counts}\n",
    "\n",
    "results_df[\"samples\"] = pd.Categorical(\n",
    "    results_df[\"samples\"],\n",
    "    categories=[0] + [k for k in results_df[\"samples\"] if k not in [0, \"all\"]] + [\"all\"],\n",
    "    ordered=True\n",
    ")\n",
    "\n",
    "plot_fewshot_results(results_df, crop_counts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05a04225-f096-4786-9ce7-9b02670dc07f",
   "metadata": {},
   "source": [
    "**You have reached the end of the notebook**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
