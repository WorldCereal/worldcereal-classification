{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2301a591",
   "metadata": {},
   "source": [
    "![](./resources/Custom_croptype_map.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939a284b",
   "metadata": {},
   "source": [
    "### Content\n",
    "\n",
    "- [Introduction](###-Introduction)\n",
    "- [How to run this notebook?](###-How-to-run-this-notebook?)\n",
    "- [Before you start](###-Before-you-start)\n",
    "- [1. Gather and prepare your training data](###-1.-Gather-and-prepare-your-training-data)\n",
    "- [2. Prepare training features](###-2.-Prepare-training-features)\n",
    "- [3. Train custom classification model](###-3.-Train-custom-classification-model)\n",
    "- [4. Deploy your custom model](###-4.-Deploy-your-custom-model)\n",
    "- [5. Generate your custom crop type map](###-5.-Generate-your-custom-crop-type-map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c162856",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook guides you through the process of training a custom crop type classification model in Tanzania based on publicly available training data sourced from the WorldCereal Reference Data Module.\n",
    "\n",
    "After model training, we deploy your custom model to the cloud, from where it can be accessed by OpenEO, allowing you to generate a crop type map.\n",
    "\n",
    "Note that if you would like to repeat this exercise for another area and/or season, we refer to the [worldcereal_custom_croptype.ipynb](https://github.com/WorldCereal/worldcereal-classification/blob/main/notebooks/worldcereal_custom_croptype.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b4436d",
   "metadata": {},
   "source": [
    "### How to run this notebook?\n",
    "\n",
    "#### Option 1: Run on Terrascope\n",
    "\n",
    "You can use a preconfigured environment on [**Terrascope**](https://terrascope.be/en) to run the workflows in a Jupyter notebook environment. Just register as a new user on Terrascope or use one of the supported EGI eduGAIN login methods to get started.\n",
    "\n",
    "Once you have a Terrascope account, you can run this notebook by clicking the button shown below.\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">When you click the button, you will be prompted with \"Server Options\".<br>\n",
    "Make sure to select the \"Worldcereal\" image here. Did you choose \"Terrascope\" by accident?<br>\n",
    "Then go to File > Hub Control Panel > Stop my server, and click the link below once again.</div>\n",
    "\n",
    "\n",
    "<a href=\"https://notebooks.terrascope.be/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2FWorldCereal%2Fworldcereal-classification&urlpath=lab%2Ftree%2Fworldcereal-classification%2Fnotebooks%2FLPS_tutorial_custom_croptype.ipynb&branch=main\"><img src=\"https://img.shields.io/badge/Generate%20custom%20crop%20type%20map-Terrascope-brightgreen\" alt=\"Generate custom crop type map\" valign=\"middle\"></a>\n",
    "\n",
    "\n",
    "#### Option 2: Install Locally\n",
    "\n",
    "If you prefer to install the package locally, you can create the WorldCereal environment using **Conda** or **pip**.\n",
    "\n",
    "First clone the repository:\n",
    "```bash\n",
    "git clone https://github.com/WorldCereal/worldcereal-classification.git\n",
    "cd worldcereal-classification\n",
    "```\n",
    "Next, install the package locally:\n",
    "- for Conda: `conda env create -f environment.yml`\n",
    "- for Pip: `pip install .[train,notebooks]`\n",
    "\n",
    "\n",
    "#### Option 3: Run on CDSE notebooks or Google colab\n",
    "\n",
    "Working in another Jupyter cloud environment?\n",
    "\n",
    "You can install the worldcereal package and its dependencies using:\n",
    "```bash\n",
    "pip install git+https://github.com/WorldCereal/presto-worldcereal.git@croptype\n",
    "pip install --no-deps --quiet \"git+https://github.com/worldcereal/worldcereal-classification.git@main\"\n",
    "pip install --upgrade --quiet \"worldcereal[train,notebooks]\"\n",
    "```\n",
    "\n",
    "Then upload the notebook and all files in the `notebook_utils` subdirectory and you should be good to go..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382eb9cc",
   "metadata": {},
   "source": [
    "### Before you start\n",
    "\n",
    "In order to run WorldCereal crop mapping jobs from this notebook, you need to create an account on the [Copernicus Data Space Ecosystem](https://dataspace.copernicus.eu/).<br>\n",
    "This is free of charge and will grant you a number of free openEO processing credits to continue this demo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4116e791",
   "metadata": {},
   "source": [
    "### 1. Gather and prepare your training data\n",
    "\n",
    "Public reference data, along with pre-processed time series of all required inputs for model training, are available in a dedicated S3 bucket.<br>\n",
    "Here we query this bucket to retrieve all data surrounding our area of interest."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c64e8c9",
   "metadata": {},
   "source": [
    "**Step 1: Define your area of interest (AOI)**\n",
    "\n",
    "For the purpose of this demo, we use a preconfigured bounding box, located in the Manyara province in Tanzania."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2cb08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openeo_gfmap import BoundingBoxExtent\n",
    "from shapely.geometry import box\n",
    "\n",
    "processing_extent = BoundingBoxExtent(west=36.44183147892941, south=-5.575316737398433, east=36.60335694430027, north=-5.499907154141718, epsg=4326)\n",
    "processing_extent_utm = BoundingBoxExtent(west=216548.57047209592, south=9383125.482200256, east=234490.35950809612, north=9391543.763833705, epsg=32737)\n",
    "polygon = box(\n",
    "    processing_extent.west,\n",
    "    processing_extent.south,\n",
    "    processing_extent.east,\n",
    "    processing_extent.north)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca4b0f1",
   "metadata": {},
   "source": [
    "**Step 2: Get all available reference data**\n",
    "\n",
    "We apply a spatial buffer of 600 km around our area of interest to ensure enough training data is found.\n",
    "You can freely expand this search perimeter by changing the value of the `buffer` parameter.\n",
    "\n",
    "In the background, we explicitly filter on temporary crops.<br>\n",
    "Note that this implies mapping of permanent crops is currently not supported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d1721e1",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.extractions import query_extractions\n",
    "\n",
    "# Specify a buffer distance to expand your search perimeter\n",
    "buffer = 600000  # meters\n",
    "\n",
    "# Query our public database of training data\n",
    "extractions = query_extractions(polygon, buffer)\n",
    "extractions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4e4487",
   "metadata": {},
   "source": [
    "**Step 3: Perform a quick quality check**\n",
    "\n",
    "In this optional step, we provide you with some tools to quickly assess the quality of the datasets.\n",
    "\n",
    "Upon executing this cell, you will be prompted to enter a dataset name (ref_id) for inspection.\n",
    "\n",
    "Especially the visualization of the time series might help you better define your season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a38d333",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.extractions import get_band_statistics, visualize_timeseries\n",
    "\n",
    "dataset_name = input('Enter the dataset name: ')\n",
    "subset_data = extractions.loc[extractions['ref_id'] == dataset_name]\n",
    "\n",
    "# Check band statistics\n",
    "band_stats = get_band_statistics(subset_data)\n",
    "\n",
    "# Visualize timeseries for a few samples\n",
    "visualize_timeseries(subset_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80e37cc6",
   "metadata": {},
   "source": [
    "**Step 4: Select your season of interest**\n",
    "\n",
    "To gain a better understanding of crop seasonality in your area of interest, you can consult the WorldCereal crop calendars (by executing the next cell), or check out the [USDA crop calendars](https://ipad.fas.usda.gov/ogamaps/cropcalendar.aspx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcf426",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.seasons import retrieve_worldcereal_seasons\n",
    "\n",
    "seasons = retrieve_worldcereal_seasons(processing_extent_utm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0020a3",
   "metadata": {},
   "source": [
    "Let's say we want to produce our map for 2021, more specifically for the season running from October 2020 to April 2021.<br>\n",
    "WorldCereal models always need a full year of data, so we ensure the peak of season (February 2021) is nicely centered in the selected period of time: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea25aeed",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from openeo_gfmap import TemporalContext\n",
    "\n",
    "start_date = '2020-08-01'\n",
    "end_date = '2021-07-31'\n",
    "\n",
    "processing_period = TemporalContext(start_date, end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e373be4",
   "metadata": {},
   "source": [
    "**Step 5: Filter your training data based on timing of observation**\n",
    "\n",
    "In this step, our training data is first converted into a format which can be used by our training feature computation and model training routines.\n",
    "\n",
    "Then, we filter out any sample for which the observation date (attribute `valid_time`) does not match the selected season of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2e07f9",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.refdata import process_extractions_df\n",
    "\n",
    "# Process the merged data\n",
    "training_df = process_extractions_df(extractions, processing_period)\n",
    "\n",
    "# Report on the contents of the data\n",
    "print(f'Samples originating from {training_df[\"ref_id\"].nunique()} unique reference datasets.')\n",
    "print('Distribution of samples across years:')\n",
    "print(training_df.year.value_counts())\n",
    "ncroptypes = training_df['ewoc_code'].nunique()\n",
    "print(f'Number of crop types remaining: {ncroptypes}')\n",
    "if ncroptypes <= 1:\n",
    "    raise ValueError(\"Not enough crop types found in the remaining data to train a model, cannot continue.\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f5a9e5",
   "metadata": {},
   "source": [
    "**Step 6: Select your crops of interest**\n",
    "\n",
    "The following widget will display all available crop types in your training dataframe.\n",
    "\n",
    "Tick the checkbox for each crop type you wish to explicitly include in your model.<br>\n",
    "In case you wish to group multiple crops together, just tick the parent node in the hierarchy.\n",
    "\n",
    "Not selected crops will be merged together in an `other_temporary_crops` class.\n",
    "\n",
    "After selecting all your crop types of interest, hit the \"Apply\" button.\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Minimum number of samples:</b><br>\n",
    "In order to train a model, we recommend a minimum of 30-50 samples to be available for each unique crop type.<br>\n",
    "Think carefully about which crops to include!\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70716157",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import CropTypePicker\n",
    "\n",
    "croptypepicker = CropTypePicker(sample_df=training_df, count_threshold=0, expand=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe53569",
   "metadata": {},
   "source": [
    "In the next cell, we apply your selection to your training dataframe.<br>\n",
    "The new dataframe will contain a `downstream_class` attribute, denoting the final label.<br>\n",
    "Let's first check which classes ended up in the \"other_temporary_crops\" class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd192cb8",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.croptypepicker import apply_croptypepicker_to_df\n",
    "from worldcereal.utils.legend import translate_ewoc_codes\n",
    "\n",
    "training_df = apply_croptypepicker_to_df(training_df, croptypepicker)\n",
    "other_classes = list(training_df.loc[training_df['downstream_class'] == 'other_temporary_crops']['ewoc_code'].unique())\n",
    "other_crops = translate_ewoc_codes(other_classes)\n",
    "other_crops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "493e8190",
   "metadata": {},
   "source": [
    "Based on this list, you might consider dropping some classes.<br>\n",
    "This can be done by providing the \"ewoc_codes\" in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d282d",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "# drop classes\n",
    "to_drop = [1111010100]   # dropping sugarcane\n",
    "if len(to_drop) > 0:\n",
    "    training_df = training_df.loc[~training_df['ewoc_code'].isin(to_drop)]\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb126217",
   "metadata": {},
   "source": [
    "Finally, you could opt to combine some classes using the code snippet below as an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2e79a79",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "combine_classes = {\n",
    "    'vegetables_root_crops': ['vegetables_fruits', 'root_tuber_crops'],}\n",
    "for new_class, old_classes in combine_classes.items():\n",
    "    training_df.loc[training_df['downstream_class'].isin(old_classes), 'downstream_class'] = new_class\n",
    "\n",
    "# Report on the contents of the data\n",
    "training_df['downstream_class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a38a25e",
   "metadata": {},
   "source": [
    "**Step 7: Save your final training dataframe for future reference**\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a unique name for your dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97a9c9b",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "df_name = get_input(\"name dataframe\")\n",
    "\n",
    "training_dir = Path('./training_data')\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "outfile = training_dir / f'{df_name}.csv'\n",
    "\n",
    "if outfile.exists():\n",
    "    raise ValueError(f\"File {outfile} already exists. Please delete it or choose a different name.\")\n",
    "\n",
    "training_df.to_csv(outfile)\n",
    "\n",
    "print(f\"Dataframe saved to {outfile}\")\n",
    "training_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f1d5f0",
   "metadata": {},
   "source": [
    "### 2. Prepare training features\n",
    "\n",
    "Using a deep learning framework (Presto), we derive classification features for each sample in the dataframe resulting from your query. Presto was pre-trained on millions of unlabeled samples around the world and finetuned on global labelled land cover and crop type data from the WorldCereal reference database. The resulting *embeddings* (`presto_ft_0` -> `presto_ft_127`) and the target labels (`downstream_class`) to train on will be returned as a training dataframe which we will use for downstream model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529dbd1a",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import prepare_training_dataframe\n",
    "\n",
    "training_dataframe = prepare_training_dataframe(training_df)\n",
    "training_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65beebf",
   "metadata": {},
   "source": [
    "### 3. Train custom classification model\n",
    "\n",
    "We train a catboost model for the selected crop types.<br> \n",
    "\n",
    "By default, we apply **class balancing** to ensure minority classes are not discarded. However, depending on the class distribution this may lead to undesired results. There is no golden rule here. If your main goal is to make sure the most dominant classes in your training data are very precisely identified in your map, you can opt to NOT apply class balancing by setting: `balance_classes=False`. \n",
    "\n",
    "Before training, the available training data has been automatically split into a calibration and validation part. The validation report and (optionally) confusion matrix already provides you with a first idea on your model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8237d6",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from notebook_utils.classifier import train_classifier\n",
    "\n",
    "custom_model, report, confusion_matrix = train_classifier(\n",
    "    training_dataframe, balance_classes=True, show_confusion_matrix=True,\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87456094",
   "metadata": {},
   "source": [
    "### 4. Deploy your custom model\n",
    "\n",
    "Once trained, we have to upload our model to the cloud so it can be used by OpenEO for inference.\n",
    "\n",
    "Upon executing the next cell, you will be prompted to provide a clear and short name for your custom model.\n",
    "\n",
    "Note that these models are only kept in cloud storage for a limited amount of time. Make sure to download your model (using the link provided) if you wish to store it for a longer period of time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed0ece5",
   "metadata": {
    "vscode": {
     "languageId": "ruby"
    }
   },
   "outputs": [],
   "source": [
    "from worldcereal.utils.upload import deploy_model\n",
    "from openeo_gfmap.backend import cdse_connection\n",
    "from notebook_utils.classifier import get_input\n",
    "\n",
    "modelname = get_input(\"model\")\n",
    "model_url = deploy_model(cdse_connection(), custom_model, pattern=modelname)\n",
    "print(f\"Your model can be downloaded from: {model_url}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4204b6",
   "metadata": {},
   "source": [
    "### 5. Generate your custom crop type map\n",
    "\n",
    "Using our custom model, we generate a map for our region and season of interest.\n",
    "\n",
    "The next cell takes care of splitting your area of interest into small tiles (size is specified through `tile_resolution` parameter) and generate a map for each tile.<br>\n",
    "\n",
    "You will be able to track progress through the automated reporting.<br>\n",
    "\n",
    "Results will be automatically saved to a folder containing your model name:<br> `runs/CROPTYPE_custom_{your_modelname}_{timestamp}`<br>\n",
    "\n",
    "The first time you run this, you will be asked to authenticate with your CDSE account by clicking the link provided below the cell.<br>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>What to do in case of interruption?</b><br> \n",
    "In case processing got interrupted, just make sure to manually set `output_dir` to the directory you previously used. In this case, processing will just continue where it stopped.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d9bbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from worldcereal.job import PostprocessParameters\n",
    "from worldcereal.job import WorldCerealProductType, CropTypeParameters\n",
    "from notebook_utils.production import start_production_process, monitor_production_process\n",
    "\n",
    "# The output directory is named after the model\n",
    "timestamp = pd.Timestamp.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "output_dir = Path('./runs') / f'CROPTYPE_custom_{modelname}_{timestamp}'\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "### OPTIONAL PARAMETERS\n",
    "#-----------------------------------------------------------------------\n",
    "# Choose whether you want to store the cropland mask as separate output file\n",
    "save_mask = True\n",
    "\n",
    "# Choose whether or not you want to spatially clean the classification results\n",
    "postprocess_result = True\n",
    "\n",
    "# Choose the postprocessing method you want to use [\"smooth_probabilities\", \"majority_vote\"]\n",
    "# (\"smooth_probabilities will do limited spatial cleaning,\n",
    "# while \"majority_vote\" will do more aggressive spatial cleaning, depending on the value of kernel_size)\n",
    "postprocess_method = \"majority_vote\"\n",
    "\n",
    "# Additional parameter for the majority vote method\n",
    "# (the higher the value, the more aggressive the spatial cleaning,\n",
    "# should be an odd number, not larger than 25, default = 5)\n",
    "kernel_size = 5\n",
    "\n",
    "# Do you want to save the intermediate results? (before applying the postprocessing)\n",
    "save_intermediate = True\n",
    "\n",
    "# Do you want to save all class probabilities in the final product? (default is False)\n",
    "keep_class_probs = True\n",
    "\n",
    "postprocess_parameters = PostprocessParameters(\n",
    "    enable=postprocess_result,\n",
    "    method=postprocess_method,\n",
    "    kernel_size=kernel_size,\n",
    "    save_intermediate=save_intermediate,\n",
    "    keep_class_probs=keep_class_probs,\n",
    ")\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "# Initializes default parameters\n",
    "parameters = CropTypeParameters()\n",
    "\n",
    "# Change the URL to your custom classification model\n",
    "parameters.classifier_parameters.classifier_url = model_url\n",
    "parameters.save_mask = save_mask\n",
    "\n",
    "# Define tile resolution in km\n",
    "tile_resolution = 20\n",
    "\n",
    "job_options={\"image-name\":\"registry.prod.warsaw.openeo.dataspace.copernicus.eu/prod/openeo-geotrellis-kube-python311:20250619-34\"}\n",
    "\n",
    "args = (processing_extent, processing_period, output_dir)\n",
    "kwargs = dict(\n",
    "    tile_resolution=tile_resolution,\n",
    "    product_type=WorldCerealProductType.CROPTYPE,\n",
    "    croptype_parameters=parameters,\n",
    "    postprocess_parameters=postprocess_parameters,\n",
    "    job_options=job_options,\n",
    ")\n",
    "\n",
    "proc, queue, stop_event = start_production_process(args, kwargs)\n",
    "status_df = monitor_production_process(proc, queue, stop_event)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a156038d",
   "metadata": {},
   "source": [
    "Once production across your tiles is finalized, you can use the cell below to merge the different tiles together into one map.<br>\n",
    "\n",
    "By default, four products are generated:\n",
    "- `cropland-raw` --> cropland mask produced using the global WorldCereal cropland model\n",
    "- `cropland` --> cropland mask, after post-processing\n",
    "- `croptype-raw` --> your custom crop type product\n",
    "- `croptype` --> your custom crop type product after post-processing\n",
    "\n",
    "For each of these products, you will get a raster file containing at least two bands:\n",
    "1. The label of the winning class\n",
    "2. The probability of the winning class [50 - 100]\n",
    "3. and beyond (optional, depending on settings): Class probabilities of each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65bf4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.production import merge_maps\n",
    "\n",
    "merged_path = merge_maps(output_dir, product='croptype')\n",
    "print(f\"Results merged to {merged_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daedb2a",
   "metadata": {},
   "source": [
    "Finally, use the next cell to quickly visualize your crop type product in this notebook.\n",
    "\n",
    "In case you want to compare all products, we recommend you to use QGIS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed88c02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from notebook_utils.visualization import visualize_product\n",
    "from worldcereal.utils.models import load_model_lut\n",
    "\n",
    "lut = load_model_lut(model_url)\n",
    "visualize_product(merged_path, product='croptype', lut=lut, write=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47960734",
   "metadata": {},
   "source": [
    "Congratulations, you have reached the end of this demo!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "worldcereal",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
